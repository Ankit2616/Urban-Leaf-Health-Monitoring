{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3849a2cd-03b0-46c0-9e46-e05ed04f3412",
   "metadata": {},
   "source": [
    "## Standard Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92ed236-e7f5-4239-b9b0-3489c684cab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "print('Imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8434100-8690-4bfc-afae-7babc0b73e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Earth Engine\n",
    "try:\n",
    "    ee.Initialize(project = 'glacier-probe-model-475519')\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project = 'glacier-probe-model-475519')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66debf43-25da-4443-9724-e116fd61c74e",
   "metadata": {},
   "source": [
    "## 1. Hasdeo Forest RGB Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf5851-0480-44ed-bb8e-60d5bd82aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hasdeo Forest GeoTIFF Downloader - MODEL TRAINING VERSION\n",
    "=========================================================\n",
    "Downloads high-quality multi-band GeoTIFF satellite imagery from Sentinel-2\n",
    "for the Hasdeo Arand forest region, covering full deforestation timeline.\n",
    "\n",
    "BANDS DOWNLOADED:\n",
    "  - B2 (Blue, 490nm), B3 (Green, 560nm), B4 (Red, 665nm)\n",
    "  - B8 (NIR, 842nm) â€” critical for NDVI / vegetation indices\n",
    "  - B11 (SWIR1, 1610nm), B12 (SWIR2, 2190nm) â€” for burn/soil detection\n",
    "  - NDVI (computed) â€” pre-computed vegetation index\n",
    "  - SCL (Scene Classification Layer) â€” for masking\n",
    "\n",
    "OUTPUT:\n",
    "  - Full-resolution GeoTIFF (10m or 20m) with all bands\n",
    "  - Cloud-masked composites (median per season)\n",
    "  - Individual scene downloads\n",
    "  - Metadata CSV for dataset bookkeeping\n",
    "\n",
    "USAGE:\n",
    "  pip install earthengine-api google-cloud-storage requests pillow numpy tqdm\n",
    "  python hasdeo_geotiff_downloader.py\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CONFIGURATION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "PROJECT_ID = 'glacier-probe-model-475519'   # â† your GEE project ID\n",
    "GCS_BUCKET = ''                              # â† your GCS bucket name for large exports (optional)\n",
    "OUTPUT_DIR = 'hasdeo_training_dataset'\n",
    "\n",
    "# â”€â”€ Hasdeo Arand full region + sub-regions of interest â”€â”€\n",
    "REGIONS = {\n",
    "    # Full Hasdeo Arand forest block (~10km x 10km)\n",
    "    'Hasdeo_Full':       [82.60, 22.80, 83.00, 23.20],\n",
    "\n",
    "    # PEKB (Parsa East & Kante Basan) â€” primary deforestation zone\n",
    "    'PEKB_Core':         [82.70, 22.90, 82.85, 23.05],\n",
    "\n",
    "    # Kente Extension block â€” active 2023-2026\n",
    "    'Kente_Extension':   [82.65, 23.05, 82.80, 23.20],\n",
    "\n",
    "    # Buffer / control area (less disturbed forest for comparison)\n",
    "    'Control_Forest':    [82.85, 23.00, 83.00, 23.15],\n",
    "}\n",
    "\n",
    "# â”€â”€ Deforestation timeline: quarterly sampling for dense coverage â”€â”€\n",
    "# Format: (start_date, end_date, priority_label)\n",
    "# Higher frequency during rapid expansion phases\n",
    "TIME_PERIODS = []\n",
    "\n",
    "def build_time_periods():\n",
    "    \"\"\"Build quarterly time windows across the full deforestation timeline.\"\"\"\n",
    "    periods = []\n",
    "\n",
    "    # 2013-2015: Initial clearing â€” semi-annual\n",
    "    for year in range(2013, 2016):\n",
    "        periods.append((f'{year}-01-01', f'{year}-07-01', 'initial_clearing'))\n",
    "        periods.append((f'{year}-07-01', f'{year+1}-01-01', 'initial_clearing'))\n",
    "\n",
    "    # 2016-2019: Rapid expansion â€” quarterly\n",
    "    for year in range(2016, 2020):\n",
    "        for q, (m1, m2) in enumerate([('01','04'),('04','07'),('07','10'),('10','12')], 1):\n",
    "            end_m = '01' if q == 4 else m2\n",
    "            end_y = year + 1 if q == 4 else year\n",
    "            periods.append((f'{year}-{m1}-01', f'{end_y}-{end_m}-01', 'rapid_expansion'))\n",
    "\n",
    "    # 2020-2022: Slowdown â€” quarterly\n",
    "    for year in range(2020, 2023):\n",
    "        for q, (m1, m2) in enumerate([('01','04'),('04','07'),('07','10'),('10','12')], 1):\n",
    "            end_m = '01' if q == 4 else m2\n",
    "            end_y = year + 1 if q == 4 else year\n",
    "            periods.append((f'{year}-{m1}-01', f'{end_y}-{end_m}-01', 'slowdown'))\n",
    "\n",
    "    # 2023-2025: Renewed surge â€” monthly for key months\n",
    "    for year in range(2023, 2026):\n",
    "        for month in range(1, 13):\n",
    "            start = f'{year}-{month:02d}-01'\n",
    "            if month == 12:\n",
    "                end = f'{year+1}-01-01'\n",
    "            else:\n",
    "                end = f'{year}-{month+1:02d}-01'\n",
    "            if year == 2025 and month > 8:\n",
    "                break\n",
    "            periods.append((start, end, 'renewed_surge'))\n",
    "\n",
    "    return periods\n",
    "\n",
    "TIME_PERIODS = build_time_periods()\n",
    "\n",
    "# â”€â”€ Sentinel-2 bands for model training â”€â”€\n",
    "S2_BANDS = ['B2', 'B3', 'B4', 'B8', 'B8A', 'B11', 'B12', 'SCL']\n",
    "BAND_LABELS = {\n",
    "    'B2':  'Blue_490nm',\n",
    "    'B3':  'Green_560nm',\n",
    "    'B4':  'Red_665nm',\n",
    "    'B8':  'NIR_842nm',\n",
    "    'B8A': 'NIR_narrow_865nm',\n",
    "    'B11': 'SWIR1_1610nm',\n",
    "    'B12': 'SWIR2_2190nm',\n",
    "    'SCL': 'SceneClassification',\n",
    "}\n",
    "\n",
    "SCALE_METERS = 10        # 10m native resolution for B2/B3/B4/B8; 20m resampled up\n",
    "MAX_CLOUD_COVER = 20     # % cloud threshold per scene\n",
    "MIN_IMAGES_PER_PERIOD = 1\n",
    "EXPORT_MODE = 'drive'    # 'drive' | 'gcs' | 'local_thumb'\n",
    "                         # 'drive' â†’ exports to your Google Drive (recommended for large files)\n",
    "                         # 'gcs'   â†’ exports to GCS bucket (fastest for bulk)\n",
    "                         # 'local_thumb' â†’ downloads small thumbs locally (no quota needed)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# INITIALIZATION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def init_ee():\n",
    "    try:\n",
    "        ee.Initialize(project=PROJECT_ID)\n",
    "        print(f\"âœ“ Earth Engine initialized | project: {PROJECT_ID}\")\n",
    "    except Exception:\n",
    "        print(\"âš  Re-authenticating...\")\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize(project=PROJECT_ID)\n",
    "        print(\"âœ“ Authenticated and initialized.\")\n",
    "\n",
    "def create_dirs():\n",
    "    for sub in ['exports', 'metadata', 'composites', 'logs']:\n",
    "        Path(f\"{OUTPUT_DIR}/{sub}\").mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"âœ“ Output directories ready: {OUTPUT_DIR}/\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CLOUD MASKING & PREPROCESSING\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def mask_s2_clouds(image):\n",
    "    \"\"\"\n",
    "    Robust cloud masking using:\n",
    "    1. QA60 bitmask (clouds + cirrus)\n",
    "    2. SCL layer (cloud shadow, medium/high probability cloud, cirrus)\n",
    "    \"\"\"\n",
    "    qa = image.select('QA60')\n",
    "    cloud_bit  = 1 << 10\n",
    "    cirrus_bit = 1 << 11\n",
    "    qa_mask = qa.bitwiseAnd(cloud_bit).eq(0).And(\n",
    "               qa.bitwiseAnd(cirrus_bit).eq(0))\n",
    "\n",
    "    scl = image.select('SCL')\n",
    "    # SCL classes to EXCLUDE: 3=shadow, 8=cloud_med, 9=cloud_high, 10=cirrus, 11=snow\n",
    "    scl_mask = scl.neq(3).And(scl.neq(8)).And(scl.neq(9)).And(scl.neq(10))\n",
    "\n",
    "    return image.updateMask(qa_mask.And(scl_mask))\n",
    "\n",
    "def add_indices(image):\n",
    "    \"\"\"Add vegetation and deforestation-relevant indices.\"\"\"\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')   # water\n",
    "    nbr  = image.normalizedDifference(['B8', 'B12']).rename('NBR')   # burn ratio\n",
    "    evi  = image.expression(\n",
    "        '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',\n",
    "        {'NIR': image.select('B8'), 'RED': image.select('B4'), 'BLUE': image.select('B2')}\n",
    "    ).rename('EVI')\n",
    "    return image.addBands([ndvi, ndwi, nbr, evi])\n",
    "\n",
    "def get_s2_collection(roi, start_date, end_date):\n",
    "    \"\"\"Get cloud-filtered, index-enhanced Sentinel-2 collection.\"\"\"\n",
    "    col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "           .filterBounds(roi)\n",
    "           .filterDate(start_date, end_date)\n",
    "           .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', MAX_CLOUD_COVER))\n",
    "           .select(S2_BANDS + ['QA60'])\n",
    "           .map(mask_s2_clouds)\n",
    "           .map(add_indices))\n",
    "    return col\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# EXPORT FUNCTIONS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def export_to_drive(image, description, region, scale=SCALE_METERS):\n",
    "    \"\"\"\n",
    "    Export full-resolution GeoTIFF to Google Drive.\n",
    "    Best for model training â€” preserves geospatial metadata.\n",
    "    \"\"\"\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image=image,\n",
    "        description=description,\n",
    "        folder='Hasdeo_Training_Dataset',\n",
    "        fileNamePrefix=description,\n",
    "        region=region,\n",
    "        scale=scale,\n",
    "        crs='EPSG:32644',           # UTM Zone 44N â€” appropriate for Hasdeo\n",
    "        fileFormat='GeoTIFF',\n",
    "        maxPixels=1e10,\n",
    "        formatOptions={\n",
    "            'cloudOptimized': True  # Cloud-Optimized GeoTIFF for fast ML reads\n",
    "        }\n",
    "    )\n",
    "    task.start()\n",
    "    return task\n",
    "\n",
    "def export_to_gcs(image, description, region, bucket, scale=SCALE_METERS):\n",
    "    \"\"\"Export to Google Cloud Storage bucket.\"\"\"\n",
    "    task = ee.batch.Export.image.toCloudStorage(\n",
    "        image=image,\n",
    "        description=description,\n",
    "        bucket=bucket,\n",
    "        fileNamePrefix=f'hasdeo/{description}',\n",
    "        region=region,\n",
    "        scale=scale,\n",
    "        crs='EPSG:32644',\n",
    "        fileFormat='GeoTIFF',\n",
    "        maxPixels=1e10,\n",
    "        formatOptions={'cloudOptimized': True}\n",
    "    )\n",
    "    task.start()\n",
    "    return task\n",
    "\n",
    "def download_local_thumb(image, region, filepath, bands=['B4','B3','B2'], size=512):\n",
    "    \"\"\"\n",
    "    Download small PNG thumbnail locally (no Drive/GCS needed).\n",
    "    Use for quick visual QA only â€” not for model training.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        vis = image.visualize(bands=bands, min=0, max=3000)\n",
    "        url = vis.getThumbURL({'region': region, 'dimensions': size, 'format': 'png'})\n",
    "        r = requests.get(url, timeout=120)\n",
    "        if r.status_code == 200:\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Thumb error: {str(e)[:60]}\")\n",
    "    return False\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# COMPOSITE GENERATION (for training labels)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def create_seasonal_composite(roi, year, season='dry'):\n",
    "    \"\"\"\n",
    "    Create seasonal median composite â€” excellent for change detection training.\n",
    "    dry   = Nov-Apr (clearer skies, best for deforestation detection)\n",
    "    wet   = May-Oct\n",
    "    \"\"\"\n",
    "    if season == 'dry':\n",
    "        start = f'{year}-11-01'\n",
    "        end   = f'{year+1}-04-30'\n",
    "    else:\n",
    "        start = f'{year}-05-01'\n",
    "        end   = f'{year}-10-31'\n",
    "\n",
    "    col = get_s2_collection(roi, start, end)\n",
    "    composite = col.median().clip(roi)\n",
    "    return composite, col.size().getInfo()\n",
    "\n",
    "def create_annual_mosaic(roi, year):\n",
    "    \"\"\"Best-pixel annual mosaic using minimum cloud score.\"\"\"\n",
    "    col = get_s2_collection(roi, f'{year}-01-01', f'{year}-12-31')\n",
    "    # Use median as best-pixel approximation\n",
    "    mosaic = col.median().clip(roi)\n",
    "    return mosaic, col.size().getInfo()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# METADATA TRACKING\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "metadata_records = []\n",
    "\n",
    "def log_export(task_id, description, region_name, start_date, end_date,\n",
    "               image_count, phase, export_type):\n",
    "    metadata_records.append({\n",
    "        'task_id':      task_id,\n",
    "        'description':  description,\n",
    "        'region':       region_name,\n",
    "        'start_date':   start_date,\n",
    "        'end_date':     end_date,\n",
    "        'image_count':  image_count,\n",
    "        'phase':        phase,\n",
    "        'export_type':  export_type,\n",
    "        'timestamp':    datetime.now().isoformat(),\n",
    "        'scale_m':      SCALE_METERS,\n",
    "        'crs':          'EPSG:32644',\n",
    "        'bands':        ','.join(S2_BANDS + ['NDVI','NDWI','NBR','EVI']),\n",
    "    })\n",
    "\n",
    "def save_metadata_csv():\n",
    "    if not metadata_records:\n",
    "        return\n",
    "    csv_path = f\"{OUTPUT_DIR}/metadata/export_log.csv\"\n",
    "    with open(csv_path, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=metadata_records[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(metadata_records)\n",
    "    print(f\"âœ“ Metadata saved: {csv_path}\")\n",
    "\n",
    "def save_task_ids(tasks):\n",
    "    \"\"\"Save all GEE task IDs so you can monitor them.\"\"\"\n",
    "    task_file = f\"{OUTPUT_DIR}/logs/task_ids.json\"\n",
    "    task_data = [{'id': t.id, 'description': t.config['description'],\n",
    "                  'status': t.status()['state']} for t in tasks if t]\n",
    "    with open(task_file, 'w') as f:\n",
    "        json.dump(task_data, f, indent=2)\n",
    "    print(f\"âœ“ Task IDs saved: {task_file}\")\n",
    "    print(f\"  Monitor at: https://code.earthengine.google.com/tasks\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MAIN EXECUTION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"HASDEO FOREST â€” GeoTIFF DOWNLOADER FOR MODEL TRAINING\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Export mode : {EXPORT_MODE.upper()}\")\n",
    "    print(f\"Resolution  : {SCALE_METERS}m\")\n",
    "    print(f\"Cloud cover : <{MAX_CLOUD_COVER}%\")\n",
    "    print(f\"Time periods: {len(TIME_PERIODS)}\")\n",
    "    print(f\"Regions     : {list(REGIONS.keys())}\")\n",
    "    print(f\"Bands       : {S2_BANDS} + NDVI, NDWI, NBR, EVI\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    init_ee()\n",
    "    create_dirs()\n",
    "\n",
    "    all_tasks = []\n",
    "    export_count = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    # â”€â”€ PART 1: Individual scene / period exports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"\\n[ PART 1 ] Exporting per-period composites...\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    for region_name, coords in REGIONS.items():\n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        print(f\"\\nğŸŒ³ Region: {region_name}\")\n",
    "\n",
    "        for start_date, end_date, phase in tqdm(TIME_PERIODS, desc=f\"  {region_name}\"):\n",
    "            try:\n",
    "                col = get_s2_collection(roi, start_date, end_date)\n",
    "                count = col.size().getInfo()\n",
    "\n",
    "                if count < MIN_IMAGES_PER_PERIOD:\n",
    "                    skipped_count += 1\n",
    "                    continue\n",
    "\n",
    "                # Use median composite for the period\n",
    "                composite = col.median().clip(roi)\n",
    "\n",
    "                # Safe description (GEE has 100-char limit, no special chars)\n",
    "                desc = (f\"{region_name}_{start_date[:7]}_{phase[:8]}\"\n",
    "                        .replace('-', '_').replace(' ', '_'))[:90]\n",
    "\n",
    "                if EXPORT_MODE == 'drive':\n",
    "                    task = export_to_drive(composite, desc, roi)\n",
    "                    all_tasks.append(task)\n",
    "                    export_count += 1\n",
    "                    print(f\"    âœ“ Queued: {desc} ({count} scenes)\")\n",
    "\n",
    "                elif EXPORT_MODE == 'gcs':\n",
    "                    if not GCS_BUCKET:\n",
    "                        raise ValueError(\"Set GCS_BUCKET in config for gcs mode\")\n",
    "                    task = export_to_gcs(composite, desc, roi, GCS_BUCKET)\n",
    "                    all_tasks.append(task)\n",
    "                    export_count += 1\n",
    "\n",
    "                elif EXPORT_MODE == 'local_thumb':\n",
    "                    # Quick local download (PNG thumbs for visual QA)\n",
    "                    thumb_path = f\"{OUTPUT_DIR}/exports/{desc}.png\"\n",
    "                    if not os.path.exists(thumb_path):\n",
    "                        success = download_local_thumb(composite, roi, thumb_path)\n",
    "                        if success:\n",
    "                            export_count += 1\n",
    "                    else:\n",
    "                        skipped_count += 1\n",
    "\n",
    "                log_export(\n",
    "                    task_id=all_tasks[-1].id if all_tasks and EXPORT_MODE != 'local_thumb' else 'local',\n",
    "                    description=desc,\n",
    "                    region_name=region_name,\n",
    "                    start_date=start_date,\n",
    "                    end_date=end_date,\n",
    "                    image_count=count,\n",
    "                    phase=phase,\n",
    "                    export_type=EXPORT_MODE\n",
    "                )\n",
    "\n",
    "                time.sleep(0.5)  # Rate limit GEE API calls\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    âœ— Error [{start_date}]: {str(e)[:60]}\")\n",
    "                continue\n",
    "\n",
    "    # â”€â”€ PART 2: Annual mosaics (2013-2025) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"\\n\\n[ PART 2 ] Exporting annual mosaics (best for change detection)...\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    for region_name, coords in REGIONS.items():\n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        print(f\"\\nğŸŒ³ Region: {region_name} â€” Annual Mosaics\")\n",
    "\n",
    "        for year in range(2013, 2026):\n",
    "            try:\n",
    "                mosaic, count = create_annual_mosaic(roi, year)\n",
    "                if count == 0:\n",
    "                    print(f\"  {year}: No data\")\n",
    "                    continue\n",
    "\n",
    "                desc = f\"ANNUAL_{region_name}_{year}\"[:90]\n",
    "\n",
    "                if EXPORT_MODE == 'drive':\n",
    "                    task = export_to_drive(mosaic, desc, roi)\n",
    "                    all_tasks.append(task)\n",
    "                    export_count += 1\n",
    "                    print(f\"  âœ“ {year}: {count} scenes â†’ {desc}\")\n",
    "\n",
    "                elif EXPORT_MODE == 'gcs':\n",
    "                    task = export_to_gcs(mosaic, desc, roi, GCS_BUCKET)\n",
    "                    all_tasks.append(task)\n",
    "                    export_count += 1\n",
    "\n",
    "                elif EXPORT_MODE == 'local_thumb':\n",
    "                    thumb_path = f\"{OUTPUT_DIR}/composites/{desc}.png\"\n",
    "                    download_local_thumb(mosaic, roi, thumb_path)\n",
    "                    export_count += 1\n",
    "\n",
    "                log_export(\n",
    "                    task_id=all_tasks[-1].id if all_tasks and EXPORT_MODE != 'local_thumb' else 'local',\n",
    "                    description=desc,\n",
    "                    region_name=region_name,\n",
    "                    start_date=f'{year}-01-01',\n",
    "                    end_date=f'{year}-12-31',\n",
    "                    image_count=count,\n",
    "                    phase='annual_mosaic',\n",
    "                    export_type=EXPORT_MODE\n",
    "                )\n",
    "\n",
    "                time.sleep(0.5)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  âœ— {year}: {str(e)[:60]}\")\n",
    "\n",
    "    # â”€â”€ PART 3: Seasonal dry-season composites â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"\\n\\n[ PART 3 ] Dry-season composites (Nov-Apr, clearest images)...\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    for region_name, coords in REGIONS.items():\n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        for year in range(2013, 2025):\n",
    "            try:\n",
    "                composite, count = create_seasonal_composite(roi, year, 'dry')\n",
    "                if count == 0:\n",
    "                    continue\n",
    "\n",
    "                desc = f\"DRY_{region_name}_{year}_{year+1}\"[:90]\n",
    "\n",
    "                if EXPORT_MODE == 'drive':\n",
    "                    task = export_to_drive(composite, desc, roi)\n",
    "                    all_tasks.append(task)\n",
    "                    export_count += 1\n",
    "                    print(f\"  âœ“ Dry {year}-{year+1}: {count} scenes\")\n",
    "\n",
    "                elif EXPORT_MODE == 'gcs':\n",
    "                    task = export_to_gcs(composite, desc, roi, GCS_BUCKET)\n",
    "                    all_tasks.append(task)\n",
    "                    export_count += 1\n",
    "\n",
    "                log_export(\n",
    "                    task_id=all_tasks[-1].id if all_tasks and EXPORT_MODE != 'local_thumb' else 'local',\n",
    "                    description=desc,\n",
    "                    region_name=region_name,\n",
    "                    start_date=f'{year}-11-01',\n",
    "                    end_date=f'{year+1}-04-30',\n",
    "                    image_count=count,\n",
    "                    phase='dry_season_composite',\n",
    "                    export_type=EXPORT_MODE\n",
    "                )\n",
    "\n",
    "                time.sleep(0.5)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  âœ— Dry {year}: {str(e)[:50]}\")\n",
    "\n",
    "    # â”€â”€ SUMMARY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"EXPORT SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"âœ“ Exports queued : {export_count}\")\n",
    "    print(f\"âŠ™ Skipped        : {skipped_count} (no data in period)\")\n",
    "    print(f\"ğŸ“Š Total periods  : {len(TIME_PERIODS)} Ã— {len(REGIONS)} regions\")\n",
    "    print()\n",
    "\n",
    "    if EXPORT_MODE == 'drive':\n",
    "        print(\"ğŸ“ Files will appear in Google Drive â†’ 'Hasdeo_Training_Dataset' folder\")\n",
    "        print(\"â±  Large exports may take 10 min â€“ several hours depending on size\")\n",
    "        print(\"ğŸ”— Monitor tasks at: https://code.earthengine.google.com/tasks\")\n",
    "        save_task_ids(all_tasks)\n",
    "    elif EXPORT_MODE == 'gcs':\n",
    "        print(f\"ğŸ“ Files uploading to gs://{GCS_BUCKET}/hasdeo/\")\n",
    "        save_task_ids(all_tasks)\n",
    "    else:\n",
    "        print(f\"ğŸ“ PNG thumbnails saved to: {OUTPUT_DIR}/exports/\")\n",
    "\n",
    "    save_metadata_csv()\n",
    "\n",
    "    print()\n",
    "    print(\"DATASET STRUCTURE:\")\n",
    "    print(f\"  â€¢ Per-period composites : ~{len(TIME_PERIODS) * len(REGIONS)} images\")\n",
    "    print(f\"  â€¢ Annual mosaics        : ~{13 * len(REGIONS)} images (2013-2025)\")\n",
    "    print(f\"  â€¢ Dry-season composites : ~{12 * len(REGIONS)} images\")\n",
    "    print(f\"  â€¢ Bands per image       : B2,B3,B4,B8,B8A,B11,B12,SCL + NDVI,NDWI,NBR,EVI\")\n",
    "    print(f\"  â€¢ Format                : Cloud-Optimized GeoTIFF (COG), EPSG:32644\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ac0a10f-c13e-4813-b00f-11209f893138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Earth Engine initialized for project: glacier-probe-model-475519\n",
      "======================================================================\n",
      "HASDEO FOREST IMAGE DOWNLOADER - RGB VIEWABLE VERSION\n",
      "Targeting Central Hasdeo Region: [82.75, 22.95, 82.85, 23.05]\n",
      "======================================================================\n",
      "âœ“ Created output directories in hasdeo_forest_dataset_rgb/\n",
      "\n",
      "Target: 50 images (Max Cloud Cover: 30%)\n",
      "Time periods: 7\n",
      "Resolution: 30m | Format: PNG (Viewable RGB)\n",
      "\n",
      "ğŸŒ³ Starting Downloads for: Hasdeo_Arand_Zoomed\n",
      "----------------------------------------------------------------------\n",
      "  2018: 11 images available\n",
      "    â†“ 2018-01-21... âœ“ (1/50)\n",
      "    â†“ 2018-01-31... âœ“ (2/50)\n",
      "    â†“ 2018-02-15... âœ“ (3/50)\n",
      "    â†“ 2018-03-07... âœ“ (4/50)\n",
      "    â†“ 2018-03-12... âœ“ (5/50)\n",
      "    â†“ 2018-04-21... âœ“ (6/50)\n",
      "    â†“ 2018-11-07... âœ“ (7/50)\n",
      "    â†“ 2018-11-17... âœ“ (8/50)\n",
      "    â†“ 2018-12-07... âœ“ (9/50)\n",
      "    â†“ 2018-12-22... âœ“ (10/50)\n",
      "  2019: 41 images available\n",
      "    â†“ 2019-01-01... âœ“ (11/50)\n",
      "    â†“ 2019-01-06... âœ“ (12/50)\n",
      "    â†“ 2019-01-11... âœ“ (13/50)\n",
      "    â†“ 2019-01-16... âœ“ (14/50)\n",
      "    â†“ 2019-01-21... âœ“ (15/50)\n",
      "    â†“ 2019-01-31... âœ“ (16/50)\n",
      "    â†“ 2019-02-05... âœ“ (17/50)\n",
      "    â†“ 2019-02-10... âœ“ (18/50)\n",
      "    â†“ 2019-02-20... âœ“ (19/50)\n",
      "    â†“ 2019-03-02... âœ“ (20/50)\n",
      "  2020: 34 images available\n",
      "    â†“ 2020-01-06... âœ“ (21/50)\n",
      "    â†“ 2020-01-11... âœ“ (22/50)\n",
      "    â†“ 2020-01-16... âœ“ (23/50)\n",
      "    â†“ 2020-01-21... âœ“ (24/50)\n",
      "    â†“ 2020-01-26... âœ“ (25/50)\n",
      "    â†“ 2020-01-31... âœ“ (26/50)\n",
      "    â†“ 2020-02-10... âœ“ (27/50)\n",
      "    â†“ 2020-02-15... âœ“ (28/50)\n",
      "    â†“ 2020-03-01... âœ“ (29/50)\n",
      "    â†“ 2020-03-16... âœ“ (30/50)\n",
      "  2021: 40 images available\n",
      "    â†“ 2021-01-05... âœ“ (31/50)\n",
      "    â†“ 2021-01-10... âœ“ (32/50)\n",
      "    â†“ 2021-01-15... âœ“ (33/50)\n",
      "    â†“ 2021-01-20... âœ“ (34/50)\n",
      "    â†“ 2021-01-25... âœ“ (35/50)\n",
      "    â†“ 2021-01-30... âœ“ (36/50)\n",
      "    â†“ 2021-02-04... âœ“ (37/50)\n",
      "    â†“ 2021-02-09... âœ“ (38/50)\n",
      "    â†“ 2021-02-14... âœ“ (39/50)\n",
      "    â†“ 2021-02-24... âœ“ (40/50)\n",
      "  2022: 40 images available\n",
      "    â†“ 2022-01-05... âœ“ (41/50)\n",
      "    â†“ 2022-01-10... âœ“ (42/50)\n",
      "    â†“ 2022-01-20... âœ“ (43/50)\n",
      "    â†“ 2022-01-30... âœ“ (44/50)\n",
      "    â†“ 2022-02-04... âœ“ (45/50)\n",
      "    â†“ 2022-02-14... âœ“ (46/50)\n",
      "    â†“ 2022-02-19... âœ“ (47/50)\n",
      "    â†“ 2022-02-24... âœ“ (48/50)\n",
      "    â†“ 2022-03-01... âœ“ (49/50)\n",
      "    â†“ 2022-03-06... âœ“ (50/50)\n",
      "\n",
      "======================================================================\n",
      "DOWNLOAD COMPLETE\n",
      "======================================================================\n",
      "âœ“ Downloaded: 50 images\n",
      "âœ— Failed: 0\n",
      "ğŸ“ Location: hasdeo_forest_dataset_rgb/rgb_images/\n",
      "\n",
      "âœ“ Images are in standard PNG format and viewable!\n",
      "You can open them with any image viewer or photo app.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hasdeo Forest RGB Image Downloader - VIEWABLE VERSION\n",
    "Downloads RGB satellite imagery for Hasdeo Arand in standard viewable format.\n",
    "Images are saved as PNG with proper color scaling for visualization.\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "PROJECT_ID = 'glacier-probe-model-475519'\n",
    "OUTPUT_DIR = 'hasdeo_forest_dataset_rgb'\n",
    "NUM_IMAGES = 50  \n",
    "SCALE = 30  # 30m resolution for manageable file sizes\n",
    "MAX_CLOUD_COVER = 30  # Reduced for better quality images\n",
    "\n",
    "# Hasdeo Forest Area of Interest\n",
    "# Coordinates: [lon_min, lat_min, lon_max, lat_max]\n",
    "HASDEO_REGION = {\n",
    "    'Hasdeo_Arand_Zoomed': [82.75, 22.95, 82.85, 23.05]\n",
    "}\n",
    "\n",
    "# Year ranges for sampling\n",
    "YEAR_RANGES = [\n",
    "    ('2018-01-01', '2019-01-01'),\n",
    "    ('2019-01-01', '2020-01-01'),\n",
    "    ('2020-01-01', '2021-01-01'),\n",
    "    ('2021-01-01', '2022-01-01'),\n",
    "    ('2022-01-01', '2023-01-01'),\n",
    "    ('2023-01-01', '2024-01-01'),\n",
    "    ('2024-01-01', '2025-01-01'),\n",
    "]\n",
    "\n",
    "# --- INITIALIZATION ---\n",
    "\n",
    "try:\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"âœ“ Earth Engine initialized for project: {PROJECT_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  Initialization failed. Attempting authentication...\")\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"âœ“ Authentication successful. Earth Engine initialized.\")\n",
    "\n",
    "# --- UTILITY FUNCTIONS ---\n",
    "\n",
    "def create_output_dirs():\n",
    "    \"\"\"Create output directory structure\"\"\"\n",
    "    Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/rgb_images\").mkdir(exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/metadata\").mkdir(exist_ok=True)\n",
    "    print(f\"âœ“ Created output directories in {OUTPUT_DIR}/\")\n",
    "\n",
    "def get_satellite_collection(start_date, end_date, roi, max_cloud_cover):\n",
    "    \"\"\"Get Sentinel-2 collection with cloud filtering\"\"\"\n",
    "    # Sentinel-2 Surface Reflectance with cloud masking\n",
    "    def maskS2clouds(image):\n",
    "        qa = image.select('QA60')\n",
    "        # Bits 10 and 11 are clouds and cirrus\n",
    "        cloudBitMask = 1 << 10\n",
    "        cirrusBitMask = 1 << 11\n",
    "        mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(\n",
    "            qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "        return image.updateMask(mask)\n",
    "    \n",
    "    sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "        .filterBounds(roi) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover)) \\\n",
    "        .map(maskS2clouds)\n",
    "\n",
    "    s2_count = sentinel2.size().getInfo()\n",
    "    \n",
    "    if s2_count > 0:\n",
    "        return sentinel2, 'sentinel2'\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def download_rgb_image(image, region, filename):\n",
    "    \"\"\"Downloads RGB image in viewable PNG format\"\"\"\n",
    "    try:\n",
    "        # Select RGB bands (B4=Red, B3=Green, B2=Blue)\n",
    "        rgb = image.select(['B4', 'B3', 'B2'])\n",
    "        \n",
    "        # Normalize to 0-255 range for viewing\n",
    "        # Sentinel-2 values are 0-10000, we'll use 0-3000 as typical range\n",
    "        rgb_vis = rgb.visualize(\n",
    "            min=0,\n",
    "            max=3000,\n",
    "            bands=['B4', 'B3', 'B2']\n",
    "        )\n",
    "        \n",
    "        # Get thumbnail URL (this returns a viewable image)\n",
    "        url = rgb_vis.getThumbURL({\n",
    "            'region': region,\n",
    "            'dimensions': 1024,  # 1024x1024 pixels\n",
    "            'format': 'png'\n",
    "        })\n",
    "        \n",
    "        # Download and save as PNG\n",
    "        response = requests.get(url, timeout=300)\n",
    "        if response.status_code == 200:\n",
    "            # Save directly as PNG\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âœ— HTTP Error {response.status_code}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"âœ— Error: {error_msg[:100]}...\")\n",
    "        return False\n",
    "\n",
    "def save_metadata(image, filename, region_name):\n",
    "    \"\"\"Save image metadata\"\"\"\n",
    "    try:\n",
    "        props = image.getInfo()['properties']\n",
    "        metadata_file = filename\n",
    "        \n",
    "        with open(metadata_file, 'w') as f:\n",
    "            f.write(f\"Region: {region_name}\\n\")\n",
    "            f.write(f\"Satellite: SENTINEL-2\\n\")\n",
    "            f.write(f\"Image Type: RGB (True Color)\\n\")\n",
    "            f.write(f\"Format: PNG (Viewable)\\n\")\n",
    "            \n",
    "            date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "            f.write(f\"Date: {date}\\n\")\n",
    "            f.write(f\"Cloud Cover: {props.get('CLOUDY_PIXEL_PERCENTAGE', 'N/A')}%\\n\")\n",
    "            f.write(f\"Product ID: {props.get('PRODUCT_ID', 'N/A')}\\n\")\n",
    "            f.write(f\"Bands: R=B4 (Red), G=B3 (Green), B=B2 (Blue)\\n\")\n",
    "            f.write(f\"Resolution: {SCALE}m\\n\")\n",
    "            f.write(f\"Processing: Cloud-masked, normalized to 0-255\\n\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  âš  Metadata warning: {str(e)[:30]}\")\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "def main_hasdeo():\n",
    "    \"\"\"Main download function for Hasdeo Forest\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"HASDEO FOREST IMAGE DOWNLOADER - RGB VIEWABLE VERSION\")\n",
    "    print(f\"Targeting Central Hasdeo Region: {HASDEO_REGION['Hasdeo_Arand_Zoomed']}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    create_output_dirs()\n",
    "    \n",
    "    downloaded_count = 0\n",
    "    failed_count = 0\n",
    "    \n",
    "    print(f\"\\nTarget: {NUM_IMAGES} images (Max Cloud Cover: {MAX_CLOUD_COVER}%)\")\n",
    "    print(f\"Time periods: {len(YEAR_RANGES)}\")\n",
    "    print(f\"Resolution: {SCALE}m | Format: PNG (Viewable RGB)\\n\")\n",
    "    \n",
    "    region_name = 'Hasdeo_Arand_Zoomed'\n",
    "    coords = HASDEO_REGION[region_name]\n",
    "    roi = ee.Geometry.Rectangle(coords)\n",
    "\n",
    "    print(f\"ğŸŒ³ Starting Downloads for: {region_name}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Iterate through each year range\n",
    "    for start_date, end_date in YEAR_RANGES:\n",
    "        if downloaded_count >= NUM_IMAGES:\n",
    "            break\n",
    "        \n",
    "        # Get the satellite collection for the year\n",
    "        collection, satellite_type = get_satellite_collection(start_date, end_date, roi, MAX_CLOUD_COVER)\n",
    "        \n",
    "        if collection is None:\n",
    "            print(f\"  {start_date[:4]}: 0 images found\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            count = collection.size().getInfo()\n",
    "            if count == 0:\n",
    "                print(f\"  {start_date[:4]}: 0 images found\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"  {start_date[:4]}: {count} images available\")\n",
    "            \n",
    "            # Limit download per year\n",
    "            images_to_download = min(10, count, NUM_IMAGES - downloaded_count)\n",
    "            if images_to_download <= 0:\n",
    "                break\n",
    "                \n",
    "            images = collection.limit(images_to_download).toList(images_to_download)\n",
    "            \n",
    "            for i in range(images_to_download):\n",
    "                if downloaded_count >= NUM_IMAGES:\n",
    "                    break\n",
    "                    \n",
    "                image = ee.Image(images.get(i))\n",
    "                \n",
    "                # Get date\n",
    "                date_acquired = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "                \n",
    "                # Filename construction (PNG format)\n",
    "                filename = f\"{OUTPUT_DIR}/rgb_images/{region_name}_{date_acquired}_RGB.png\"\n",
    "                metadata_filename = f\"{OUTPUT_DIR}/metadata/{region_name}_{date_acquired}_metadata.txt\"\n",
    "                \n",
    "                # Skip if exists\n",
    "                if os.path.exists(filename):\n",
    "                    downloaded_count += 1\n",
    "                    print(f\"    âŠ™ {date_acquired} (exists)\")\n",
    "                    continue\n",
    "                \n",
    "                print(f\"    â†“ {date_acquired}...\", end=' ')\n",
    "                \n",
    "                if download_rgb_image(image, roi, filename):\n",
    "                    save_metadata(image, metadata_filename, region_name)\n",
    "                    downloaded_count += 1\n",
    "                    print(f\"âœ“ ({downloaded_count}/{NUM_IMAGES})\")\n",
    "                else:\n",
    "                    failed_count += 1\n",
    "                \n",
    "                time.sleep(2)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— Error in collection processing: {str(e)[:50]}...\")\n",
    "            continue\n",
    "            \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"DOWNLOAD COMPLETE\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"âœ“ Downloaded: {downloaded_count} images\")\n",
    "    print(f\"âœ— Failed: {failed_count}\")\n",
    "    print(f\"ğŸ“ Location: {OUTPUT_DIR}/rgb_images/\")\n",
    "    print(\"\\nâœ“ Images are in standard PNG format and viewable!\")\n",
    "    print(\"You can open them with any image viewer or photo app.\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_hasdeo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d14f471-c7a1-4308-a868-23338b1a726b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Kangaroo Island Black Summer Bushfire Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdc9e7e9-4202-4a65-9f0c-1530cd2fb5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Earth Engine initialized for project: glacier-probe-model-475519\n",
      "================================================================================\n",
      "KANGAROO ISLAND BLACK SUMMER BUSHFIRE IMAGE DOWNLOADER\n",
      "Coordinates: [136.5344, -36.0867, 138.0, -35.5614]\n",
      "Fire Period: December 20, 2019 - February 6, 2020\n",
      "Coverage: 5 years pre-fire (2014-2019) + fire period + 5 years post-fire (2020-2024)\n",
      "================================================================================\n",
      "âœ“ Created output directories in kangaroo_island_black_summer/\n",
      "\n",
      "Target: 100 images (Max Cloud Cover: 100%)\n",
      "Time periods: 12\n",
      "Resolution: 30m | Format: PNG (Viewable RGB)\n",
      "\n",
      "ğŸ”¥ Starting Downloads for: Kangaroo Island Black Summer\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE (2014): 0 images found\n",
      "  PRE-FIRE (2015): 0 images found\n",
      "  PRE-FIRE (2016): 0 images found\n",
      "  PRE-FIRE (2017): 4 images available\n",
      "    â†“ 2017-03-08... âœ“ (1/100)\n",
      "    â†“ 2017-07-21... âœ“ (2/100)\n",
      "    âŠ™ 2017-07-21 (exists)\n",
      "    â†“ 2017-12-26... âœ“ (4/100)\n",
      "  PRE-FIRE (2018): 28 images available\n",
      "    â†“ 2018-02-06... âœ“ (5/100)\n",
      "    âŠ™ 2018-02-06 (exists)\n",
      "    â†“ 2018-02-26... âœ“ (7/100)\n",
      "    âŠ™ 2018-02-26 (exists)\n",
      "    â†“ 2018-03-16... âœ“ (9/100)\n",
      "    â†“ 2018-03-31... âœ“ (10/100)\n",
      "    âŠ™ 2018-03-31 (exists)\n",
      "    â†“ 2018-04-07... âœ“ (12/100)\n",
      "  2019: 346 images available\n",
      "    â†“ 2019-01-02... âœ“ (13/100)\n",
      "    âŠ™ 2019-01-02 (exists)\n",
      "    â†“ 2019-01-05... âœ“ (15/100)\n",
      "    âŠ™ 2019-01-05 (exists)\n",
      "    âŠ™ 2019-01-05 (exists)\n",
      "    â†“ 2019-01-07... âœ“ (18/100)\n",
      "    âŠ™ 2019-01-07 (exists)\n",
      "    â†“ 2019-01-10... âœ“ (20/100)\n",
      "  DURING FIRE (Dec 20, 2019 - Feb 6, 2020): 50 images available\n",
      "    â†“ 2019-12-21... âœ“ (21/100)\n",
      "    âŠ™ 2019-12-21 (exists)\n",
      "    âŠ™ 2019-12-21 (exists)\n",
      "    â†“ 2019-12-23... âœ“ (24/100)\n",
      "    âŠ™ 2019-12-23 (exists)\n",
      "    â†“ 2019-12-26... âœ“ (26/100)\n",
      "    âŠ™ 2019-12-26 (exists)\n",
      "    âŠ™ 2019-12-26 (exists)\n",
      "    â†“ 2019-12-28... âœ“ (29/100)\n",
      "    âŠ™ 2019-12-28 (exists)\n",
      "    â†“ 2019-12-31... âœ“ (31/100)\n",
      "    âŠ™ 2019-12-31 (exists)\n",
      "    âŠ™ 2019-12-31 (exists)\n",
      "    â†“ 2020-01-02... âœ“ (34/100)\n",
      "    âŠ™ 2020-01-02 (exists)\n",
      "    â†“ 2020-01-05... âœ“ (36/100)\n",
      "    âŠ™ 2020-01-05 (exists)\n",
      "    â†“ 2020-01-07... âœ“ (38/100)\n",
      "    âŠ™ 2020-01-07 (exists)\n",
      "    â†“ 2020-01-10... âœ“ (40/100)\n",
      "  POST-FIRE RECOVERY (+0 years - 2020): 321 images available\n",
      "    â†“ 2020-02-09... âœ“ (41/100)\n",
      "    âŠ™ 2020-02-09 (exists)\n",
      "    âŠ™ 2020-02-09 (exists)\n",
      "    â†“ 2020-02-11... âœ“ (44/100)\n",
      "    âŠ™ 2020-02-11 (exists)\n",
      "    â†“ 2020-02-14... âœ“ (46/100)\n",
      "    âŠ™ 2020-02-14 (exists)\n",
      "    âŠ™ 2020-02-14 (exists)\n",
      "  POST-FIRE RECOVERY (+1 years - 2021): 367 images available\n",
      "    â†“ 2021-01-01... âœ“ (49/100)\n",
      "    âŠ™ 2021-01-01 (exists)\n",
      "    â†“ 2021-01-04... âœ“ (51/100)\n",
      "    âŠ™ 2021-01-04 (exists)\n",
      "    âŠ™ 2021-01-04 (exists)\n",
      "    â†“ 2021-01-06... âœ“ (54/100)\n",
      "    âŠ™ 2021-01-06 (exists)\n",
      "    â†“ 2021-01-09... âœ“ (56/100)\n",
      "  POST-FIRE RECOVERY (+2 years - 2022): 355 images available\n",
      "    â†“ 2022-01-01... âœ“ (57/100)\n",
      "    âŠ™ 2022-01-01 (exists)\n",
      "    â†“ 2022-01-04... âœ“ (59/100)\n",
      "    âŠ™ 2022-01-04 (exists)\n",
      "    âŠ™ 2022-01-04 (exists)\n",
      "    â†“ 2022-01-06... âœ“ (62/100)\n",
      "    âŠ™ 2022-01-06 (exists)\n",
      "    â†“ 2022-01-09... âœ“ (64/100)\n",
      "  POST-FIRE RECOVERY (+3 years - 2023): 365 images available\n",
      "    â†“ 2023-01-01... âœ“ (65/100)\n",
      "    âŠ™ 2023-01-01 (exists)\n",
      "    â†“ 2023-01-04... âœ“ (67/100)\n",
      "    âŠ™ 2023-01-04 (exists)\n",
      "    âŠ™ 2023-01-04 (exists)\n",
      "    â†“ 2023-01-06... âœ“ (70/100)\n",
      "    âŠ™ 2023-01-06 (exists)\n",
      "    â†“ 2023-01-09... âœ“ (72/100)\n",
      "  POST-FIRE RECOVERY (+4 years - 2024): 371 images available\n",
      "    â†“ 2024-01-01... âœ“ (73/100)\n",
      "    âŠ™ 2024-01-01 (exists)\n",
      "    â†“ 2024-01-04... âœ“ (75/100)\n",
      "    âŠ™ 2024-01-04 (exists)\n",
      "    âŠ™ 2024-01-04 (exists)\n",
      "    â†“ 2024-01-09... âœ“ (78/100)\n",
      "    âŠ™ 2024-01-09 (exists)\n",
      "    âŠ™ 2024-01-09 (exists)\n",
      "\n",
      "================================================================================\n",
      "DOWNLOAD COMPLETE - KANGAROO ISLAND BLACK SUMMER DATASET\n",
      "================================================================================\n",
      "âœ“ Downloaded: 80 images\n",
      "âœ— Failed: 0\n",
      "ğŸ“ Location: kangaroo_island_black_summer/rgb_images/\n",
      "\n",
      "ğŸ“Š Dataset Coverage:\n",
      "   â€¢ Pre-fire baseline: 2014-2019 (5 years)\n",
      "   â€¢ Active fire period: Dec 20, 2019 - Feb 6, 2020\n",
      "   â€¢ Post-fire recovery: 2020-2024 (5 years)\n",
      "   â€¢ Area burned: ~211,500 hectares (48% of island)\n",
      "\n",
      "âœ“ Images are in standard PNG format and viewable!\n",
      "You can open them with any image viewer or photo app.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Kangaroo Island Black Summer Bushfire Image Downloader\n",
    "Downloads RGB satellite imagery for Kangaroo Island, South Australia\n",
    "Covering the 2019-20 Black Summer bushfire period and recovery\n",
    "Images are saved as PNG with proper color scaling for visualization.\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "PROJECT_ID = 'glacier-probe-model-475519'\n",
    "OUTPUT_DIR = 'kangaroo_island_black_summer'\n",
    "NUM_IMAGES = 100  # More images to capture pre-fire, during, and post-fire periods\n",
    "SCALE = 30  # 30m resolution for manageable file sizes\n",
    "MAX_CLOUD_COVER = 100  # Allow ALL images including heavy smoke/clouds\n",
    "\n",
    "# Kangaroo Island Area of Interest - Black Summer Fire Zone\n",
    "# Coordinates converted from DMS to decimal degrees:\n",
    "# Latitude: 35Â°33'41\"S to 36Â°05'12\"S = -35.5614 to -36.0867\n",
    "# Longitude: 136Â°32'04\"E to 138Â°00'00\"E = 136.5344 to 138.0000\n",
    "KANGAROO_ISLAND_REGION = {\n",
    "    'Kangaroo_Island_Fire_Zone': [136.5344, -36.0867, 138.0000, -35.5614]\n",
    "}\n",
    "\n",
    "# Black Summer bushfires on Kangaroo Island:\n",
    "# - Started: December 20, 2019 (lightning strikes)\n",
    "# - Major fires: December 30, 2019 - February 6, 2020\n",
    "# - Declared safe: February 6, 2020\n",
    "# Year ranges: 5 years before (2014-2019) and 5 years after (2020-2025)\n",
    "YEAR_RANGES = [\n",
    "    # Pre-fire period (5 years before)\n",
    "    ('2014-01-01', '2014-12-31'),\n",
    "    ('2015-01-01', '2015-12-31'),\n",
    "    ('2016-01-01', '2016-12-31'),\n",
    "    ('2017-01-01', '2017-12-31'),\n",
    "    ('2018-01-01', '2018-12-31'),\n",
    "    # Critical fire year\n",
    "    ('2019-01-01', '2019-12-19'),  # Pre-fire 2019\n",
    "    ('2019-12-20', '2020-02-06'),  # During fire (Dec 20, 2019 - Feb 6, 2020)\n",
    "    ('2020-02-07', '2020-12-31'),  # Post-fire recovery 2020\n",
    "    # Post-fire recovery period (4 more years)\n",
    "    ('2021-01-01', '2021-12-31'),\n",
    "    ('2022-01-01', '2022-12-31'),\n",
    "    ('2023-01-01', '2023-12-31'),\n",
    "    ('2024-01-01', '2024-12-31'),\n",
    "]\n",
    "\n",
    "# --- INITIALIZATION ---\n",
    "\n",
    "try:\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"âœ“ Earth Engine initialized for project: {PROJECT_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  Initialization failed. Attempting authentication...\")\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"âœ“ Authentication successful. Earth Engine initialized.\")\n",
    "\n",
    "# --- UTILITY FUNCTIONS ---\n",
    "\n",
    "def create_output_dirs():\n",
    "    \"\"\"Create output directory structure\"\"\"\n",
    "    Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/rgb_images\").mkdir(exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/metadata\").mkdir(exist_ok=True)\n",
    "    print(f\"âœ“ Created output directories in {OUTPUT_DIR}/\")\n",
    "\n",
    "def get_satellite_collection(start_date, end_date, roi, max_cloud_cover):\n",
    "    \"\"\"Get Sentinel-2 collection WITHOUT cloud masking to preserve smoke/fire effects\"\"\"\n",
    "    # NO CLOUD MASKING - We want to see smoke, clouds, and fire effects!\n",
    "    sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "        .filterBounds(roi) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover))\n",
    "\n",
    "    s2_count = sentinel2.size().getInfo()\n",
    "    \n",
    "    if s2_count > 0:\n",
    "        return sentinel2, 'sentinel2'\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def download_rgb_image(image, region, filename):\n",
    "    \"\"\"Downloads RGB image in viewable PNG format\"\"\"\n",
    "    try:\n",
    "        # Select RGB bands (B4=Red, B3=Green, B2=Blue)\n",
    "        rgb = image.select(['B4', 'B3', 'B2'])\n",
    "        \n",
    "        # Normalize to 0-255 range for viewing\n",
    "        # Sentinel-2 values are 0-10000, we'll use 0-3000 as typical range\n",
    "        rgb_vis = rgb.visualize(\n",
    "            min=0,\n",
    "            max=3000,\n",
    "            bands=['B4', 'B3', 'B2']\n",
    "        )\n",
    "        \n",
    "        # Get thumbnail URL (this returns a viewable image)\n",
    "        url = rgb_vis.getThumbURL({\n",
    "            'region': region,\n",
    "            'dimensions': 2048,  # Higher resolution for large area (2048x2048)\n",
    "            'format': 'png'\n",
    "        })\n",
    "        \n",
    "        # Download and save as PNG\n",
    "        response = requests.get(url, timeout=300)\n",
    "        if response.status_code == 200:\n",
    "            # Save directly as PNG\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âœ— HTTP Error {response.status_code}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"âœ— Error: {error_msg[:100]}...\")\n",
    "        return False\n",
    "\n",
    "def save_metadata(image, filename, region_name, period_label):\n",
    "    \"\"\"Save image metadata\"\"\"\n",
    "    try:\n",
    "        props = image.getInfo()['properties']\n",
    "        metadata_file = filename\n",
    "        \n",
    "        with open(metadata_file, 'w') as f:\n",
    "            f.write(f\"Region: {region_name}\\n\")\n",
    "            f.write(f\"Location: Kangaroo Island, South Australia\\n\")\n",
    "            f.write(f\"Event: Black Summer Bushfires (2019-20)\\n\")\n",
    "            f.write(f\"Period: {period_label}\\n\")\n",
    "            f.write(f\"Satellite: SENTINEL-2\\n\")\n",
    "            f.write(f\"Image Type: RGB (True Color)\\n\")\n",
    "            f.write(f\"Format: PNG (Viewable)\\n\")\n",
    "            \n",
    "            date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "            f.write(f\"Date: {date}\\n\")\n",
    "            f.write(f\"Cloud Cover: {props.get('CLOUDY_PIXEL_PERCENTAGE', 'N/A')}%\\n\")\n",
    "            f.write(f\"Product ID: {props.get('PRODUCT_ID', 'N/A')}\\n\")\n",
    "            f.write(f\"Bands: R=B4 (Red), G=B3 (Green), B=B2 (Blue)\\n\")\n",
    "            f.write(f\"Resolution: {SCALE}m\\n\")\n",
    "            f.write(f\"Processing: NO cloud masking - smoke and fire effects preserved\\n\")\n",
    "            f.write(f\"\\nContext: Area burned ~211,500 ha (48% of island)\\n\")\n",
    "            f.write(f\"Fire Period: Dec 20, 2019 - Feb 6, 2020\\n\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  âš  Metadata warning: {str(e)[:30]}\")\n",
    "\n",
    "def get_period_label(start_date, end_date):\n",
    "    \"\"\"Get descriptive label for the time period\"\"\"\n",
    "    if '2019-12-20' in start_date and '2020-02-06' in end_date:\n",
    "        return \"DURING FIRE (Dec 20, 2019 - Feb 6, 2020)\"\n",
    "    elif int(start_date[:4]) < 2019 or (start_date[:4] == '2019' and '12-19' in start_date):\n",
    "        return f\"PRE-FIRE ({start_date[:4]})\"\n",
    "    elif int(start_date[:4]) >= 2020:\n",
    "        years_after = int(start_date[:4]) - 2020\n",
    "        return f\"POST-FIRE RECOVERY (+{years_after} years - {start_date[:4]})\"\n",
    "    return start_date[:4]\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "def main_kangaroo_island():\n",
    "    \"\"\"Main download function for Kangaroo Island Black Summer\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"KANGAROO ISLAND BLACK SUMMER BUSHFIRE IMAGE DOWNLOADER\")\n",
    "    print(f\"Coordinates: {KANGAROO_ISLAND_REGION['Kangaroo_Island_Fire_Zone']}\")\n",
    "    print(\"Fire Period: December 20, 2019 - February 6, 2020\")\n",
    "    print(\"Coverage: 5 years pre-fire (2014-2019) + fire period + 5 years post-fire (2020-2024)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    create_output_dirs()\n",
    "    \n",
    "    downloaded_count = 0\n",
    "    failed_count = 0\n",
    "    \n",
    "    print(f\"\\nTarget: {NUM_IMAGES} images (Max Cloud Cover: {MAX_CLOUD_COVER}%)\")\n",
    "    print(f\"Time periods: {len(YEAR_RANGES)}\")\n",
    "    print(f\"Resolution: {SCALE}m | Format: PNG (Viewable RGB)\\n\")\n",
    "    \n",
    "    region_name = 'Kangaroo_Island_Fire_Zone'\n",
    "    coords = KANGAROO_ISLAND_REGION[region_name]\n",
    "    roi = ee.Geometry.Rectangle(coords)\n",
    "\n",
    "    print(f\" Starting Downloads for: Kangaroo Island Black Summer\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Iterate through each year range\n",
    "    for start_date, end_date in YEAR_RANGES:\n",
    "        if downloaded_count >= NUM_IMAGES:\n",
    "            break\n",
    "        \n",
    "        period_label = get_period_label(start_date, end_date)\n",
    "        \n",
    "        # Get the satellite collection for the period\n",
    "        collection, satellite_type = get_satellite_collection(start_date, end_date, roi, MAX_CLOUD_COVER)\n",
    "        \n",
    "        if collection is None:\n",
    "            print(f\"  {period_label}: 0 images found\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            count = collection.size().getInfo()\n",
    "            if count == 0:\n",
    "                print(f\"  {period_label}: 0 images found\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"  {period_label}: {count} images available\")\n",
    "            \n",
    "            # Adjust number of images per period\n",
    "            # More images during fire period, fewer for other years\n",
    "            if 'DURING FIRE' in period_label:\n",
    "                images_per_period = min(20, count, NUM_IMAGES - downloaded_count)\n",
    "            else:\n",
    "                images_per_period = min(8, count, NUM_IMAGES - downloaded_count)\n",
    "                \n",
    "            if images_per_period <= 0:\n",
    "                break\n",
    "                \n",
    "            images = collection.limit(images_per_period).toList(images_per_period)\n",
    "            \n",
    "            for i in range(images_per_period):\n",
    "                if downloaded_count >= NUM_IMAGES:\n",
    "                    break\n",
    "                    \n",
    "                image = ee.Image(images.get(i))\n",
    "                \n",
    "                # Get date\n",
    "                date_acquired = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "                \n",
    "                # Filename construction (PNG format)\n",
    "                period_prefix = period_label.split('(')[0].strip().replace(' ', '_').replace('-', '')\n",
    "                filename = f\"{OUTPUT_DIR}/rgb_images/KI_{date_acquired}_{period_prefix}_RGB.png\"\n",
    "                metadata_filename = f\"{OUTPUT_DIR}/metadata/KI_{date_acquired}_{period_prefix}_metadata.txt\"\n",
    "                \n",
    "                # Skip if exists\n",
    "                if os.path.exists(filename):\n",
    "                    downloaded_count += 1\n",
    "                    print(f\"    âŠ™ {date_acquired} (exists)\")\n",
    "                    continue\n",
    "                \n",
    "                print(f\"    â†“ {date_acquired}...\", end=' ')\n",
    "                \n",
    "                if download_rgb_image(image, roi, filename):\n",
    "                    save_metadata(image, metadata_filename, region_name, period_label)\n",
    "                    downloaded_count += 1\n",
    "                    print(f\"âœ“ ({downloaded_count}/{NUM_IMAGES})\")\n",
    "                else:\n",
    "                    failed_count += 1\n",
    "                \n",
    "                time.sleep(2)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— Error in collection processing: {str(e)[:50]}...\")\n",
    "            continue\n",
    "            \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DOWNLOAD COMPLETE - KANGAROO ISLAND BLACK SUMMER DATASET\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"âœ“ Downloaded: {downloaded_count} images\")\n",
    "    print(f\"âœ— Failed: {failed_count}\")\n",
    "    print(f\" Location: {OUTPUT_DIR}/rgb_images/\")\n",
    "    print(f\"\\n Dataset Coverage:\")\n",
    "    print(f\"   â€¢ Pre-fire baseline: 2014-2019 (5 years)\")\n",
    "    print(f\"   â€¢ Active fire period: Dec 20, 2019 - Feb 6, 2020\")\n",
    "    print(f\"   â€¢ Post-fire recovery: 2020-2024 (5 years)\")\n",
    "    print(f\"   â€¢ Area burned: ~211,500 hectares (48% of island)\")\n",
    "    print(f\"\\nâœ“ Images are in standard PNG format and viewable!\")\n",
    "    print(\"You can open them with any image viewer or photo app.\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_kangaroo_island()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9970422d-6e15-4911-921f-487f05dc3532",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Greater Sydney Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84ebeed6-fbd2-4c21-93eb-d99fac592431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Earth Engine initialized for project: glacier-probe-model-475519\n",
      "================================================================================\n",
      "ğŸ‡¦ğŸ‡º GREATER SYDNEY BLUE MOUNTAINS FRINGE IMAGE DOWNLOADER\n",
      "Multiple Sub-Regions for Complete Coverage\n",
      "================================================================================\n",
      "ğŸ“ Regions: 5\n",
      "   â€¢ Blue_Mts_Katoomba: [150.25, -33.75, 150.35, -33.65]\n",
      "   â€¢ Blue_Mts_Wentworth_Falls: [150.35, -33.75, 150.45, -33.65]\n",
      "   â€¢ Warragamba_Dam_North: [150.55, -33.95, 150.65, -33.85]\n",
      "   â€¢ Warragamba_Dam_South: [150.55, -34.05, 150.65, -33.95]\n",
      "   â€¢ Penrith_Urban_Edge: [150.65, -33.8, 150.75, -33.7]\n",
      "ğŸ”¥ Event: Black Summer Bushfires (2019-2020)\n",
      "ğŸŒµ Context: Prolonged drought + catastrophic fire + urban expansion\n",
      "ğŸ“Š Research: Bushfire, Drought, Regrowth, Deforestation\n",
      "================================================================================\n",
      "âœ“ Created output directories in sydney_blue_mountains_fringe_rgb/\n",
      "\n",
      "Target: 75 images total (~15 per region)\n",
      "Time periods: 7\n",
      "Resolution: 30m | Format: PNG (Viewable RGB)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ğŸŒ³ Processing Region: Blue_Mts_Katoomba\n",
      "ğŸ“ Coordinates: [150.25, -33.75, 150.35, -33.65]\n",
      "ğŸ¯ Target: 15 images\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE BASELINE (2018): 12 images available\n",
      "    â†“ 2018-02-14... âœ“ (1/15)\n",
      "    â†“ 2018-03-11... âœ“ (2/15)\n",
      "    âŠ™ 2018-03-11 (exists)\n",
      "  DROUGHT & BLACK SUMMER FIRES (2019-2020): 140 images available\n",
      "    â†“ 2019-06-04... âœ“ (4/15)\n",
      "    âŠ™ 2019-06-04 (exists)\n",
      "    â†“ 2019-06-09... âœ“ (6/15)\n",
      "    âŠ™ 2019-06-09 (exists)\n",
      "    â†“ 2019-06-14... âœ“ (8/15)\n",
      "  IMMEDIATE POST-FIRE RECOVERY (2020-2021): 143 images available\n",
      "    â†“ 2020-06-03... âœ“ (9/15)\n",
      "    âŠ™ 2020-06-03 (exists)\n",
      "    â†“ 2020-06-08... âœ“ (11/15)\n",
      "  POST-FIRE RECOVERY & MONITORING (2021-2022): 141 images available\n",
      "    â†“ 2021-06-03... âœ“ (12/15)\n",
      "    âŠ™ 2021-06-03 (exists)\n",
      "    â†“ 2021-06-08... âœ“ (14/15)\n",
      "  REGROWTH & DEFORESTATION MONITORING (2022-2023): 146 images available\n",
      "    â†“ 2022-06-03... âœ“ (15/15)\n",
      "\n",
      "âœ“ Blue_Mts_Katoomba: 15 downloaded, 0 failed\n",
      "\n",
      "================================================================================\n",
      "ğŸŒ³ Processing Region: Blue_Mts_Wentworth_Falls\n",
      "ğŸ“ Coordinates: [150.35, -33.75, 150.45, -33.65]\n",
      "ğŸ¯ Target: 15 images\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE BASELINE (2018): 6 images available\n",
      "    â†“ 2018-03-11... âœ“ (1/15)\n",
      "    â†“ 2018-06-04... âœ“ (2/15)\n",
      "    â†“ 2018-12-16... âœ“ (3/15)\n",
      "  DROUGHT & BLACK SUMMER FIRES (2019-2020): 70 images available\n",
      "    â†“ 2019-06-04... âœ“ (4/15)\n",
      "    â†“ 2019-06-09... âœ“ (5/15)\n",
      "    â†“ 2019-06-14... âœ“ (6/15)\n",
      "    â†“ 2019-06-19... âœ“ (7/15)\n",
      "    â†“ 2019-06-24... âœ“ (8/15)\n",
      "  IMMEDIATE POST-FIRE RECOVERY (2020-2021): 72 images available\n",
      "    â†“ 2020-06-03... âœ“ (9/15)\n",
      "    â†“ 2020-06-08... âœ“ (10/15)\n",
      "    â†“ 2020-06-13... âœ“ (11/15)\n",
      "  POST-FIRE RECOVERY & MONITORING (2021-2022): 71 images available\n",
      "    â†“ 2021-06-03... âœ“ (12/15)\n",
      "    â†“ 2021-06-08... âœ“ (13/15)\n",
      "    â†“ 2021-06-13... âœ“ (14/15)\n",
      "  REGROWTH & DEFORESTATION MONITORING (2022-2023): 72 images available\n",
      "    â†“ 2022-06-03... âœ“ (15/15)\n",
      "\n",
      "âœ“ Blue_Mts_Wentworth_Falls: 15 downloaded, 0 failed\n",
      "\n",
      "================================================================================\n",
      "ğŸŒ³ Processing Region: Warragamba_Dam_North\n",
      "ğŸ“ Coordinates: [150.55, -33.95, 150.65, -33.85]\n",
      "ğŸ¯ Target: 15 images\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE BASELINE (2018): 6 images available\n",
      "    â†“ 2018-03-11... âœ“ (1/15)\n",
      "    â†“ 2018-06-04... âœ“ (2/15)\n",
      "    â†“ 2018-12-16... âœ“ (3/15)\n",
      "  DROUGHT & BLACK SUMMER FIRES (2019-2020): 70 images available\n",
      "    â†“ 2019-06-04... âœ“ (4/15)\n",
      "    â†“ 2019-06-09... âœ“ (5/15)\n",
      "    â†“ 2019-06-14... âœ“ (6/15)\n",
      "    â†“ 2019-06-19... âœ“ (7/15)\n",
      "    â†“ 2019-06-24... âœ“ (8/15)\n",
      "  IMMEDIATE POST-FIRE RECOVERY (2020-2021): 72 images available\n",
      "    â†“ 2020-06-03... âœ“ (9/15)\n",
      "    â†“ 2020-06-08... âœ“ (10/15)\n",
      "    â†“ 2020-06-13... âœ“ (11/15)\n",
      "  POST-FIRE RECOVERY & MONITORING (2021-2022): 71 images available\n",
      "    â†“ 2021-06-03... âœ“ (12/15)\n",
      "    â†“ 2021-06-08... âœ“ (13/15)\n",
      "    â†“ 2021-06-13... âœ“ (14/15)\n",
      "  REGROWTH & DEFORESTATION MONITORING (2022-2023): 72 images available\n",
      "    â†“ 2022-06-03... âœ“ (15/15)\n",
      "\n",
      "âœ“ Warragamba_Dam_North: 15 downloaded, 0 failed\n",
      "\n",
      "================================================================================\n",
      "ğŸŒ³ Processing Region: Warragamba_Dam_South\n",
      "ğŸ“ Coordinates: [150.55, -34.05, 150.65, -33.95]\n",
      "ğŸ¯ Target: 15 images\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE BASELINE (2018): 6 images available\n",
      "    â†“ 2018-03-11... âœ“ (1/15)\n",
      "    â†“ 2018-06-04... âœ“ (2/15)\n",
      "    â†“ 2018-12-16... âœ“ (3/15)\n",
      "  DROUGHT & BLACK SUMMER FIRES (2019-2020): 70 images available\n",
      "    â†“ 2019-06-04... âœ“ (4/15)\n",
      "    â†“ 2019-06-09... âœ“ (5/15)\n",
      "    â†“ 2019-06-14... âœ“ (6/15)\n",
      "    â†“ 2019-06-19... âœ“ (7/15)\n",
      "    â†“ 2019-06-24... âœ“ (8/15)\n",
      "  IMMEDIATE POST-FIRE RECOVERY (2020-2021): 72 images available\n",
      "    â†“ 2020-06-03... âœ“ (9/15)\n",
      "    â†“ 2020-06-08... âœ“ (10/15)\n",
      "    â†“ 2020-06-13... âœ“ (11/15)\n",
      "  POST-FIRE RECOVERY & MONITORING (2021-2022): 71 images available\n",
      "    â†“ 2021-06-03... âœ“ (12/15)\n",
      "    â†“ 2021-06-08... âœ“ (13/15)\n",
      "    â†“ 2021-06-13... âœ“ (14/15)\n",
      "  REGROWTH & DEFORESTATION MONITORING (2022-2023): 72 images available\n",
      "    â†“ 2022-06-03... âœ“ (15/15)\n",
      "\n",
      "âœ“ Warragamba_Dam_South: 15 downloaded, 0 failed\n",
      "\n",
      "================================================================================\n",
      "ğŸŒ³ Processing Region: Penrith_Urban_Edge\n",
      "ğŸ“ Coordinates: [150.65, -33.8, 150.75, -33.7]\n",
      "ğŸ¯ Target: 15 images\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE BASELINE (2018): 6 images available\n",
      "    â†“ 2018-03-11... âœ“ (1/15)\n",
      "    â†“ 2018-06-04... âœ“ (2/15)\n",
      "    â†“ 2018-12-16... âœ“ (3/15)\n",
      "  DROUGHT & BLACK SUMMER FIRES (2019-2020): 70 images available\n",
      "    â†“ 2019-06-04... âœ“ (4/15)\n",
      "    â†“ 2019-06-09... âœ“ (5/15)\n",
      "    â†“ 2019-06-14... âœ“ (6/15)\n",
      "    â†“ 2019-06-19... âœ“ (7/15)\n",
      "    â†“ 2019-06-24... âœ“ (8/15)\n",
      "  IMMEDIATE POST-FIRE RECOVERY (2020-2021): 72 images available\n",
      "    â†“ 2020-06-03... âœ“ (9/15)\n",
      "    â†“ 2020-06-08... âœ“ (10/15)\n",
      "    â†“ 2020-06-13... âœ“ (11/15)\n",
      "  POST-FIRE RECOVERY & MONITORING (2021-2022): 71 images available\n",
      "    â†“ 2021-06-03... âœ“ (12/15)\n",
      "    â†“ 2021-06-08... âœ“ (13/15)\n",
      "    â†“ 2021-06-13... âœ“ (14/15)\n",
      "  REGROWTH & DEFORESTATION MONITORING (2022-2023): 72 images available\n",
      "    â†“ 2022-06-03... âœ“ (15/15)\n",
      "\n",
      "âœ“ Penrith_Urban_Edge: 15 downloaded, 0 failed\n",
      "\n",
      "================================================================================\n",
      "DOWNLOAD COMPLETE - SYDNEY BLUE MOUNTAINS MULTI-REGION DATASET\n",
      "================================================================================\n",
      "âœ“ Total Downloaded: 75/75 images\n",
      "âœ— Total Failed: 0\n",
      "ğŸ“ Location: sydney_blue_mountains_fringe_rgb/rgb_images/\n",
      "\n",
      "ğŸ“Š Dataset Coverage:\n",
      "   â€¢ Pre-fire baseline: 2018\n",
      "   â€¢ Drought & Black Summer fires: 2019-2020\n",
      "   â€¢ Post-fire recovery: 2020-2021\n",
      "   â€¢ Long-term monitoring: 2021-2025\n",
      "\n",
      "ğŸ—ºï¸ Sub-Regions Captured:\n",
      "   â€¢ Blue_Mts_Katoomba\n",
      "   â€¢ Blue_Mts_Wentworth_Falls\n",
      "   â€¢ Warragamba_Dam_North\n",
      "   â€¢ Warragamba_Dam_South\n",
      "   â€¢ Penrith_Urban_Edge\n",
      "\n",
      "ğŸ”¬ Recommended Analysis Indices:\n",
      "   â€¢ NBR (Normalized Burn Ratio): B8-B12 / B8+B12\n",
      "     â†’ Fire severity mapping, burn scar detection\n",
      "   â€¢ NDVI (Vegetation Index): B8-B4 / B8+B4\n",
      "     â†’ Vegetation health, regrowth monitoring\n",
      "   â€¢ EVI (Enhanced Vegetation): 2.5*(B8-B4) / (B8+6*B4-7.5*B2+1)\n",
      "     â†’ Drought stress, canopy density\n",
      "   â€¢ NDMI (Moisture Index): B8-B11 / B8+B11\n",
      "     â†’ Water stress, drought impact\n",
      "   â€¢ NDWI (Water Index): B3-B8 / B3+B8\n",
      "     â†’ Drought severity, water availability\n",
      "\n",
      "âœ“ Images are in standard PNG format and viewable!\n",
      "All smoke, fire, and atmospheric effects are preserved.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Greater Sydney Blue Mountains Fringe Satellite Image Downloader\n",
    "Downloads RGB satellite imagery for the Blue Mountains/Warragamba Dam Catchment Area\n",
    "Captures: Bushfire (Black Summer 2019-20), Drought, Regrowth, and Deforestation\n",
    "Images are saved as PNG with proper color scaling for visualization.\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# --- CONFIGURATION (MODIFIED for Sydney Blue Mountains Fringe) ---\n",
    "\n",
    "PROJECT_ID = 'glacier-probe-model-475519'\n",
    "OUTPUT_DIR = 'sydney_blue_mountains_fringe_rgb'\n",
    "NUM_IMAGES = 75  # 15 images per sub-region\n",
    "SCALE = 30  # Increased to 30m to ensure successful downloads\n",
    "MAX_CLOUD_COVER = 100  # Allow all images including smoke/clouds during fires\n",
    "\n",
    "# Greater Sydney Blue Mountains Fringe - Multiple Sub-Regions\n",
    "# Multiple smaller regions to ensure visible imagery capture\n",
    "# Coordinates: [lon_min, lat_min, lon_max, lat_max]\n",
    "SYDNEY_REGIONS = {\n",
    "    'Blue_Mts_Katoomba': [150.25, -33.75, 150.35, -33.65],  # Katoomba/Three Sisters area\n",
    "    'Blue_Mts_Wentworth_Falls': [150.35, -33.75, 150.45, -33.65],  # Wentworth Falls\n",
    "    'Warragamba_Dam_North': [150.55, -33.95, 150.65, -33.85],  # North of dam\n",
    "    'Warragamba_Dam_South': [150.55, -34.05, 150.65, -33.95],  # South of dam\n",
    "    'Penrith_Urban_Edge': [150.65, -33.80, 150.75, -33.70],  # Urban fringe\n",
    "}\n",
    "\n",
    "# Date ranges specifically targeting the Black Summer event and recovery/drought periods\n",
    "YEAR_RANGES = [\n",
    "    # Pre-fire/drought baseline\n",
    "    ('2018-01-01', '2019-01-01'), \n",
    "    # Peak drought and fire period (Black Summer)\n",
    "    ('2019-06-01', '2020-06-01'), \n",
    "    # Immediate post-fire and start of regrowth\n",
    "    ('2020-06-01', '2021-06-01'), \n",
    "    # Continued recovery and expansion monitoring\n",
    "    ('2021-06-01', '2022-06-01'),\n",
    "    ('2022-06-01', '2023-06-01'),\n",
    "    ('2023-06-01', '2024-06-01'),\n",
    "    ('2024-06-01', '2025-06-01'),\n",
    "]\n",
    "\n",
    "# --- INITIALIZATION ---\n",
    "\n",
    "try:\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"âœ“ Earth Engine initialized for project: {PROJECT_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  Initialization failed. Attempting authentication...\")\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"âœ“ Authentication successful. Earth Engine initialized.\")\n",
    "\n",
    "# --- UTILITY FUNCTIONS ---\n",
    "\n",
    "def create_output_dirs():\n",
    "    \"\"\"Create output directory structure\"\"\"\n",
    "    Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/rgb_images\").mkdir(exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/metadata\").mkdir(exist_ok=True)\n",
    "    print(f\"âœ“ Created output directories in {OUTPUT_DIR}/\")\n",
    "\n",
    "def get_satellite_collection(start_date, end_date, roi, max_cloud_cover):\n",
    "    \"\"\"Get Sentinel-2 collection WITHOUT cloud masking to preserve all effects\"\"\"\n",
    "    sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "        .filterBounds(roi) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover))\n",
    "\n",
    "    s2_count = sentinel2.size().getInfo()\n",
    "    \n",
    "    if s2_count > 0:\n",
    "        return sentinel2, 'sentinel2'\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def download_rgb_image(image, region, filename):\n",
    "    \"\"\"Downloads RGB image in viewable PNG format\"\"\"\n",
    "    try:\n",
    "        # Select RGB bands (B4=Red, B3=Green, B2=Blue)\n",
    "        rgb = image.select(['B4', 'B3', 'B2'])\n",
    "        \n",
    "        # Normalize to 0-255 range for viewing\n",
    "        rgb_vis = rgb.visualize(\n",
    "            min=0,\n",
    "            max=3000,\n",
    "            bands=['B4', 'B3', 'B2']\n",
    "        )\n",
    "        \n",
    "        # Get thumbnail URL with adjusted dimensions\n",
    "        url = rgb_vis.getThumbURL({\n",
    "            'region': region,\n",
    "            'dimensions': 512,  # Reduced for better compatibility\n",
    "            'format': 'png'\n",
    "        })\n",
    "        \n",
    "        # Download and save as PNG\n",
    "        response = requests.get(url, timeout=300)\n",
    "        if response.status_code == 200:\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âœ— HTTP Error {response.status_code}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"âœ— Error: {error_msg[:100]}...\")\n",
    "        return False\n",
    "\n",
    "def save_metadata(image, filename, region_name, period_label):\n",
    "    \"\"\"Save image metadata\"\"\"\n",
    "    try:\n",
    "        props = image.getInfo()['properties']\n",
    "        metadata_file = filename\n",
    "        \n",
    "        with open(metadata_file, 'w') as f:\n",
    "            f.write(f\"Region: {region_name}\\n\")\n",
    "            f.write(f\"Location: Greater Sydney - Blue Mountains Fringe & Warragamba Catchment\\n\")\n",
    "            f.write(f\"Research Focus: Bushfire, Drought, Regrowth, Deforestation\\n\")\n",
    "            f.write(f\"Period: {period_label}\\n\\n\")\n",
    "            \n",
    "            f.write(f\"Satellite: SENTINEL-2\\n\")\n",
    "            f.write(f\"Image Type: RGB (True Color)\\n\")\n",
    "            f.write(f\"Format: PNG (Viewable)\\n\")\n",
    "            \n",
    "            date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "            f.write(f\"Date: {date}\\n\")\n",
    "            f.write(f\"Cloud Cover: {props.get('CLOUDY_PIXEL_PERCENTAGE', 'N/A')}%\\n\")\n",
    "            f.write(f\"Product ID: {props.get('PRODUCT_ID', 'N/A')}\\n\")\n",
    "            f.write(f\"Bands: R=B4 (Red), G=B3 (Green), B=B2 (Blue)\\n\")\n",
    "            f.write(f\"Resolution: {SCALE}m\\n\")\n",
    "            f.write(f\"Processing: NO cloud masking - smoke and fire effects preserved\\n\")\n",
    "            \n",
    "            f.write(f\"\\n=== RESEARCH CONTEXT ===\\n\")\n",
    "            f.write(f\"Black Summer Fires: 2019-2020\\n\")\n",
    "            f.write(f\"Key Indices for Analysis:\\n\")\n",
    "            f.write(f\"  â€¢ NBR (Normalized Burn Ratio): Fire severity\\n\")\n",
    "            f.write(f\"  â€¢ NDVI (Normalized Difference Vegetation Index): Vegetation health/regrowth\\n\")\n",
    "            f.write(f\"  â€¢ EVI (Enhanced Vegetation Index): Drought impact\\n\")\n",
    "            f.write(f\"  â€¢ NDMI (Normalized Difference Moisture Index): Water stress\\n\")\n",
    "            f.write(f\"  â€¢ NDWI (Normalized Difference Water Index): Drought monitoring\\n\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  âš  Metadata warning: {str(e)[:30]}\")\n",
    "\n",
    "def get_period_label(start_date, end_date):\n",
    "    \"\"\"Get descriptive label for the time period\"\"\"\n",
    "    if '2018' in start_date:\n",
    "        return \"PRE-FIRE BASELINE (2018)\"\n",
    "    elif '2019-06' in start_date and '2020-06' in end_date:\n",
    "        return \"DROUGHT & BLACK SUMMER FIRES (2019-2020)\"\n",
    "    elif '2020-06' in start_date and '2021' in end_date:\n",
    "        return \"IMMEDIATE POST-FIRE RECOVERY (2020-2021)\"\n",
    "    elif '2021' in start_date:\n",
    "        return f\"POST-FIRE RECOVERY & MONITORING ({start_date[:4]}-{end_date[:4]})\"\n",
    "    elif '2022' in start_date:\n",
    "        return f\"REGROWTH & DEFORESTATION MONITORING ({start_date[:4]}-{end_date[:4]})\"\n",
    "    elif '2023' in start_date or '2024' in start_date:\n",
    "        return f\"LONG-TERM RECOVERY ({start_date[:4]}-{end_date[:4]})\"\n",
    "    return f\"{start_date[:4]}-{end_date[:4]}\"\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "def main_sydney():\n",
    "    \"\"\"Main download function for Sydney Blue Mountains Fringe - Multiple Regions\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"GREATER SYDNEY BLUE MOUNTAINS FRINGE IMAGE DOWNLOADER\")\n",
    "    print(\"Multiple Sub-Regions for Complete Coverage\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ğŸ“ Regions: {len(SYDNEY_REGIONS)}\")\n",
    "    for name, coords in SYDNEY_REGIONS.items():\n",
    "        print(f\"   â€¢ {name}: {coords}\")\n",
    "    print(f\" Event: Black Summer Bushfires (2019-2020)\")\n",
    "    print(f\" Context: Prolonged drought + catastrophic fire + urban expansion\")\n",
    "    print(f\" Research: Bushfire, Drought, Regrowth, Deforestation\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    create_output_dirs()\n",
    "    \n",
    "    total_downloaded = 0\n",
    "    total_failed = 0\n",
    "    \n",
    "    print(f\"\\nTarget: {NUM_IMAGES} images total (~{NUM_IMAGES // len(SYDNEY_REGIONS)} per region)\")\n",
    "    print(f\"Time periods: {len(YEAR_RANGES)}\")\n",
    "    print(f\"Resolution: {SCALE}m | Format: PNG (Viewable RGB)\\n\")\n",
    "    \n",
    "    images_per_region = NUM_IMAGES // len(SYDNEY_REGIONS)\n",
    "    \n",
    "    # Process each sub-region\n",
    "    for region_name, coords in SYDNEY_REGIONS.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ğŸŒ³ Processing Region: {region_name}\")\n",
    "        print(f\"ğŸ“ Coordinates: {coords}\")\n",
    "        print(f\"ğŸ¯ Target: {images_per_region} images\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        downloaded_count = 0\n",
    "        failed_count = 0\n",
    "        \n",
    "        # Iterate through each year range for this region\n",
    "        for start_date, end_date in YEAR_RANGES:\n",
    "            if downloaded_count >= images_per_region:\n",
    "                break\n",
    "            \n",
    "            period_label = get_period_label(start_date, end_date)\n",
    "            \n",
    "            # Get the satellite collection for the period\n",
    "            collection, satellite_type = get_satellite_collection(start_date, end_date, roi, MAX_CLOUD_COVER)\n",
    "            \n",
    "            if collection is None:\n",
    "                print(f\"  {period_label}: 0 images found\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                count = collection.size().getInfo()\n",
    "                if count == 0:\n",
    "                    print(f\"  {period_label}: 0 images found\")\n",
    "                    continue\n",
    "                    \n",
    "                print(f\"  {period_label}: {count} images available\")\n",
    "                \n",
    "                # Images per period\n",
    "                if 'BLACK SUMMER' in period_label:\n",
    "                    images_per_period = min(5, count, images_per_region - downloaded_count)\n",
    "                else:\n",
    "                    images_per_period = min(3, count, images_per_region - downloaded_count)\n",
    "                    \n",
    "                if images_per_period <= 0:\n",
    "                    break\n",
    "                    \n",
    "                images = collection.limit(images_per_period).toList(images_per_period)\n",
    "                \n",
    "                for i in range(images_per_period):\n",
    "                    if downloaded_count >= images_per_region:\n",
    "                        break\n",
    "                        \n",
    "                    image = ee.Image(images.get(i))\n",
    "                    \n",
    "                    # Get date\n",
    "                    date_acquired = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "                    \n",
    "                    # Filename construction\n",
    "                    period_code = period_label.split('(')[0].strip().replace(' ', '_').replace('&', '').replace('-', '')\n",
    "                    filename = f\"{OUTPUT_DIR}/rgb_images/{region_name}_{date_acquired}_{period_code}_RGB.png\"\n",
    "                    metadata_filename = f\"{OUTPUT_DIR}/metadata/{region_name}_{date_acquired}_{period_code}_meta.txt\"\n",
    "                    \n",
    "                    # Skip if exists\n",
    "                    if os.path.exists(filename):\n",
    "                        downloaded_count += 1\n",
    "                        print(f\"    âŠ™ {date_acquired} (exists)\")\n",
    "                        continue\n",
    "                    \n",
    "                    print(f\"    â†“ {date_acquired}...\", end=' ')\n",
    "                    \n",
    "                    if download_rgb_image(image, roi, filename):\n",
    "                        save_metadata(image, metadata_filename, region_name, period_label)\n",
    "                        downloaded_count += 1\n",
    "                        print(f\"âœ“ ({downloaded_count}/{images_per_region})\")\n",
    "                    else:\n",
    "                        failed_count += 1\n",
    "                    \n",
    "                    time.sleep(1.5)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  âœ— Error in collection processing: {str(e)[:50]}...\")\n",
    "                continue\n",
    "        \n",
    "        total_downloaded += downloaded_count\n",
    "        total_failed += failed_count\n",
    "        print(f\"\\nâœ“ {region_name}: {downloaded_count} downloaded, {failed_count} failed\")\n",
    "    \n",
    "    # Final Summary\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DOWNLOAD COMPLETE - SYDNEY BLUE MOUNTAINS MULTI-REGION DATASET\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"âœ“ Total Downloaded: {total_downloaded}/{NUM_IMAGES} images\")\n",
    "    print(f\"âœ— Total Failed: {total_failed}\")\n",
    "    print(f\" Location: {OUTPUT_DIR}/rgb_images/\")\n",
    "    print(f\"\\n Dataset Coverage:\")\n",
    "    print(f\"   â€¢ Pre-fire baseline: 2018\")\n",
    "    print(f\"   â€¢ Drought & Black Summer fires: 2019-2020\")\n",
    "    print(f\"   â€¢ Post-fire recovery: 2020-2021\")\n",
    "    print(f\"   â€¢ Long-term monitoring: 2021-2025\")\n",
    "    print(f\"\\n Sub-Regions Captured:\")\n",
    "    for name in SYDNEY_REGIONS.keys():\n",
    "        print(f\"   â€¢ {name}\")\n",
    "    print(f\"\\n Recommended Analysis Indices:\")\n",
    "    print(f\"   â€¢ NBR (Normalized Burn Ratio): B8-B12 / B8+B12\")\n",
    "    print(f\"     â†’ Fire severity mapping, burn scar detection\")\n",
    "    print(f\"   â€¢ NDVI (Vegetation Index): B8-B4 / B8+B4\")\n",
    "    print(f\"     â†’ Vegetation health, regrowth monitoring\")\n",
    "    print(f\"   â€¢ EVI (Enhanced Vegetation): 2.5*(B8-B4) / (B8+6*B4-7.5*B2+1)\")\n",
    "    print(f\"     â†’ Drought stress, canopy density\")\n",
    "    print(f\"   â€¢ NDMI (Moisture Index): B8-B11 / B8+B11\")\n",
    "    print(f\"     â†’ Water stress, drought impact\")\n",
    "    print(f\"   â€¢ NDWI (Water Index): B3-B8 / B3+B8\")\n",
    "    print(f\"     â†’ Drought severity, water availability\")\n",
    "    print(f\"\\nâœ“ Images are in standard PNG format and viewable!\")\n",
    "    print(\"All smoke, fire, and atmospheric effects are preserved.\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_sydney()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d32e17-a6c7-4e7c-ad16-83f22f8a6c82",
   "metadata": {},
   "source": [
    "## 4. Hyderbad Forest Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7a75079-e361-43f0-b1d1-d2c9e5dd412c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Earth Engine initialized: glacier-probe-model-475519\n",
      "âœ“ Queued Hyderabad_Central (2018-01-14)\n",
      "âœ“ Queued Hyderabad_Central (2019-01-04)\n",
      "âœ“ Queued Hyderabad_Central (2020-01-14)\n",
      "âœ“ Queued Hyderabad_Central (2021-01-18)\n",
      "âœ“ Queued ORR_Northwest (2018-01-14)\n",
      "âœ“ Queued ORR_Northwest (2019-01-04)\n",
      "âœ“ Queued ORR_Northwest (2020-01-14)\n",
      "âœ“ Queued ORR_Northwest (2021-01-18)\n",
      "âœ“ Queued ORR_Northeast (2018-01-14)\n",
      "âœ“ Queued ORR_Northeast (2019-01-04)\n",
      "âœ“ Queued ORR_Northeast (2020-01-14)\n",
      "âœ“ Queued ORR_Northeast (2021-01-18)\n",
      "âœ“ Queued ORR_Southwest (2018-01-14)\n",
      "âœ“ Queued ORR_Southwest (2019-01-04)\n",
      "âœ“ Queued ORR_Southwest (2020-01-14)\n",
      "âœ“ Queued ORR_Southwest (2021-01-18)\n",
      "âœ“ Queued ORR_Southeast (2018-01-14)\n",
      "âœ“ Queued ORR_Southeast (2019-01-04)\n",
      "âœ“ Queued ORR_Southeast (2020-01-14)\n",
      "âœ“ Queued ORR_Southeast (2021-01-18)\n",
      "âœ“ Queued Kompally_Corridor (2018-01-14)\n",
      "âœ“ Queued Kompally_Corridor (2019-01-04)\n",
      "âœ“ Queued Kompally_Corridor (2020-01-14)\n",
      "âœ“ Queued Kompally_Corridor (2021-01-18)\n",
      "âœ“ Queued Airport_Zone (2018-01-14)\n",
      "âœ“ Queued Airport_Zone (2019-01-04)\n",
      "âœ“ Queued Airport_Zone (2020-01-14)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 109\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck progress: https://code.earthengine.google.com/tasks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 109\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[12], line 103\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m                 region_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    102\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ“ Queued \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 103\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ… \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexported_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tasks are now RUNNING in Earth Engine.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck progress: https://code.earthengine.google.com/tasks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hyderabad Region ULTRA HIGH QUALITY Image Exporter\n",
    "Fixed for GeoTIFF compatibility and automated task starting.\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import time\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "PROJECT_ID = 'glacier-probe-model-475519'\n",
    "DRIVE_FOLDER = 'Hyderabad_Deforestation_UltraHD'\n",
    "NUM_IMAGES = 50\n",
    "SCALE = 10 \n",
    "MAX_CLOUD_COVER = 5 \n",
    "\n",
    "# Regions\n",
    "HYDERABAD_REGIONS = {\n",
    "    'Hyderabad_Central': [78.300, 17.425, 78.350, 17.465],\n",
    "    'ORR_Northwest': [78.260, 17.505, 78.310, 17.545],\n",
    "    'ORR_Northeast': [78.530, 17.495, 78.580, 17.535],\n",
    "    'ORR_Southwest': [78.260, 17.345, 78.310, 17.385],\n",
    "    'ORR_Southeast': [78.520, 17.335, 78.570, 17.375],\n",
    "    'Kompally_Corridor': [78.460, 17.535, 78.510, 17.575],\n",
    "    'Airport_Zone': [78.400, 17.215, 78.450, 17.255],\n",
    "    'IT_Corridor_West': [78.310, 17.405, 78.360, 17.445],\n",
    "    'Industrial_West': [78.200, 17.475, 78.250, 17.515],\n",
    "    'Eastern_Expansion': [78.570, 17.385, 78.620, 17.425],\n",
    "    'Gandipet_Periphery': [78.260, 17.365, 78.310, 17.405],\n",
    "    'Southern_Sprawl': [78.490, 17.285, 78.540, 17.325],\n",
    "}\n",
    "\n",
    "YEAR_RANGES = [\n",
    "    ('2018-01-01', '2019-01-01'), ('2019-01-01', '2020-01-01'),\n",
    "    ('2020-01-01', '2021-01-01'), ('2021-01-01', '2022-01-01'),\n",
    "    ('2022-01-01', '2023-01-01'), ('2023-01-01', '2024-01-01'),\n",
    "    ('2024-01-01', '2025-01-01'),\n",
    "]\n",
    "\n",
    "# --- INITIALIZATION ---\n",
    "try:\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"âœ“ Earth Engine initialized: {PROJECT_ID}\")\n",
    "except Exception:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "\n",
    "# --- FUNCTIONS ---\n",
    "def maskS2clouds(image):\n",
    "    qa = image.select('QA60')\n",
    "    mask = qa.bitwiseAnd(1 << 10).eq(0).And(qa.bitwiseAnd(1 << 11).eq(0))\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "def export_to_drive(image, region, region_name, date_str):\n",
    "    try:\n",
    "        rgb = image.select(['B4', 'B3', 'B2']).visualize(\n",
    "            min=[300, 400, 400], max=[2800, 2500, 2200], gamma=[1.2, 1.3, 1.4]\n",
    "        )\n",
    "        \n",
    "        task = ee.batch.Export.image.toDrive(\n",
    "            image=rgb,\n",
    "            description=f'{region_name}_{date_str}',\n",
    "            folder=DRIVE_FOLDER,\n",
    "            fileNamePrefix=f'{region_name}_{date_str}',\n",
    "            region=region,\n",
    "            scale=SCALE,\n",
    "            crs='EPSG:4326',\n",
    "            maxPixels=1e13,\n",
    "            fileFormat='GeoTIFF',\n",
    "            formatOptions={'cloudOptimized': True}\n",
    "        )\n",
    "        task.start()\n",
    "        return task.id\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- MAIN ---\n",
    "def main():\n",
    "    exported_count = 0\n",
    "    images_per_region = max(1, NUM_IMAGES // len(HYDERABAD_REGIONS))\n",
    "\n",
    "    for region_name, coords in HYDERABAD_REGIONS.items():\n",
    "        if exported_count >= NUM_IMAGES: break\n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        region_count = 0\n",
    "\n",
    "        for start, end in YEAR_RANGES:\n",
    "            if exported_count >= NUM_IMAGES or region_count >= images_per_region: break\n",
    "            \n",
    "            col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\\\n",
    "                .filterBounds(roi).filterDate(start, end)\\\n",
    "                .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', MAX_CLOUD_COVER))\\\n",
    "                .map(maskS2clouds)\n",
    "\n",
    "            if col.size().getInfo() > 0:\n",
    "                img = ee.Image(col.first())\n",
    "                date = ee.Date(img.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "                tid = export_to_drive(img, roi, region_name, date)\n",
    "                if tid:\n",
    "                    exported_count += 1\n",
    "                    region_count += 1\n",
    "                    print(f\"âœ“ Queued {region_name} ({date})\")\n",
    "                time.sleep(0.5)\n",
    "\n",
    "    print(f\"\\nâœ… {exported_count} tasks are now RUNNING in Earth Engine.\")\n",
    "    print(f\"Check progress: https://code.earthengine.google.com/tasks\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87cb4c0-69b6-46ee-be70-c45bad84c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tifffile # pip install tifffile\n",
    "\n",
    "input_dir = 'Hyderabad_Deforestation_UltraHD'\n",
    "output_dir = 'Hyderabad_JPEGs'\n",
    "\n",
    "if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "\n",
    "print(\"Starting conversion to JPEG...\")\n",
    "for f in os.listdir(input_dir):\n",
    "    if f.endswith('.tif'):\n",
    "        # Read the GeoTIFF\n",
    "        img = tifffile.imread(os.path.join(input_dir, f))\n",
    "        # Ensure it's 8-bit for JPEG\n",
    "        if img.dtype != np.uint8:\n",
    "            img = (img / 256).astype(np.uint8)\n",
    "        \n",
    "        # Save as JPEG\n",
    "        out_path = os.path.join(output_dir, f.replace('.tif', '.jpg'))\n",
    "        Image.fromarray(img).save(out_path, \"JPEG\", quality=95)\n",
    "        print(f\"Converted: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa5db76c-4de4-4fe3-a062-fa5ccc391041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ³ Starting Hyderabad Forest Image Downloader\n",
      "\n",
      "Processing Region: KBR_Park_Central\n",
      "\n",
      "Processing Region: Mrugavani_National_Park\n",
      "\n",
      "Processing Region: Mahavir_Harin_Vansthali\n",
      "\n",
      "Processing Region: Ananthagiri_Hills_Proxy\n",
      "  â†“ Downloading 2025-03-31... Done! (1/50)\n",
      "\n",
      "âœ… Finished! Images saved to hyderabad_forest_dataset_rgb/rgb_images/\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hyderabad Forest & Green Cover RGB Image Downloader\n",
    "Downloads RGB satellite imagery for Hyderabad's forest areas in viewable PNG format.\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "PROJECT_ID = 'glacier-probe-model-475519'\n",
    "OUTPUT_DIR = 'hyderabad_forest_dataset_rgb'\n",
    "NUM_IMAGES = 50  \n",
    "SCALE = 30  \n",
    "MAX_CLOUD_COVER = 30  \n",
    "\n",
    "# Green zones and forested peripheries in Hyderabad\n",
    "HYDERABAD_REGIONS = {\n",
    "    'KBR_Park_Central': [78.40, 17.41, 78.43, 17.44],\n",
    "    'Mrugavani_National_Park': [78.32, 17.34, 78.36, 17.38],\n",
    "    'Mahavir_Harin_Vansthali': [78.57, 17.31, 78.61, 17.35],\n",
    "    'Ananthagiri_Hills_Proxy': [77.85, 17.29, 77.90, 17.34], # Outer Hyderabad\n",
    "}\n",
    "\n",
    "#\n",
    "# YEAR_RANGES = [\n",
    "#     ('2024-12-01', '2025-01-01'), # Early Winter\n",
    "#     ('2025-01-01', '2025-02-01'), # Peak Winter\n",
    "#     ('2025-02-01', '2025-03-01'), # Early Spring\n",
    "#     ('2025-03-01', '2025-03-29'), # Baseline (Immediate Pre-Event)\n",
    "# ]\n",
    "\n",
    "# During the event\n",
    "# During the event\n",
    "YEAR_RANGES = [\n",
    "    ('2025-03-29', '2025-04-03'), # Start and end date for the window\n",
    "]\n",
    "\n",
    "\n",
    "# YEAR_RANGES = [\n",
    "#     ('2025-04-03', '2025-05-01'), # Immediate Aftermath\n",
    "#     ('2025-05-01', '2025-06-01'), # Pre-Monsoon Heat (Dry Vegetation)\n",
    "#     ('2025-06-01', '2025-07-01'), # Start of Monsoon (Cloud cover may increase)\n",
    "#     ('2025-07-01', '2025-08-01'), # Peak Monsoon (Check for regrowth/flooding)\n",
    "# ]\n",
    "# --- INITIALIZATION ---\n",
    "\n",
    "\n",
    "try:\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "except Exception:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "\n",
    "# --- CORE FUNCTIONS ---\n",
    "\n",
    "def create_output_dirs():\n",
    "    Path(f\"{OUTPUT_DIR}/rgb_images\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/metadata\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def get_satellite_collection(start_date, end_date, roi, max_cloud_cover):\n",
    "    def maskS2clouds(image):\n",
    "        qa = image.select('QA60')\n",
    "        mask = qa.bitwiseAnd(1 << 10).eq(0).And(qa.bitwiseAnd(1 << 11).eq(0))\n",
    "        return image.updateMask(mask)\n",
    "    \n",
    "    collection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "        .filterBounds(roi) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover)) \\\n",
    "        .map(maskS2clouds)\n",
    "    \n",
    "    return collection\n",
    "\n",
    "def download_rgb_image(image, region, filename):\n",
    "    try:\n",
    "        rgb_vis = image.select(['B4', 'B3', 'B2']).visualize(min=0, max=3000)\n",
    "        url = rgb_vis.getThumbURL({'region': region, 'dimensions': 1024, 'format': 'png'})\n",
    "        response = requests.get(url, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\" Error: {e}\")\n",
    "    return False\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "def main_hyderabad():\n",
    "    print(f\"ğŸŒ³ Starting Hyderabad Forest Image Downloader\")\n",
    "    create_output_dirs()\n",
    "    \n",
    "    downloaded_total = 0\n",
    "    \n",
    "    for region_name, coords in HYDERABAD_REGIONS.items():\n",
    "        if downloaded_total >= NUM_IMAGES: break\n",
    "        \n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        print(f\"\\nProcessing Region: {region_name}\")\n",
    "\n",
    "        for start_date, end_date in YEAR_RANGES:\n",
    "            if downloaded_total >= NUM_IMAGES: break\n",
    "            \n",
    "            collection = get_satellite_collection(start_date, end_date, roi, MAX_CLOUD_COVER)\n",
    "            count = collection.size().getInfo()\n",
    "            \n",
    "            if count == 0: continue\n",
    "            \n",
    "            # Take the clearest image from the year\n",
    "            best_image = collection.sort('CLOUDY_PIXEL_PERCENTAGE').first()\n",
    "            date_str = ee.Date(best_image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "            \n",
    "            filename = f\"{OUTPUT_DIR}/rgb_images/{region_name}_{date_str}.png\"\n",
    "            \n",
    "            print(f\"  â†“ Downloading {date_str}...\", end=\" \")\n",
    "            if download_rgb_image(best_image, roi, filename):\n",
    "                downloaded_total += 1\n",
    "                print(f\"Done! ({downloaded_total}/{NUM_IMAGES})\")\n",
    "                time.sleep(1) # Rate limiting\n",
    "\n",
    "    print(f\"\\nâœ… Finished! Images saved to {OUTPUT_DIR}/rgb_images/\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_hyderabad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140e7d5-0a38-4b51-8b40-5d2811631ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef897c71-634e-4e3f-a439-49ae706652ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0499c34d-9aa3-4998-af15-08f9800b0666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
