{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3849a2cd-03b0-46c0-9e46-e05ed04f3412",
   "metadata": {},
   "source": [
    "## Standard Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92ed236-e7f5-4239-b9b0-3489c684cab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "print('Imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8434100-8690-4bfc-afae-7babc0b73e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Earth Engine\n",
    "try:\n",
    "    ee.Initialize(project = 'glacier-probe-model-475519')\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project = 'glacier-probe-model-475519')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66debf43-25da-4443-9724-e116fd61c74e",
   "metadata": {},
   "source": [
    "## 1. Hasdeo Forest RGB Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0bf5851-0480-44ed-bb8e-60d5bd82aef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "  HASDEO FOREST â€” GeoTIFF DOWNLOADER v2  (TARGET: 1 000+ IMAGES)\n",
      "========================================================================\n",
      "  Export mode      : DRIVE\n",
      "  Resolution       : 10 m\n",
      "  Max cloud cover  : 20%\n",
      "  Regions          : 7  â†’ ['Hasdeo_Full', 'PEKB_Core', 'Kente_Extension', 'Control_Forest', 'Hasdeo_North', 'Hasdeo_South', 'Mining_Buffer']\n",
      "  Monthly periods  : 152 (Jan 2013 â€“ Aug 2025)\n",
      "  Potential exports: 1,323\n",
      "    â”œâ”€ Monthly composites : 1064\n",
      "    â”œâ”€ Annual mosaics     : 91\n",
      "    â””â”€ Seasonal (dry+wet) : 168\n",
      "========================================================================\n",
      "âœ“ Earth Engine initialized | project: glacier-probe-model-475519\n",
      "âœ“ Output directories ready under: hasdeo_training_dataset/\n",
      "\n",
      "[ PART 1 ]  Monthly composites â€” all years 2013-2025\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "  ðŸŒ³ Region: Hasdeo_Full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Hasdeo_Full: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [03:51<00:00,  1.53s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Region: PEKB_Core\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PEKB_Core: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [03:06<00:00,  1.23s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Region: Kente_Extension\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Kente_Extension: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [03:06<00:00,  1.23s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Region: Control_Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Control_Forest: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [03:12<00:00,  1.27s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Region: Hasdeo_North\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Hasdeo_North: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [02:44<00:00,  1.08s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Region: Hasdeo_South\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Hasdeo_South: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [03:04<00:00,  1.21s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Region: Mining_Buffer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Mining_Buffer: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [03:03<00:00,  1.21s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[ PART 2 ]  Annual mosaics (2013â€“2025)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "  ðŸŒ³ Region: Hasdeo_Full\n",
      "    2013: no scenes â€” skipped\n",
      "    2014: no scenes â€” skipped\n",
      "    2015: no scenes â€” skipped\n",
      "    âœ“ 2016: 3 scenes â†’ ANN_Hasdeo_Full_2016\n",
      "    âœ“ 2017: 18 scenes â†’ ANN_Hasdeo_Full_2017\n",
      "    âœ“ 2018: 24 scenes â†’ ANN_Hasdeo_Full_2018\n",
      "    âœ“ 2019: 71 scenes â†’ ANN_Hasdeo_Full_2019\n",
      "    âœ“ 2020: 63 scenes â†’ ANN_Hasdeo_Full_2020\n",
      "    âœ“ 2021: 74 scenes â†’ ANN_Hasdeo_Full_2021\n",
      "    âœ“ 2022: 73 scenes â†’ ANN_Hasdeo_Full_2022\n",
      "    âœ“ 2023: 65 scenes â†’ ANN_Hasdeo_Full_2023\n",
      "    âœ“ 2024: 64 scenes â†’ ANN_Hasdeo_Full_2024\n",
      "    âœ“ 2025: 89 scenes â†’ ANN_Hasdeo_Full_2025\n",
      "\n",
      "  ðŸŒ³ Region: PEKB_Core\n",
      "    2013: no scenes â€” skipped\n",
      "    2014: no scenes â€” skipped\n",
      "    2015: no scenes â€” skipped\n",
      "    âœ“ 2016: 2 scenes â†’ ANN_PEKB_Core_2016\n",
      "    âœ“ 2017: 9 scenes â†’ ANN_PEKB_Core_2017\n",
      "    âœ“ 2018: 15 scenes â†’ ANN_PEKB_Core_2018\n",
      "    âœ“ 2019: 35 scenes â†’ ANN_PEKB_Core_2019\n",
      "    âœ“ 2020: 31 scenes â†’ ANN_PEKB_Core_2020\n",
      "    âœ“ 2021: 36 scenes â†’ ANN_PEKB_Core_2021\n",
      "    âœ“ 2022: 38 scenes â†’ ANN_PEKB_Core_2022\n",
      "    âœ“ 2023: 32 scenes â†’ ANN_PEKB_Core_2023\n",
      "    âœ“ 2024: 32 scenes â†’ ANN_PEKB_Core_2024\n",
      "    âœ“ 2025: 44 scenes â†’ ANN_PEKB_Core_2025\n",
      "\n",
      "  ðŸŒ³ Region: Kente_Extension\n",
      "    2013: no scenes â€” skipped\n",
      "    2014: no scenes â€” skipped\n",
      "    2015: no scenes â€” skipped\n",
      "    âœ“ 2016: 2 scenes â†’ ANN_Kente_Extension_2016\n",
      "    âœ“ 2017: 9 scenes â†’ ANN_Kente_Extension_2017\n",
      "    âœ“ 2018: 15 scenes â†’ ANN_Kente_Extension_2018\n",
      "    âœ“ 2019: 35 scenes â†’ ANN_Kente_Extension_2019\n",
      "    âœ“ 2020: 31 scenes â†’ ANN_Kente_Extension_2020\n",
      "    âœ“ 2021: 36 scenes â†’ ANN_Kente_Extension_2021\n",
      "    âœ“ 2022: 38 scenes â†’ ANN_Kente_Extension_2022\n",
      "    âœ“ 2023: 33 scenes â†’ ANN_Kente_Extension_2023\n",
      "    âœ“ 2024: 32 scenes â†’ ANN_Kente_Extension_2024\n",
      "    âœ“ 2025: 44 scenes â†’ ANN_Kente_Extension_2025\n",
      "\n",
      "  ðŸŒ³ Region: Control_Forest\n",
      "    2013: no scenes â€” skipped\n",
      "    2014: no scenes â€” skipped\n",
      "    2015: no scenes â€” skipped\n",
      "    âœ“ 2016: 3 scenes â†’ ANN_Control_Forest_2016\n",
      "    âœ“ 2017: 18 scenes â†’ ANN_Control_Forest_2017\n",
      "    âœ“ 2018: 24 scenes â†’ ANN_Control_Forest_2018\n",
      "    âœ“ 2019: 71 scenes â†’ ANN_Control_Forest_2019\n",
      "    âœ“ 2020: 63 scenes â†’ ANN_Control_Forest_2020\n",
      "    âœ“ 2021: 74 scenes â†’ ANN_Control_Forest_2021\n",
      "    âœ“ 2022: 73 scenes â†’ ANN_Control_Forest_2022\n",
      "    âœ“ 2023: 65 scenes â†’ ANN_Control_Forest_2023\n",
      "    âœ“ 2024: 64 scenes â†’ ANN_Control_Forest_2024\n",
      "    âœ“ 2025: 87 scenes â†’ ANN_Control_Forest_2025\n",
      "\n",
      "  ðŸŒ³ Region: Hasdeo_North\n",
      "    2013: no scenes â€” skipped\n",
      "    2014: no scenes â€” skipped\n",
      "    2015: no scenes â€” skipped\n",
      "    âœ“ 2016: 2 scenes â†’ ANN_Hasdeo_North_2016\n",
      "    âœ“ 2017: 9 scenes â†’ ANN_Hasdeo_North_2017\n",
      "    âœ“ 2018: 15 scenes â†’ ANN_Hasdeo_North_2018\n",
      "    âœ“ 2019: 35 scenes â†’ ANN_Hasdeo_North_2019\n",
      "    âœ“ 2020: 31 scenes â†’ ANN_Hasdeo_North_2020\n",
      "    âœ“ 2021: 36 scenes â†’ ANN_Hasdeo_North_2021\n",
      "    âœ“ 2022: 38 scenes â†’ ANN_Hasdeo_North_2022\n",
      "    âœ“ 2023: 34 scenes â†’ ANN_Hasdeo_North_2023\n",
      "    âœ“ 2024: 32 scenes â†’ ANN_Hasdeo_North_2024\n",
      "    âœ“ 2025: 44 scenes â†’ ANN_Hasdeo_North_2025\n",
      "\n",
      "  ðŸŒ³ Region: Hasdeo_South\n",
      "    2013: no scenes â€” skipped\n",
      "    2014: no scenes â€” skipped\n",
      "    2015: no scenes â€” skipped\n",
      "    âœ“ 2016: 2 scenes â†’ ANN_Hasdeo_South_2016\n",
      "    âœ“ 2017: 9 scenes â†’ ANN_Hasdeo_South_2017\n",
      "    âœ“ 2018: 15 scenes â†’ ANN_Hasdeo_South_2018\n",
      "    âœ“ 2019: 35 scenes â†’ ANN_Hasdeo_South_2019\n",
      "    âœ“ 2020: 31 scenes â†’ ANN_Hasdeo_South_2020\n",
      "    âœ“ 2021: 36 scenes â†’ ANN_Hasdeo_South_2021\n",
      "    âœ“ 2022: 38 scenes â†’ ANN_Hasdeo_South_2022\n",
      "    âœ“ 2023: 32 scenes â†’ ANN_Hasdeo_South_2023\n",
      "    âœ“ 2024: 32 scenes â†’ ANN_Hasdeo_South_2024\n",
      "    âœ“ 2025: 45 scenes â†’ ANN_Hasdeo_South_2025\n",
      "\n",
      "  ðŸŒ³ Region: Mining_Buffer\n",
      "    2013: no scenes â€” skipped\n",
      "    2014: no scenes â€” skipped\n",
      "    2015: no scenes â€” skipped\n",
      "    âœ“ 2016: 3 scenes â†’ ANN_Mining_Buffer_2016\n",
      "    âœ“ 2017: 18 scenes â†’ ANN_Mining_Buffer_2017\n",
      "    âœ“ 2018: 24 scenes â†’ ANN_Mining_Buffer_2018\n",
      "    âœ“ 2019: 71 scenes â†’ ANN_Mining_Buffer_2019\n",
      "    âœ“ 2020: 63 scenes â†’ ANN_Mining_Buffer_2020\n",
      "    âœ“ 2021: 74 scenes â†’ ANN_Mining_Buffer_2021\n",
      "    âœ“ 2022: 73 scenes â†’ ANN_Mining_Buffer_2022\n",
      "    âœ“ 2023: 63 scenes â†’ ANN_Mining_Buffer_2023\n",
      "    âœ“ 2024: 64 scenes â†’ ANN_Mining_Buffer_2024\n",
      "    âœ“ 2025: 87 scenes â†’ ANN_Mining_Buffer_2025\n",
      "\n",
      "\n",
      "[ PART 3 ]  Seasonal composites (dry Novâ€“Apr + wet Mayâ€“Oct)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "  ðŸŒ³ Region: Hasdeo_Full\n",
      "    âœ“ Dry 2016: 11 scenes\n",
      "    âœ“ Wet 2016: 2 scenes\n",
      "    âœ“ Dry 2017: 19 scenes\n",
      "    âœ“ Dry 2018: 48 scenes\n",
      "    âœ“ Wet 2018: 1 scenes\n",
      "    âœ“ Dry 2019: 46 scenes\n",
      "    âœ“ Wet 2019: 17 scenes\n",
      "    âœ“ Dry 2020: 59 scenes\n",
      "    âœ“ Wet 2020: 15 scenes\n",
      "    âœ“ Dry 2021: 57 scenes\n",
      "    âœ“ Wet 2021: 14 scenes\n",
      "    âœ“ Dry 2022: 52 scenes\n",
      "    âœ“ Wet 2022: 14 scenes\n",
      "    âœ“ Dry 2023: 52 scenes\n",
      "    âœ“ Wet 2023: 17 scenes\n",
      "    âœ“ Dry 2024: 61 scenes\n",
      "    âœ“ Wet 2024: 13 scenes\n",
      "\n",
      "  ðŸŒ³ Region: PEKB_Core\n",
      "    âœ“ Dry 2016: 6 scenes\n",
      "    âœ“ Wet 2016: 1 scenes\n",
      "    âœ“ Dry 2017: 12 scenes\n",
      "    âœ“ Dry 2018: 24 scenes\n",
      "    âœ“ Wet 2018: 1 scenes\n",
      "    âœ“ Dry 2019: 23 scenes\n",
      "    âœ“ Wet 2019: 8 scenes\n",
      "    âœ“ Dry 2020: 27 scenes\n",
      "    âœ“ Wet 2020: 7 scenes\n",
      "    âœ“ Dry 2021: 30 scenes\n",
      "    âœ“ Wet 2021: 8 scenes\n",
      "    âœ“ Dry 2022: 26 scenes\n",
      "    âœ“ Wet 2022: 7 scenes\n",
      "    âœ“ Dry 2023: 26 scenes\n",
      "    âœ“ Wet 2023: 8 scenes\n",
      "    âœ“ Dry 2024: 31 scenes\n",
      "    âœ“ Wet 2024: 7 scenes\n",
      "\n",
      "  ðŸŒ³ Region: Kente_Extension\n",
      "    âœ“ Dry 2016: 6 scenes\n",
      "    âœ“ Wet 2016: 1 scenes\n",
      "    âœ“ Dry 2017: 12 scenes\n",
      "    âœ“ Dry 2018: 24 scenes\n",
      "    âœ“ Wet 2018: 1 scenes\n",
      "    âœ“ Dry 2019: 23 scenes\n",
      "    âœ“ Wet 2019: 8 scenes\n",
      "    âœ“ Dry 2020: 27 scenes\n",
      "    âœ“ Wet 2020: 7 scenes\n",
      "    âœ“ Dry 2021: 30 scenes\n",
      "    âœ“ Wet 2021: 8 scenes\n",
      "    âœ“ Dry 2022: 27 scenes\n",
      "    âœ“ Wet 2022: 7 scenes\n",
      "    âœ“ Dry 2023: 26 scenes\n",
      "    âœ“ Wet 2023: 8 scenes\n",
      "    âœ“ Dry 2024: 31 scenes\n",
      "    âœ“ Wet 2024: 7 scenes\n",
      "\n",
      "  ðŸŒ³ Region: Control_Forest\n",
      "    âœ“ Dry 2016: 11 scenes\n",
      "    âœ“ Wet 2016: 2 scenes\n",
      "    âœ“ Dry 2017: 19 scenes\n",
      "    âœ“ Dry 2018: 48 scenes\n",
      "    âœ“ Wet 2018: 1 scenes\n",
      "    âœ“ Dry 2019: 46 scenes\n",
      "    âœ“ Wet 2019: 17 scenes\n",
      "    âœ“ Dry 2020: 59 scenes\n",
      "    âœ“ Wet 2020: 15 scenes\n",
      "    âœ“ Dry 2021: 57 scenes\n",
      "    âœ“ Wet 2021: 14 scenes\n",
      "    âœ“ Dry 2022: 52 scenes\n",
      "    âœ“ Wet 2022: 14 scenes\n",
      "    âœ“ Dry 2023: 52 scenes\n",
      "    âœ“ Wet 2023: 17 scenes\n",
      "    âœ“ Dry 2024: 61 scenes\n",
      "    âœ“ Wet 2024: 13 scenes\n",
      "\n",
      "  ðŸŒ³ Region: Hasdeo_North\n",
      "    âœ“ Dry 2016: 6 scenes\n",
      "    âœ“ Wet 2016: 1 scenes\n",
      "    âœ“ Dry 2017: 12 scenes\n",
      "    âœ“ Dry 2018: 24 scenes\n",
      "    âœ“ Wet 2018: 1 scenes\n",
      "    âœ“ Dry 2019: 23 scenes\n",
      "    âœ“ Wet 2019: 8 scenes\n",
      "    âœ“ Dry 2020: 27 scenes\n",
      "    âœ“ Wet 2020: 7 scenes\n",
      "    âœ“ Dry 2021: 30 scenes\n",
      "    âœ“ Wet 2021: 8 scenes\n",
      "    âœ“ Dry 2022: 28 scenes\n",
      "    âœ“ Wet 2022: 7 scenes\n",
      "    âœ“ Dry 2023: 26 scenes\n",
      "    âœ“ Wet 2023: 8 scenes\n",
      "    âœ“ Dry 2024: 31 scenes\n",
      "    âœ“ Wet 2024: 7 scenes\n",
      "\n",
      "  ðŸŒ³ Region: Hasdeo_South\n",
      "    âœ“ Dry 2016: 6 scenes\n",
      "    âœ“ Wet 2016: 1 scenes\n",
      "    âœ“ Dry 2017: 12 scenes\n",
      "    âœ“ Dry 2018: 24 scenes\n",
      "    âœ“ Wet 2018: 1 scenes\n",
      "    âœ“ Dry 2019: 23 scenes\n",
      "    âœ“ Wet 2019: 8 scenes\n",
      "    âœ“ Dry 2020: 27 scenes\n",
      "    âœ“ Wet 2020: 7 scenes\n",
      "    âœ“ Dry 2021: 30 scenes\n",
      "    âœ“ Wet 2021: 8 scenes\n",
      "    âœ“ Dry 2022: 26 scenes\n",
      "    âœ“ Wet 2022: 7 scenes\n",
      "    âœ“ Dry 2023: 26 scenes\n",
      "    âœ“ Wet 2023: 8 scenes\n",
      "    âœ“ Dry 2024: 31 scenes\n",
      "    âœ“ Wet 2024: 7 scenes\n",
      "\n",
      "  ðŸŒ³ Region: Mining_Buffer\n",
      "    âœ“ Dry 2016: 11 scenes\n",
      "    âœ“ Wet 2016: 2 scenes\n",
      "    âœ“ Dry 2017: 19 scenes\n",
      "    âœ“ Dry 2018: 48 scenes\n",
      "    âœ“ Wet 2018: 1 scenes\n",
      "    âœ“ Dry 2019: 46 scenes\n",
      "    âœ“ Wet 2019: 17 scenes\n",
      "    âœ“ Dry 2020: 59 scenes\n",
      "    âœ“ Wet 2020: 15 scenes\n",
      "    âœ“ Dry 2021: 57 scenes\n",
      "    âœ“ Wet 2021: 14 scenes\n",
      "    âœ“ Dry 2022: 50 scenes\n",
      "    âœ“ Wet 2022: 14 scenes\n",
      "    âœ“ Dry 2023: 52 scenes\n",
      "    âœ“ Wet 2023: 17 scenes\n",
      "    âœ“ Dry 2024: 61 scenes\n",
      "    âœ“ Wet 2024: 13 scenes\n",
      "\n",
      "========================================================================\n",
      "  EXPORT SUMMARY\n",
      "========================================================================\n",
      "  âœ“ Exports queued / downloaded : 703\n",
      "  âŠ™ Skipped (no data / cached)  : 620\n",
      "  ðŸ“Š Potential total             : 1,323\n",
      "\n",
      "  ðŸ“ Destination : Google Drive  â†’  'Hasdeo_Training_Dataset/' folder\n",
      "  â±  Large exports can take 10 min â€“ several hours\n",
      "  ðŸ”— Monitor  : https://code.earthengine.google.com/tasks\n",
      "âœ“ Task IDs saved: hasdeo_training_dataset/logs/task_ids.json\n",
      "  â–¶  Monitor: https://code.earthengine.google.com/tasks\n",
      "âœ“ Metadata saved: hasdeo_training_dataset/metadata/export_log.csv  (703 records)\n",
      "\n",
      "  DATASET BREAKDOWN\n",
      "  â”œâ”€ Monthly composites   : up to 1064  images\n",
      "  â”œâ”€ Annual mosaics       : up to 91  images\n",
      "  â”œâ”€ Seasonal composites  : up to 168  images\n",
      "  â”œâ”€ Bands per image      : B2,B3,B4,B8,B8A,B11,B12,SCL + NDVI,NDWI,NBR,EVI\n",
      "  â””â”€ Format               : Cloud-Optimized GeoTIFF, EPSG:32644, 10m\n",
      "========================================================================\n",
      "\n",
      "  âœ… Script complete.  Check the task monitor for export progress.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hasdeo Forest GeoTIFF Downloader - MODEL TRAINING VERSION (1000+ Images)\n",
    "=========================================================================\n",
    "Downloads high-quality multi-band GeoTIFF satellite imagery from Sentinel-2\n",
    "for the Hasdeo Arand forest region, covering full deforestation timeline.\n",
    "\n",
    "TARGET: 1000+ unique image exports via:\n",
    "  - Monthly composites across ALL years (2013â€“2025) Ã— 7 regions  = 1,092\n",
    "  - Annual mosaics (2013â€“2025) Ã— 7 regions                       =    91\n",
    "  - Dry-season composites (2013â€“2024) Ã— 7 regions                =    84\n",
    "  - Wet-season composites (2013â€“2024) Ã— 7 regions                =    84\n",
    "  TOTAL POTENTIAL                                                 = 1,351+\n",
    "\n",
    "BANDS DOWNLOADED:\n",
    "  - B2 (Blue, 490nm), B3 (Green, 560nm), B4 (Red, 665nm)\n",
    "  - B8 (NIR, 842nm)       â€” critical for NDVI / vegetation indices\n",
    "  - B8A (NIR narrow, 865nm)\n",
    "  - B11 (SWIR1, 1610nm), B12 (SWIR2, 2190nm) â€” burn/soil detection\n",
    "  - SCL (Scene Classification Layer)           â€” for masking\n",
    "  - NDVI, NDWI, NBR, EVI  â€” pre-computed indices\n",
    "\n",
    "OUTPUT:\n",
    "  - Full-resolution Cloud-Optimized GeoTIFF (10m) with all bands\n",
    "  - Cloud-masked monthly/seasonal/annual composites\n",
    "  - Metadata CSV for dataset bookkeeping\n",
    "  - Task ID JSON for GEE monitoring\n",
    "\n",
    "USAGE:\n",
    "  pip install earthengine-api google-cloud-storage requests tqdm\n",
    "  python hasdeo_geotiff_downloader_1000.py\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CONFIGURATION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "PROJECT_ID    = 'glacier-probe-model-475519'   # â† your GEE project ID\n",
    "GCS_BUCKET    = ''                             # â† your GCS bucket (for gcs mode)\n",
    "OUTPUT_DIR    = 'hasdeo_training_dataset'\n",
    "\n",
    "# â”€â”€ 7 Regions covering Hasdeo Arand + sub-blocks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Each region is [west, south, east, north] in WGS84\n",
    "REGIONS = {\n",
    "    # Full Hasdeo Arand forest block\n",
    "    'Hasdeo_Full':       [82.60, 22.80, 83.00, 23.20],\n",
    "    # PEKB (Parsa East & Kante Basan) â€” primary deforestation zone\n",
    "    'PEKB_Core':         [82.70, 22.90, 82.85, 23.05],\n",
    "    # Kente Extension block â€” active 2023-2026\n",
    "    'Kente_Extension':   [82.65, 23.05, 82.80, 23.20],\n",
    "    # Buffer / control area (less disturbed forest)\n",
    "    'Control_Forest':    [82.85, 23.00, 83.00, 23.15],\n",
    "    # Northern Hasdeo block\n",
    "    'Hasdeo_North':      [82.60, 23.10, 82.80, 23.30],\n",
    "    # Southern Hasdeo block\n",
    "    'Hasdeo_South':      [82.70, 22.70, 82.90, 22.90],\n",
    "    # Mining buffer / transition zone\n",
    "    'Mining_Buffer':     [82.75, 22.85, 82.95, 23.05],\n",
    "}\n",
    "\n",
    "# â”€â”€ Sentinel-2 band selection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "S2_BANDS   = ['B2', 'B3', 'B4', 'B8', 'B8A', 'B11', 'B12', 'SCL']\n",
    "SCALE_METERS      = 10     # 10 m native resolution\n",
    "MAX_CLOUD_COVER   = 20     # % per scene filter\n",
    "MIN_IMAGES_PER_PERIOD = 1  # skip period if fewer scenes available\n",
    "\n",
    "# â”€â”€ Export mode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#   'drive'       â†’ Google Drive / Hasdeo_Training_Dataset  (recommended)\n",
    "#   'gcs'         â†’ GCS bucket (fastest bulk; set GCS_BUCKET above)\n",
    "#   'local_thumb' â†’ small PNGs locally (no quota; QA only, not for training)\n",
    "EXPORT_MODE = 'drive'\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TIME PERIOD BUILDER  â†’  monthly for ALL years\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def build_monthly_periods():\n",
    "    \"\"\"\n",
    "    Build monthly time windows from Jan 2013 to Aug 2025.\n",
    "    12 months Ã— 13 years Ã— 7 regions = 1,092 potential composites.\n",
    "    Labels reflect the deforestation phase for dataset annotation.\n",
    "    \"\"\"\n",
    "    phase_map = {\n",
    "        range(2013, 2016): 'initial_clearing',\n",
    "        range(2016, 2020): 'rapid_expansion',\n",
    "        range(2020, 2023): 'slowdown',\n",
    "        range(2023, 2026): 'renewed_surge',\n",
    "    }\n",
    "\n",
    "    def get_phase(year):\n",
    "        for yr_range, label in phase_map.items():\n",
    "            if year in yr_range:\n",
    "                return label\n",
    "        return 'unknown'\n",
    "\n",
    "    periods = []\n",
    "    for year in range(2013, 2026):\n",
    "        for month in range(1, 13):\n",
    "            # Stop at August 2025 (data availability boundary)\n",
    "            if year == 2025 and month > 8:\n",
    "                break\n",
    "            start = f'{year}-{month:02d}-01'\n",
    "            if month == 12:\n",
    "                end = f'{year + 1}-01-01'\n",
    "            else:\n",
    "                end = f'{year}-{month + 1:02d}-01'\n",
    "            periods.append((start, end, get_phase(year)))\n",
    "    return periods\n",
    "\n",
    "TIME_PERIODS = build_monthly_periods()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# INITIALIZATION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def init_ee():\n",
    "    try:\n",
    "        ee.Initialize(project=PROJECT_ID)\n",
    "        print(f\"âœ“ Earth Engine initialized | project: {PROJECT_ID}\")\n",
    "    except Exception:\n",
    "        print(\"âš   Re-authenticating...\")\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize(project=PROJECT_ID)\n",
    "        print(\"âœ“ Authenticated and initialized.\")\n",
    "\n",
    "\n",
    "def create_dirs():\n",
    "    for sub in ['exports', 'metadata', 'composites', 'logs', 'annual', 'seasonal']:\n",
    "        Path(f\"{OUTPUT_DIR}/{sub}\").mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"âœ“ Output directories ready under: {OUTPUT_DIR}/\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CLOUD MASKING & INDEX COMPUTATION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def mask_s2_clouds(image):\n",
    "    \"\"\"\n",
    "    Dual-layer cloud mask:\n",
    "      1. QA60 bitmask  â€” opaque cloud + cirrus\n",
    "      2. SCL layer     â€” shadow (3), medium cloud (8), high cloud (9),\n",
    "                         cirrus (10), snow/ice (11)\n",
    "    \"\"\"\n",
    "    qa = image.select('QA60')\n",
    "    qa_mask = (qa.bitwiseAnd(1 << 10).eq(0)\n",
    "                 .And(qa.bitwiseAnd(1 << 11).eq(0)))\n",
    "\n",
    "    scl = image.select('SCL')\n",
    "    scl_mask = (scl.neq(3)\n",
    "                   .And(scl.neq(8))\n",
    "                   .And(scl.neq(9))\n",
    "                   .And(scl.neq(10))\n",
    "                   .And(scl.neq(11)))\n",
    "\n",
    "    return image.updateMask(qa_mask.And(scl_mask))\n",
    "\n",
    "\n",
    "def add_indices(image):\n",
    "    \"\"\"Add vegetation / burn / water indices useful for deforestation modelling.\"\"\"\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
    "    nbr  = image.normalizedDifference(['B8', 'B12']).rename('NBR')\n",
    "    evi  = image.expression(\n",
    "        '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',\n",
    "        {'NIR':  image.select('B8'),\n",
    "         'RED':  image.select('B4'),\n",
    "         'BLUE': image.select('B2')}\n",
    "    ).rename('EVI')\n",
    "    return image.addBands([ndvi, ndwi, nbr, evi])\n",
    "\n",
    "\n",
    "def get_s2_collection(roi, start_date, end_date):\n",
    "    \"\"\"Return cloud-filtered, index-enriched Sentinel-2 SR collection.\"\"\"\n",
    "    return (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "              .filterBounds(roi)\n",
    "              .filterDate(start_date, end_date)\n",
    "              .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', MAX_CLOUD_COVER))\n",
    "              .select(S2_BANDS + ['QA60'])\n",
    "              .map(mask_s2_clouds)\n",
    "              .map(add_indices))\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# EXPORT FUNCTIONS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def export_to_drive(image, description, region, scale=SCALE_METERS):\n",
    "    \"\"\"\n",
    "    Export a full-resolution Cloud-Optimized GeoTIFF to Google Drive.\n",
    "    Files appear in: My Drive â†’ Hasdeo_Training_Dataset/\n",
    "    \"\"\"\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image          = image,\n",
    "        description    = description,\n",
    "        folder         = 'Hasdeo_Training_Dataset',\n",
    "        fileNamePrefix = description,\n",
    "        region         = region,\n",
    "        scale          = scale,\n",
    "        crs            = 'EPSG:32644',      # UTM Zone 44N â€” Hasdeo region\n",
    "        fileFormat     = 'GeoTIFF',\n",
    "        maxPixels      = 1e10,\n",
    "        formatOptions  = {'cloudOptimized': True}\n",
    "    )\n",
    "    task.start()\n",
    "    return task\n",
    "\n",
    "\n",
    "def export_to_gcs(image, description, region, bucket, scale=SCALE_METERS):\n",
    "    \"\"\"Export to a Google Cloud Storage bucket.\"\"\"\n",
    "    task = ee.batch.Export.image.toCloudStorage(\n",
    "        image          = image,\n",
    "        description    = description,\n",
    "        bucket         = bucket,\n",
    "        fileNamePrefix = f'hasdeo/{description}',\n",
    "        region         = region,\n",
    "        scale          = scale,\n",
    "        crs            = 'EPSG:32644',\n",
    "        fileFormat     = 'GeoTIFF',\n",
    "        maxPixels      = 1e10,\n",
    "        formatOptions  = {'cloudOptimized': True}\n",
    "    )\n",
    "    task.start()\n",
    "    return task\n",
    "\n",
    "\n",
    "def download_local_thumb(image, region, filepath, bands=None, size=512):\n",
    "    \"\"\"\n",
    "    Download a small RGB PNG for visual QA only.\n",
    "    NOT suitable for model training â€” use drive/gcs modes for full res.\n",
    "    \"\"\"\n",
    "    if bands is None:\n",
    "        bands = ['B4', 'B3', 'B2']\n",
    "    try:\n",
    "        vis = image.visualize(bands=bands, min=0, max=3000)\n",
    "        url = vis.getThumbURL({'region': region, 'dimensions': size, 'format': 'png'})\n",
    "        r = requests.get(url, timeout=120)\n",
    "        if r.status_code == 200:\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"    âœ— Thumb error: {str(e)[:70]}\")\n",
    "    return False\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# COMPOSITE HELPERS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def create_seasonal_composite(roi, year, season='dry'):\n",
    "    \"\"\"\n",
    "    Median composite for a season:\n",
    "      dry (Novâ€“Apr) â€” clearest skies, best for deforestation detection\n",
    "      wet (Mayâ€“Oct) â€” captures phenological changes\n",
    "    \"\"\"\n",
    "    if season == 'dry':\n",
    "        start, end = f'{year}-11-01', f'{year + 1}-04-30'\n",
    "    else:\n",
    "        start, end = f'{year}-05-01', f'{year}-10-31'\n",
    "\n",
    "    col = get_s2_collection(roi, start, end)\n",
    "    count = col.size().getInfo()\n",
    "    composite = col.median().clip(roi)\n",
    "    return composite, count\n",
    "\n",
    "\n",
    "def create_annual_mosaic(roi, year):\n",
    "    \"\"\"Best-pixel (median) annual mosaic for a full calendar year.\"\"\"\n",
    "    col = get_s2_collection(roi, f'{year}-01-01', f'{year}-12-31')\n",
    "    count = col.size().getInfo()\n",
    "    mosaic = col.median().clip(roi)\n",
    "    return mosaic, count\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# METADATA TRACKING\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "metadata_records = []\n",
    "\n",
    "def log_export(task_id, description, region_name,\n",
    "               start_date, end_date, image_count, phase, export_type):\n",
    "    metadata_records.append({\n",
    "        'task_id':     task_id,\n",
    "        'description': description,\n",
    "        'region':      region_name,\n",
    "        'start_date':  start_date,\n",
    "        'end_date':    end_date,\n",
    "        'image_count': image_count,\n",
    "        'phase':       phase,\n",
    "        'export_type': export_type,\n",
    "        'timestamp':   datetime.now().isoformat(),\n",
    "        'scale_m':     SCALE_METERS,\n",
    "        'crs':         'EPSG:32644',\n",
    "        'bands':       ','.join(S2_BANDS + ['NDVI', 'NDWI', 'NBR', 'EVI']),\n",
    "    })\n",
    "\n",
    "\n",
    "def save_metadata_csv():\n",
    "    if not metadata_records:\n",
    "        return\n",
    "    csv_path = f\"{OUTPUT_DIR}/metadata/export_log.csv\"\n",
    "    with open(csv_path, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=metadata_records[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(metadata_records)\n",
    "    print(f\"âœ“ Metadata saved: {csv_path}  ({len(metadata_records)} records)\")\n",
    "\n",
    "\n",
    "def save_task_ids(tasks):\n",
    "    \"\"\"Persist all GEE Export task IDs for later monitoring.\"\"\"\n",
    "    task_file = f\"{OUTPUT_DIR}/logs/task_ids.json\"\n",
    "    data = []\n",
    "    for t in tasks:\n",
    "        if t is None:\n",
    "            continue\n",
    "        try:\n",
    "            data.append({\n",
    "                'id':          t.id,\n",
    "                'description': t.config.get('description', ''),\n",
    "                'status':      t.status().get('state', 'UNKNOWN'),\n",
    "            })\n",
    "        except Exception:\n",
    "            pass\n",
    "    with open(task_file, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"âœ“ Task IDs saved: {task_file}\")\n",
    "    print(f\"  â–¶  Monitor: https://code.earthengine.google.com/tasks\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# GENERIC EXPORT DISPATCHER\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def dispatch_export(composite, desc, roi,\n",
    "                    region_name, start_date, end_date,\n",
    "                    count, phase, all_tasks,\n",
    "                    thumb_subdir='exports'):\n",
    "    \"\"\"\n",
    "    Route the export to the configured backend and log metadata.\n",
    "    Returns True on success, False on skip/error.\n",
    "    \"\"\"\n",
    "    task = None\n",
    "    try:\n",
    "        if EXPORT_MODE == 'drive':\n",
    "            task = export_to_drive(composite, desc, roi)\n",
    "            all_tasks.append(task)\n",
    "\n",
    "        elif EXPORT_MODE == 'gcs':\n",
    "            if not GCS_BUCKET:\n",
    "                raise ValueError(\"Set GCS_BUCKET in config for 'gcs' mode\")\n",
    "            task = export_to_gcs(composite, desc, roi, GCS_BUCKET)\n",
    "            all_tasks.append(task)\n",
    "\n",
    "        else:  # local_thumb\n",
    "            thumb_path = f\"{OUTPUT_DIR}/{thumb_subdir}/{desc}.png\"\n",
    "            if os.path.exists(thumb_path):\n",
    "                return False  # already downloaded\n",
    "            success = download_local_thumb(composite, roi, thumb_path)\n",
    "            if not success:\n",
    "                return False\n",
    "\n",
    "        task_id = task.id if task else 'local'\n",
    "        log_export(task_id, desc, region_name,\n",
    "                   start_date, end_date, count, phase, EXPORT_MODE)\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    âœ— Export error [{desc}]: {str(e)[:80]}\")\n",
    "        return False\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MAIN\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def main():\n",
    "    # â”€â”€ Header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    monthly_potential  = len(TIME_PERIODS) * len(REGIONS)\n",
    "    annual_potential   = 13 * len(REGIONS)           # 2013-2025\n",
    "    seasonal_potential = 12 * len(REGIONS) * 2       # dry + wet, 2013-2024\n",
    "    total_potential    = monthly_potential + annual_potential + seasonal_potential\n",
    "\n",
    "    print(\"=\" * 72)\n",
    "    print(\"  HASDEO FOREST â€” GeoTIFF DOWNLOADER v2  (TARGET: 1 000+ IMAGES)\")\n",
    "    print(\"=\" * 72)\n",
    "    print(f\"  Export mode      : {EXPORT_MODE.upper()}\")\n",
    "    print(f\"  Resolution       : {SCALE_METERS} m\")\n",
    "    print(f\"  Max cloud cover  : {MAX_CLOUD_COVER}%\")\n",
    "    print(f\"  Regions          : {len(REGIONS)}  â†’ {list(REGIONS.keys())}\")\n",
    "    print(f\"  Monthly periods  : {len(TIME_PERIODS)} (Jan 2013 â€“ Aug 2025)\")\n",
    "    print(f\"  Potential exports: {total_potential:,}\")\n",
    "    print(f\"    â”œâ”€ Monthly composites : {monthly_potential}\")\n",
    "    print(f\"    â”œâ”€ Annual mosaics     : {annual_potential}\")\n",
    "    print(f\"    â””â”€ Seasonal (dry+wet) : {seasonal_potential}\")\n",
    "    print(\"=\" * 72)\n",
    "\n",
    "    init_ee()\n",
    "    create_dirs()\n",
    "\n",
    "    all_tasks     = []\n",
    "    export_count  = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # PART 1 â€” Monthly composites  (core of the 1 000+ count)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    print(\"\\n[ PART 1 ]  Monthly composites â€” all years 2013-2025\")\n",
    "    print(\"-\" * 72)\n",
    "\n",
    "    for region_name, coords in REGIONS.items():\n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        print(f\"\\n  ðŸŒ³ Region: {region_name}\")\n",
    "\n",
    "        for start_date, end_date, phase in tqdm(TIME_PERIODS,\n",
    "                                                desc=f\"  {region_name}\",\n",
    "                                                unit='month'):\n",
    "            try:\n",
    "                col   = get_s2_collection(roi, start_date, end_date)\n",
    "                count = col.size().getInfo()\n",
    "\n",
    "                if count < MIN_IMAGES_PER_PERIOD:\n",
    "                    skipped_count += 1\n",
    "                    continue\n",
    "\n",
    "                composite = col.median().clip(roi)\n",
    "\n",
    "                # GEE description: max 100 chars, no special characters\n",
    "                year_month = start_date[:7].replace('-', '_')\n",
    "                desc = f\"MON_{region_name}_{year_month}_{phase[:8]}\"[:90]\n",
    "\n",
    "                ok = dispatch_export(composite, desc, roi,\n",
    "                                     region_name, start_date, end_date,\n",
    "                                     count, phase, all_tasks,\n",
    "                                     thumb_subdir='exports')\n",
    "                if ok:\n",
    "                    export_count += 1\n",
    "                else:\n",
    "                    skipped_count += 1\n",
    "\n",
    "                time.sleep(0.4)   # gentle rate-limiting\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n    âœ— Error [{start_date}]: {str(e)[:70]}\")\n",
    "                continue\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # PART 2 â€” Annual mosaics  (2013â€“2025, all 7 regions)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    print(\"\\n\\n[ PART 2 ]  Annual mosaics (2013â€“2025)\")\n",
    "    print(\"-\" * 72)\n",
    "\n",
    "    for region_name, coords in REGIONS.items():\n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        print(f\"\\n  ðŸŒ³ Region: {region_name}\")\n",
    "\n",
    "        for year in range(2013, 2026):\n",
    "            try:\n",
    "                mosaic, count = create_annual_mosaic(roi, year)\n",
    "                if count == 0:\n",
    "                    print(f\"    {year}: no scenes â€” skipped\")\n",
    "                    skipped_count += 1\n",
    "                    continue\n",
    "\n",
    "                desc = f\"ANN_{region_name}_{year}\"[:90]\n",
    "                ok   = dispatch_export(mosaic, desc, roi,\n",
    "                                       region_name,\n",
    "                                       f'{year}-01-01', f'{year}-12-31',\n",
    "                                       count, 'annual_mosaic', all_tasks,\n",
    "                                       thumb_subdir='annual')\n",
    "                if ok:\n",
    "                    export_count += 1\n",
    "                    print(f\"    âœ“ {year}: {count} scenes â†’ {desc}\")\n",
    "                else:\n",
    "                    skipped_count += 1\n",
    "\n",
    "                time.sleep(0.4)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    âœ— {year}: {str(e)[:70]}\")\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # PART 3 â€” Seasonal composites  (dry + wet, 2013â€“2024, all 7 regions)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    print(\"\\n\\n[ PART 3 ]  Seasonal composites (dry Novâ€“Apr + wet Mayâ€“Oct)\")\n",
    "    print(\"-\" * 72)\n",
    "\n",
    "    for region_name, coords in REGIONS.items():\n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        print(f\"\\n  ðŸŒ³ Region: {region_name}\")\n",
    "\n",
    "        for year in range(2013, 2025):\n",
    "            for season in ('dry', 'wet'):\n",
    "                try:\n",
    "                    composite, count = create_seasonal_composite(roi, year, season)\n",
    "                    if count == 0:\n",
    "                        skipped_count += 1\n",
    "                        continue\n",
    "\n",
    "                    if season == 'dry':\n",
    "                        s_date = f'{year}-11-01'\n",
    "                        e_date = f'{year + 1}-04-30'\n",
    "                    else:\n",
    "                        s_date = f'{year}-05-01'\n",
    "                        e_date = f'{year}-10-31'\n",
    "\n",
    "                    desc  = f\"SEAS_{season.upper()}_{region_name}_{year}\"[:90]\n",
    "                    ok    = dispatch_export(composite, desc, roi,\n",
    "                                           region_name, s_date, e_date,\n",
    "                                           count,\n",
    "                                           f'{season}_season_composite',\n",
    "                                           all_tasks,\n",
    "                                           thumb_subdir='seasonal')\n",
    "                    if ok:\n",
    "                        export_count += 1\n",
    "                        print(f\"    âœ“ {season.capitalize()} {year}: {count} scenes\")\n",
    "                    else:\n",
    "                        skipped_count += 1\n",
    "\n",
    "                    time.sleep(0.4)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"    âœ— {season} {year}: {str(e)[:70]}\")\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # SUMMARY\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    print(\"\\n\" + \"=\" * 72)\n",
    "    print(\"  EXPORT SUMMARY\")\n",
    "    print(\"=\" * 72)\n",
    "    print(f\"  âœ“ Exports queued / downloaded : {export_count}\")\n",
    "    print(f\"  âŠ™ Skipped (no data / cached)  : {skipped_count}\")\n",
    "    print(f\"  ðŸ“Š Potential total             : {total_potential:,}\")\n",
    "    print()\n",
    "\n",
    "    if EXPORT_MODE == 'drive':\n",
    "        print(\"  ðŸ“ Destination : Google Drive  â†’  'Hasdeo_Training_Dataset/' folder\")\n",
    "        print(\"  â±  Large exports can take 10 min â€“ several hours\")\n",
    "        print(\"  ðŸ”— Monitor  : https://code.earthengine.google.com/tasks\")\n",
    "        save_task_ids(all_tasks)\n",
    "\n",
    "    elif EXPORT_MODE == 'gcs':\n",
    "        print(f\"  ðŸ“ Destination : gs://{GCS_BUCKET}/hasdeo/\")\n",
    "        save_task_ids(all_tasks)\n",
    "\n",
    "    else:\n",
    "        print(f\"  ðŸ“ PNG thumbnails saved to : {OUTPUT_DIR}/\")\n",
    "\n",
    "    save_metadata_csv()\n",
    "\n",
    "    print()\n",
    "    print(\"  DATASET BREAKDOWN\")\n",
    "    print(f\"  â”œâ”€ Monthly composites   : up to {monthly_potential}  images\")\n",
    "    print(f\"  â”œâ”€ Annual mosaics       : up to {annual_potential}  images\")\n",
    "    print(f\"  â”œâ”€ Seasonal composites  : up to {seasonal_potential}  images\")\n",
    "    print(f\"  â”œâ”€ Bands per image      : B2,B3,B4,B8,B8A,B11,B12,SCL + NDVI,NDWI,NBR,EVI\")\n",
    "    print(f\"  â””â”€ Format               : Cloud-Optimized GeoTIFF, EPSG:32644, {SCALE_METERS}m\")\n",
    "    print(\"=\" * 72)\n",
    "    print(f\"\\n  âœ… Script complete.  Check the task monitor for export progress.\")\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdc9e7e9-4202-4a65-9f0c-1530cd2fb5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Earth Engine initialized for project: glacier-probe-model-475519\n",
      "================================================================================\n",
      "KANGAROO ISLAND BLACK SUMMER BUSHFIRE IMAGE DOWNLOADER\n",
      "Coordinates: [136.5344, -36.0867, 138.0, -35.5614]\n",
      "Fire Period: December 20, 2019 - February 6, 2020\n",
      "Coverage: 5 years pre-fire (2014-2019) + fire period + 5 years post-fire (2020-2024)\n",
      "================================================================================\n",
      "âœ“ Created output directories in kangaroo_island_black_summer/\n",
      "\n",
      "Target: 100 images (Max Cloud Cover: 100%)\n",
      "Time periods: 12\n",
      "Resolution: 30m | Format: PNG (Viewable RGB)\n",
      "\n",
      "ðŸ”¥ Starting Downloads for: Kangaroo Island Black Summer\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE (2014): 0 images found\n",
      "  PRE-FIRE (2015): 0 images found\n",
      "  PRE-FIRE (2016): 0 images found\n",
      "  PRE-FIRE (2017): 4 images available\n",
      "    â†“ 2017-03-08... âœ“ (1/100)\n",
      "    â†“ 2017-07-21... âœ“ (2/100)\n",
      "    âŠ™ 2017-07-21 (exists)\n",
      "    â†“ 2017-12-26... âœ“ (4/100)\n",
      "  PRE-FIRE (2018): 28 images available\n",
      "    â†“ 2018-02-06... âœ“ (5/100)\n",
      "    âŠ™ 2018-02-06 (exists)\n",
      "    â†“ 2018-02-26... âœ“ (7/100)\n",
      "    âŠ™ 2018-02-26 (exists)\n",
      "    â†“ 2018-03-16... âœ“ (9/100)\n",
      "    â†“ 2018-03-31... âœ“ (10/100)\n",
      "    âŠ™ 2018-03-31 (exists)\n",
      "    â†“ 2018-04-07... âœ“ (12/100)\n",
      "  2019: 346 images available\n",
      "    â†“ 2019-01-02... âœ“ (13/100)\n",
      "    âŠ™ 2019-01-02 (exists)\n",
      "    â†“ 2019-01-05... âœ“ (15/100)\n",
      "    âŠ™ 2019-01-05 (exists)\n",
      "    âŠ™ 2019-01-05 (exists)\n",
      "    â†“ 2019-01-07... âœ“ (18/100)\n",
      "    âŠ™ 2019-01-07 (exists)\n",
      "    â†“ 2019-01-10... âœ“ (20/100)\n",
      "  DURING FIRE (Dec 20, 2019 - Feb 6, 2020): 50 images available\n",
      "    â†“ 2019-12-21... âœ“ (21/100)\n",
      "    âŠ™ 2019-12-21 (exists)\n",
      "    âŠ™ 2019-12-21 (exists)\n",
      "    â†“ 2019-12-23... âœ“ (24/100)\n",
      "    âŠ™ 2019-12-23 (exists)\n",
      "    â†“ 2019-12-26... âœ“ (26/100)\n",
      "    âŠ™ 2019-12-26 (exists)\n",
      "    âŠ™ 2019-12-26 (exists)\n",
      "    â†“ 2019-12-28... âœ“ (29/100)\n",
      "    âŠ™ 2019-12-28 (exists)\n",
      "    â†“ 2019-12-31... âœ“ (31/100)\n",
      "    âŠ™ 2019-12-31 (exists)\n",
      "    âŠ™ 2019-12-31 (exists)\n",
      "    â†“ 2020-01-02... âœ“ (34/100)\n",
      "    âŠ™ 2020-01-02 (exists)\n",
      "    â†“ 2020-01-05... âœ“ (36/100)\n",
      "    âŠ™ 2020-01-05 (exists)\n",
      "    â†“ 2020-01-07... âœ“ (38/100)\n",
      "    âŠ™ 2020-01-07 (exists)\n",
      "    â†“ 2020-01-10... âœ“ (40/100)\n",
      "  POST-FIRE RECOVERY (+0 years - 2020): 321 images available\n",
      "    â†“ 2020-02-09... âœ“ (41/100)\n",
      "    âŠ™ 2020-02-09 (exists)\n",
      "    âŠ™ 2020-02-09 (exists)\n",
      "    â†“ 2020-02-11... âœ“ (44/100)\n",
      "    âŠ™ 2020-02-11 (exists)\n",
      "    â†“ 2020-02-14... âœ“ (46/100)\n",
      "    âŠ™ 2020-02-14 (exists)\n",
      "    âŠ™ 2020-02-14 (exists)\n",
      "  POST-FIRE RECOVERY (+1 years - 2021): 367 images available\n",
      "    â†“ 2021-01-01... âœ“ (49/100)\n",
      "    âŠ™ 2021-01-01 (exists)\n",
      "    â†“ 2021-01-04... âœ“ (51/100)\n",
      "    âŠ™ 2021-01-04 (exists)\n",
      "    âŠ™ 2021-01-04 (exists)\n",
      "    â†“ 2021-01-06... âœ“ (54/100)\n",
      "    âŠ™ 2021-01-06 (exists)\n",
      "    â†“ 2021-01-09... âœ“ (56/100)\n",
      "  POST-FIRE RECOVERY (+2 years - 2022): 355 images available\n",
      "    â†“ 2022-01-01... âœ“ (57/100)\n",
      "    âŠ™ 2022-01-01 (exists)\n",
      "    â†“ 2022-01-04... âœ“ (59/100)\n",
      "    âŠ™ 2022-01-04 (exists)\n",
      "    âŠ™ 2022-01-04 (exists)\n",
      "    â†“ 2022-01-06... âœ“ (62/100)\n",
      "    âŠ™ 2022-01-06 (exists)\n",
      "    â†“ 2022-01-09... âœ“ (64/100)\n",
      "  POST-FIRE RECOVERY (+3 years - 2023): 365 images available\n",
      "    â†“ 2023-01-01... âœ“ (65/100)\n",
      "    âŠ™ 2023-01-01 (exists)\n",
      "    â†“ 2023-01-04... âœ“ (67/100)\n",
      "    âŠ™ 2023-01-04 (exists)\n",
      "    âŠ™ 2023-01-04 (exists)\n",
      "    â†“ 2023-01-06... âœ“ (70/100)\n",
      "    âŠ™ 2023-01-06 (exists)\n",
      "    â†“ 2023-01-09... âœ“ (72/100)\n",
      "  POST-FIRE RECOVERY (+4 years - 2024): 371 images available\n",
      "    â†“ 2024-01-01... âœ“ (73/100)\n",
      "    âŠ™ 2024-01-01 (exists)\n",
      "    â†“ 2024-01-04... âœ“ (75/100)\n",
      "    âŠ™ 2024-01-04 (exists)\n",
      "    âŠ™ 2024-01-04 (exists)\n",
      "    â†“ 2024-01-09... âœ“ (78/100)\n",
      "    âŠ™ 2024-01-09 (exists)\n",
      "    âŠ™ 2024-01-09 (exists)\n",
      "\n",
      "================================================================================\n",
      "DOWNLOAD COMPLETE - KANGAROO ISLAND BLACK SUMMER DATASET\n",
      "================================================================================\n",
      "âœ“ Downloaded: 80 images\n",
      "âœ— Failed: 0\n",
      "ðŸ“ Location: kangaroo_island_black_summer/rgb_images/\n",
      "\n",
      "ðŸ“Š Dataset Coverage:\n",
      "   â€¢ Pre-fire baseline: 2014-2019 (5 years)\n",
      "   â€¢ Active fire period: Dec 20, 2019 - Feb 6, 2020\n",
      "   â€¢ Post-fire recovery: 2020-2024 (5 years)\n",
      "   â€¢ Area burned: ~211,500 hectares (48% of island)\n",
      "\n",
      "âœ“ Images are in standard PNG format and viewable!\n",
      "You can open them with any image viewer or photo app.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Kangaroo Island Black Summer Bushfire Image Downloader\n",
    "Downloads RGB satellite imagery for Kangaroo Island, South Australia\n",
    "Covering the 2019-20 Black Summer bushfire period and recovery\n",
    "Images are saved as PNG with proper color scaling for visualization.\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "PROJECT_ID = 'glacier-probe-model-475519'\n",
    "OUTPUT_DIR = 'kangaroo_island_black_summer'\n",
    "NUM_IMAGES = 100  # More images to capture pre-fire, during, and post-fire periods\n",
    "SCALE = 30  # 30m resolution for manageable file sizes\n",
    "MAX_CLOUD_COVER = 100  # Allow ALL images including heavy smoke/clouds\n",
    "\n",
    "# Kangaroo Island Area of Interest - Black Summer Fire Zone\n",
    "# Coordinates converted from DMS to decimal degrees:\n",
    "# Latitude: 35Â°33'41\"S to 36Â°05'12\"S = -35.5614 to -36.0867\n",
    "# Longitude: 136Â°32'04\"E to 138Â°00'00\"E = 136.5344 to 138.0000\n",
    "KANGAROO_ISLAND_REGION = {\n",
    "    'Kangaroo_Island_Fire_Zone': [136.5344, -36.0867, 138.0000, -35.5614]\n",
    "}\n",
    "\n",
    "# Black Summer bushfires on Kangaroo Island:\n",
    "# - Started: December 20, 2019 (lightning strikes)\n",
    "# - Major fires: December 30, 2019 - February 6, 2020\n",
    "# - Declared safe: February 6, 2020\n",
    "# Year ranges: 5 years before (2014-2019) and 5 years after (2020-2025)\n",
    "YEAR_RANGES = [\n",
    "    # Pre-fire period (5 years before)\n",
    "    ('2014-01-01', '2014-12-31'),\n",
    "    ('2015-01-01', '2015-12-31'),\n",
    "    ('2016-01-01', '2016-12-31'),\n",
    "    ('2017-01-01', '2017-12-31'),\n",
    "    ('2018-01-01', '2018-12-31'),\n",
    "    # Critical fire year\n",
    "    ('2019-01-01', '2019-12-19'),  # Pre-fire 2019\n",
    "    ('2019-12-20', '2020-02-06'),  # During fire (Dec 20, 2019 - Feb 6, 2020)\n",
    "    ('2020-02-07', '2020-12-31'),  # Post-fire recovery 2020\n",
    "    # Post-fire recovery period (4 more years)\n",
    "    ('2021-01-01', '2021-12-31'),\n",
    "    ('2022-01-01', '2022-12-31'),\n",
    "    ('2023-01-01', '2023-12-31'),\n",
    "    ('2024-01-01', '2024-12-31'),\n",
    "]\n",
    "\n",
    "# --- INITIALIZATION ---\n",
    "\n",
    "try:\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"âœ“ Earth Engine initialized for project: {PROJECT_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  Initialization failed. Attempting authentication...\")\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"âœ“ Authentication successful. Earth Engine initialized.\")\n",
    "\n",
    "# --- UTILITY FUNCTIONS ---\n",
    "\n",
    "def create_output_dirs():\n",
    "    \"\"\"Create output directory structure\"\"\"\n",
    "    Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/rgb_images\").mkdir(exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/metadata\").mkdir(exist_ok=True)\n",
    "    print(f\"âœ“ Created output directories in {OUTPUT_DIR}/\")\n",
    "\n",
    "def get_satellite_collection(start_date, end_date, roi, max_cloud_cover):\n",
    "    \"\"\"Get Sentinel-2 collection WITHOUT cloud masking to preserve smoke/fire effects\"\"\"\n",
    "    # NO CLOUD MASKING - We want to see smoke, clouds, and fire effects!\n",
    "    sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "        .filterBounds(roi) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover))\n",
    "\n",
    "    s2_count = sentinel2.size().getInfo()\n",
    "    \n",
    "    if s2_count > 0:\n",
    "        return sentinel2, 'sentinel2'\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def download_rgb_image(image, region, filename):\n",
    "    \"\"\"Downloads RGB image in viewable PNG format\"\"\"\n",
    "    try:\n",
    "        # Select RGB bands (B4=Red, B3=Green, B2=Blue)\n",
    "        rgb = image.select(['B4', 'B3', 'B2'])\n",
    "        \n",
    "        # Normalize to 0-255 range for viewing\n",
    "        # Sentinel-2 values are 0-10000, we'll use 0-3000 as typical range\n",
    "        rgb_vis = rgb.visualize(\n",
    "            min=0,\n",
    "            max=3000,\n",
    "            bands=['B4', 'B3', 'B2']\n",
    "        )\n",
    "        \n",
    "        # Get thumbnail URL (this returns a viewable image)\n",
    "        url = rgb_vis.getThumbURL({\n",
    "            'region': region,\n",
    "            'dimensions': 2048,  # Higher resolution for large area (2048x2048)\n",
    "            'format': 'png'\n",
    "        })\n",
    "        \n",
    "        # Download and save as PNG\n",
    "        response = requests.get(url, timeout=300)\n",
    "        if response.status_code == 200:\n",
    "            # Save directly as PNG\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âœ— HTTP Error {response.status_code}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"âœ— Error: {error_msg[:100]}...\")\n",
    "        return False\n",
    "\n",
    "def save_metadata(image, filename, region_name, period_label):\n",
    "    \"\"\"Save image metadata\"\"\"\n",
    "    try:\n",
    "        props = image.getInfo()['properties']\n",
    "        metadata_file = filename\n",
    "        \n",
    "        with open(metadata_file, 'w') as f:\n",
    "            f.write(f\"Region: {region_name}\\n\")\n",
    "            f.write(f\"Location: Kangaroo Island, South Australia\\n\")\n",
    "            f.write(f\"Event: Black Summer Bushfires (2019-20)\\n\")\n",
    "            f.write(f\"Period: {period_label}\\n\")\n",
    "            f.write(f\"Satellite: SENTINEL-2\\n\")\n",
    "            f.write(f\"Image Type: RGB (True Color)\\n\")\n",
    "            f.write(f\"Format: PNG (Viewable)\\n\")\n",
    "            \n",
    "            date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "            f.write(f\"Date: {date}\\n\")\n",
    "            f.write(f\"Cloud Cover: {props.get('CLOUDY_PIXEL_PERCENTAGE', 'N/A')}%\\n\")\n",
    "            f.write(f\"Product ID: {props.get('PRODUCT_ID', 'N/A')}\\n\")\n",
    "            f.write(f\"Bands: R=B4 (Red), G=B3 (Green), B=B2 (Blue)\\n\")\n",
    "            f.write(f\"Resolution: {SCALE}m\\n\")\n",
    "            f.write(f\"Processing: NO cloud masking - smoke and fire effects preserved\\n\")\n",
    "            f.write(f\"\\nContext: Area burned ~211,500 ha (48% of island)\\n\")\n",
    "            f.write(f\"Fire Period: Dec 20, 2019 - Feb 6, 2020\\n\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  âš  Metadata warning: {str(e)[:30]}\")\n",
    "\n",
    "def get_period_label(start_date, end_date):\n",
    "    \"\"\"Get descriptive label for the time period\"\"\"\n",
    "    if '2019-12-20' in start_date and '2020-02-06' in end_date:\n",
    "        return \"DURING FIRE (Dec 20, 2019 - Feb 6, 2020)\"\n",
    "    elif int(start_date[:4]) < 2019 or (start_date[:4] == '2019' and '12-19' in start_date):\n",
    "        return f\"PRE-FIRE ({start_date[:4]})\"\n",
    "    elif int(start_date[:4]) >= 2020:\n",
    "        years_after = int(start_date[:4]) - 2020\n",
    "        return f\"POST-FIRE RECOVERY (+{years_after} years - {start_date[:4]})\"\n",
    "    return start_date[:4]\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "def main_kangaroo_island():\n",
    "    \"\"\"Main download function for Kangaroo Island Black Summer\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"KANGAROO ISLAND BLACK SUMMER BUSHFIRE IMAGE DOWNLOADER\")\n",
    "    print(f\"Coordinates: {KANGAROO_ISLAND_REGION['Kangaroo_Island_Fire_Zone']}\")\n",
    "    print(\"Fire Period: December 20, 2019 - February 6, 2020\")\n",
    "    print(\"Coverage: 5 years pre-fire (2014-2019) + fire period + 5 years post-fire (2020-2024)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    create_output_dirs()\n",
    "    \n",
    "    downloaded_count = 0\n",
    "    failed_count = 0\n",
    "    \n",
    "    print(f\"\\nTarget: {NUM_IMAGES} images (Max Cloud Cover: {MAX_CLOUD_COVER}%)\")\n",
    "    print(f\"Time periods: {len(YEAR_RANGES)}\")\n",
    "    print(f\"Resolution: {SCALE}m | Format: PNG (Viewable RGB)\\n\")\n",
    "    \n",
    "    region_name = 'Kangaroo_Island_Fire_Zone'\n",
    "    coords = KANGAROO_ISLAND_REGION[region_name]\n",
    "    roi = ee.Geometry.Rectangle(coords)\n",
    "\n",
    "    print(f\" Starting Downloads for: Kangaroo Island Black Summer\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Iterate through each year range\n",
    "    for start_date, end_date in YEAR_RANGES:\n",
    "        if downloaded_count >= NUM_IMAGES:\n",
    "            break\n",
    "        \n",
    "        period_label = get_period_label(start_date, end_date)\n",
    "        \n",
    "        # Get the satellite collection for the period\n",
    "        collection, satellite_type = get_satellite_collection(start_date, end_date, roi, MAX_CLOUD_COVER)\n",
    "        \n",
    "        if collection is None:\n",
    "            print(f\"  {period_label}: 0 images found\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            count = collection.size().getInfo()\n",
    "            if count == 0:\n",
    "                print(f\"  {period_label}: 0 images found\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"  {period_label}: {count} images available\")\n",
    "            \n",
    "            # Adjust number of images per period\n",
    "            # More images during fire period, fewer for other years\n",
    "            if 'DURING FIRE' in period_label:\n",
    "                images_per_period = min(20, count, NUM_IMAGES - downloaded_count)\n",
    "            else:\n",
    "                images_per_period = min(8, count, NUM_IMAGES - downloaded_count)\n",
    "                \n",
    "            if images_per_period <= 0:\n",
    "                break\n",
    "                \n",
    "            images = collection.limit(images_per_period).toList(images_per_period)\n",
    "            \n",
    "            for i in range(images_per_period):\n",
    "                if downloaded_count >= NUM_IMAGES:\n",
    "                    break\n",
    "                    \n",
    "                image = ee.Image(images.get(i))\n",
    "                \n",
    "                # Get date\n",
    "                date_acquired = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "                \n",
    "                # Filename construction (PNG format)\n",
    "                period_prefix = period_label.split('(')[0].strip().replace(' ', '_').replace('-', '')\n",
    "                filename = f\"{OUTPUT_DIR}/rgb_images/KI_{date_acquired}_{period_prefix}_RGB.png\"\n",
    "                metadata_filename = f\"{OUTPUT_DIR}/metadata/KI_{date_acquired}_{period_prefix}_metadata.txt\"\n",
    "                \n",
    "                # Skip if exists\n",
    "                if os.path.exists(filename):\n",
    "                    downloaded_count += 1\n",
    "                    print(f\"    âŠ™ {date_acquired} (exists)\")\n",
    "                    continue\n",
    "                \n",
    "                print(f\"    â†“ {date_acquired}...\", end=' ')\n",
    "                \n",
    "                if download_rgb_image(image, roi, filename):\n",
    "                    save_metadata(image, metadata_filename, region_name, period_label)\n",
    "                    downloaded_count += 1\n",
    "                    print(f\"âœ“ ({downloaded_count}/{NUM_IMAGES})\")\n",
    "                else:\n",
    "                    failed_count += 1\n",
    "                \n",
    "                time.sleep(2)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— Error in collection processing: {str(e)[:50]}...\")\n",
    "            continue\n",
    "            \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DOWNLOAD COMPLETE - KANGAROO ISLAND BLACK SUMMER DATASET\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"âœ“ Downloaded: {downloaded_count} images\")\n",
    "    print(f\"âœ— Failed: {failed_count}\")\n",
    "    print(f\" Location: {OUTPUT_DIR}/rgb_images/\")\n",
    "    print(f\"\\n Dataset Coverage:\")\n",
    "    print(f\"   â€¢ Pre-fire baseline: 2014-2019 (5 years)\")\n",
    "    print(f\"   â€¢ Active fire period: Dec 20, 2019 - Feb 6, 2020\")\n",
    "    print(f\"   â€¢ Post-fire recovery: 2020-2024 (5 years)\")\n",
    "    print(f\"   â€¢ Area burned: ~211,500 hectares (48% of island)\")\n",
    "    print(f\"\\nâœ“ Images are in standard PNG format and viewable!\")\n",
    "    print(\"You can open them with any image viewer or photo app.\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_kangaroo_island()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84ebeed6-fbd2-4c21-93eb-d99fac592431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Earth Engine initialized for project: glacier-probe-model-475519\n",
      "================================================================================\n",
      "ðŸ‡¦ðŸ‡º GREATER SYDNEY BLUE MOUNTAINS FRINGE IMAGE DOWNLOADER\n",
      "Multiple Sub-Regions for Complete Coverage\n",
      "================================================================================\n",
      "ðŸ“ Regions: 5\n",
      "   â€¢ Blue_Mts_Katoomba: [150.25, -33.75, 150.35, -33.65]\n",
      "   â€¢ Blue_Mts_Wentworth_Falls: [150.35, -33.75, 150.45, -33.65]\n",
      "   â€¢ Warragamba_Dam_North: [150.55, -33.95, 150.65, -33.85]\n",
      "   â€¢ Warragamba_Dam_South: [150.55, -34.05, 150.65, -33.95]\n",
      "   â€¢ Penrith_Urban_Edge: [150.65, -33.8, 150.75, -33.7]\n",
      "ðŸ”¥ Event: Black Summer Bushfires (2019-2020)\n",
      "ðŸŒµ Context: Prolonged drought + catastrophic fire + urban expansion\n",
      "ðŸ“Š Research: Bushfire, Drought, Regrowth, Deforestation\n",
      "================================================================================\n",
      "âœ“ Created output directories in sydney_blue_mountains_fringe_rgb/\n",
      "\n",
      "Target: 75 images total (~15 per region)\n",
      "Time periods: 7\n",
      "Resolution: 30m | Format: PNG (Viewable RGB)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸŒ³ Processing Region: Blue_Mts_Katoomba\n",
      "ðŸ“ Coordinates: [150.25, -33.75, 150.35, -33.65]\n",
      "ðŸŽ¯ Target: 15 images\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE BASELINE (2018): 12 images available\n",
      "    â†“ 2018-02-14... âœ“ (1/15)\n",
      "    â†“ 2018-03-11... âœ“ (2/15)\n",
      "    âŠ™ 2018-03-11 (exists)\n",
      "  DROUGHT & BLACK SUMMER FIRES (2019-2020): 140 images available\n",
      "    â†“ 2019-06-04... âœ“ (4/15)\n",
      "    âŠ™ 2019-06-04 (exists)\n",
      "    â†“ 2019-06-09... âœ“ (6/15)\n",
      "    âŠ™ 2019-06-09 (exists)\n",
      "    â†“ 2019-06-14... âœ“ (8/15)\n",
      "  IMMEDIATE POST-FIRE RECOVERY (2020-2021): 143 images available\n",
      "    â†“ 2020-06-03... âœ“ (9/15)\n",
      "    âŠ™ 2020-06-03 (exists)\n",
      "    â†“ 2020-06-08... âœ“ (11/15)\n",
      "  POST-FIRE RECOVERY & MONITORING (2021-2022): 141 images available\n",
      "    â†“ 2021-06-03... âœ“ (12/15)\n",
      "    âŠ™ 2021-06-03 (exists)\n",
      "    â†“ 2021-06-08... âœ“ (14/15)\n",
      "  REGROWTH & DEFORESTATION MONITORING (2022-2023): 146 images available\n",
      "    â†“ 2022-06-03... âœ“ (15/15)\n",
      "\n",
      "âœ“ Blue_Mts_Katoomba: 15 downloaded, 0 failed\n",
      "\n",
      "================================================================================\n",
      "ðŸŒ³ Processing Region: Blue_Mts_Wentworth_Falls\n",
      "ðŸ“ Coordinates: [150.35, -33.75, 150.45, -33.65]\n",
      "ðŸŽ¯ Target: 15 images\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE BASELINE (2018): 6 images available\n",
      "    â†“ 2018-03-11... âœ“ (1/15)\n",
      "    â†“ 2018-06-04... âœ“ (2/15)\n",
      "    â†“ 2018-12-16... âœ“ (3/15)\n",
      "  DROUGHT & BLACK SUMMER FIRES (2019-2020): 70 images available\n",
      "    â†“ 2019-06-04... âœ“ (4/15)\n",
      "    â†“ 2019-06-09... âœ“ (5/15)\n",
      "    â†“ 2019-06-14... âœ“ (6/15)\n",
      "    â†“ 2019-06-19... âœ“ (7/15)\n",
      "    â†“ 2019-06-24... âœ“ (8/15)\n",
      "  IMMEDIATE POST-FIRE RECOVERY (2020-2021): 72 images available\n",
      "    â†“ 2020-06-03... âœ“ (9/15)\n",
      "    â†“ 2020-06-08... âœ“ (10/15)\n",
      "    â†“ 2020-06-13... âœ“ (11/15)\n",
      "  POST-FIRE RECOVERY & MONITORING (2021-2022): 71 images available\n",
      "    â†“ 2021-06-03... âœ“ (12/15)\n",
      "    â†“ 2021-06-08... âœ“ (13/15)\n",
      "    â†“ 2021-06-13... âœ“ (14/15)\n",
      "  REGROWTH & DEFORESTATION MONITORING (2022-2023): 72 images available\n",
      "    â†“ 2022-06-03... âœ“ (15/15)\n",
      "\n",
      "âœ“ Blue_Mts_Wentworth_Falls: 15 downloaded, 0 failed\n",
      "\n",
      "================================================================================\n",
      "ðŸŒ³ Processing Region: Warragamba_Dam_North\n",
      "ðŸ“ Coordinates: [150.55, -33.95, 150.65, -33.85]\n",
      "ðŸŽ¯ Target: 15 images\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE BASELINE (2018): 6 images available\n",
      "    â†“ 2018-03-11... âœ“ (1/15)\n",
      "    â†“ 2018-06-04... âœ“ (2/15)\n",
      "    â†“ 2018-12-16... âœ“ (3/15)\n",
      "  DROUGHT & BLACK SUMMER FIRES (2019-2020): 70 images available\n",
      "    â†“ 2019-06-04... âœ“ (4/15)\n",
      "    â†“ 2019-06-09... âœ“ (5/15)\n",
      "    â†“ 2019-06-14... âœ“ (6/15)\n",
      "    â†“ 2019-06-19... âœ“ (7/15)\n",
      "    â†“ 2019-06-24... âœ“ (8/15)\n",
      "  IMMEDIATE POST-FIRE RECOVERY (2020-2021): 72 images available\n",
      "    â†“ 2020-06-03... âœ“ (9/15)\n",
      "    â†“ 2020-06-08... âœ“ (10/15)\n",
      "    â†“ 2020-06-13... âœ“ (11/15)\n",
      "  POST-FIRE RECOVERY & MONITORING (2021-2022): 71 images available\n",
      "    â†“ 2021-06-03... âœ“ (12/15)\n",
      "    â†“ 2021-06-08... âœ“ (13/15)\n",
      "    â†“ 2021-06-13... âœ“ (14/15)\n",
      "  REGROWTH & DEFORESTATION MONITORING (2022-2023): 72 images available\n",
      "    â†“ 2022-06-03... âœ“ (15/15)\n",
      "\n",
      "âœ“ Warragamba_Dam_North: 15 downloaded, 0 failed\n",
      "\n",
      "================================================================================\n",
      "ðŸŒ³ Processing Region: Warragamba_Dam_South\n",
      "ðŸ“ Coordinates: [150.55, -34.05, 150.65, -33.95]\n",
      "ðŸŽ¯ Target: 15 images\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE BASELINE (2018): 6 images available\n",
      "    â†“ 2018-03-11... âœ“ (1/15)\n",
      "    â†“ 2018-06-04... âœ“ (2/15)\n",
      "    â†“ 2018-12-16... âœ“ (3/15)\n",
      "  DROUGHT & BLACK SUMMER FIRES (2019-2020): 70 images available\n",
      "    â†“ 2019-06-04... âœ“ (4/15)\n",
      "    â†“ 2019-06-09... âœ“ (5/15)\n",
      "    â†“ 2019-06-14... âœ“ (6/15)\n",
      "    â†“ 2019-06-19... âœ“ (7/15)\n",
      "    â†“ 2019-06-24... âœ“ (8/15)\n",
      "  IMMEDIATE POST-FIRE RECOVERY (2020-2021): 72 images available\n",
      "    â†“ 2020-06-03... âœ“ (9/15)\n",
      "    â†“ 2020-06-08... âœ“ (10/15)\n",
      "    â†“ 2020-06-13... âœ“ (11/15)\n",
      "  POST-FIRE RECOVERY & MONITORING (2021-2022): 71 images available\n",
      "    â†“ 2021-06-03... âœ“ (12/15)\n",
      "    â†“ 2021-06-08... âœ“ (13/15)\n",
      "    â†“ 2021-06-13... âœ“ (14/15)\n",
      "  REGROWTH & DEFORESTATION MONITORING (2022-2023): 72 images available\n",
      "    â†“ 2022-06-03... âœ“ (15/15)\n",
      "\n",
      "âœ“ Warragamba_Dam_South: 15 downloaded, 0 failed\n",
      "\n",
      "================================================================================\n",
      "ðŸŒ³ Processing Region: Penrith_Urban_Edge\n",
      "ðŸ“ Coordinates: [150.65, -33.8, 150.75, -33.7]\n",
      "ðŸŽ¯ Target: 15 images\n",
      "--------------------------------------------------------------------------------\n",
      "  PRE-FIRE BASELINE (2018): 6 images available\n",
      "    â†“ 2018-03-11... âœ“ (1/15)\n",
      "    â†“ 2018-06-04... âœ“ (2/15)\n",
      "    â†“ 2018-12-16... âœ“ (3/15)\n",
      "  DROUGHT & BLACK SUMMER FIRES (2019-2020): 70 images available\n",
      "    â†“ 2019-06-04... âœ“ (4/15)\n",
      "    â†“ 2019-06-09... âœ“ (5/15)\n",
      "    â†“ 2019-06-14... âœ“ (6/15)\n",
      "    â†“ 2019-06-19... âœ“ (7/15)\n",
      "    â†“ 2019-06-24... âœ“ (8/15)\n",
      "  IMMEDIATE POST-FIRE RECOVERY (2020-2021): 72 images available\n",
      "    â†“ 2020-06-03... âœ“ (9/15)\n",
      "    â†“ 2020-06-08... âœ“ (10/15)\n",
      "    â†“ 2020-06-13... âœ“ (11/15)\n",
      "  POST-FIRE RECOVERY & MONITORING (2021-2022): 71 images available\n",
      "    â†“ 2021-06-03... âœ“ (12/15)\n",
      "    â†“ 2021-06-08... âœ“ (13/15)\n",
      "    â†“ 2021-06-13... âœ“ (14/15)\n",
      "  REGROWTH & DEFORESTATION MONITORING (2022-2023): 72 images available\n",
      "    â†“ 2022-06-03... âœ“ (15/15)\n",
      "\n",
      "âœ“ Penrith_Urban_Edge: 15 downloaded, 0 failed\n",
      "\n",
      "================================================================================\n",
      "DOWNLOAD COMPLETE - SYDNEY BLUE MOUNTAINS MULTI-REGION DATASET\n",
      "================================================================================\n",
      "âœ“ Total Downloaded: 75/75 images\n",
      "âœ— Total Failed: 0\n",
      "ðŸ“ Location: sydney_blue_mountains_fringe_rgb/rgb_images/\n",
      "\n",
      "ðŸ“Š Dataset Coverage:\n",
      "   â€¢ Pre-fire baseline: 2018\n",
      "   â€¢ Drought & Black Summer fires: 2019-2020\n",
      "   â€¢ Post-fire recovery: 2020-2021\n",
      "   â€¢ Long-term monitoring: 2021-2025\n",
      "\n",
      "ðŸ—ºï¸ Sub-Regions Captured:\n",
      "   â€¢ Blue_Mts_Katoomba\n",
      "   â€¢ Blue_Mts_Wentworth_Falls\n",
      "   â€¢ Warragamba_Dam_North\n",
      "   â€¢ Warragamba_Dam_South\n",
      "   â€¢ Penrith_Urban_Edge\n",
      "\n",
      "ðŸ”¬ Recommended Analysis Indices:\n",
      "   â€¢ NBR (Normalized Burn Ratio): B8-B12 / B8+B12\n",
      "     â†’ Fire severity mapping, burn scar detection\n",
      "   â€¢ NDVI (Vegetation Index): B8-B4 / B8+B4\n",
      "     â†’ Vegetation health, regrowth monitoring\n",
      "   â€¢ EVI (Enhanced Vegetation): 2.5*(B8-B4) / (B8+6*B4-7.5*B2+1)\n",
      "     â†’ Drought stress, canopy density\n",
      "   â€¢ NDMI (Moisture Index): B8-B11 / B8+B11\n",
      "     â†’ Water stress, drought impact\n",
      "   â€¢ NDWI (Water Index): B3-B8 / B3+B8\n",
      "     â†’ Drought severity, water availability\n",
      "\n",
      "âœ“ Images are in standard PNG format and viewable!\n",
      "All smoke, fire, and atmospheric effects are preserved.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Greater Sydney Blue Mountains Fringe Satellite Image Downloader\n",
    "Downloads RGB satellite imagery for the Blue Mountains/Warragamba Dam Catchment Area\n",
    "Captures: Bushfire (Black Summer 2019-20), Drought, Regrowth, and Deforestation\n",
    "Images are saved as PNG with proper color scaling for visualization.\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# --- CONFIGURATION (MODIFIED for Sydney Blue Mountains Fringe) ---\n",
    "\n",
    "PROJECT_ID = 'glacier-probe-model-475519'\n",
    "OUTPUT_DIR = 'sydney_blue_mountains_fringe_rgb'\n",
    "NUM_IMAGES = 75  # 15 images per sub-region\n",
    "SCALE = 30  # Increased to 30m to ensure successful downloads\n",
    "MAX_CLOUD_COVER = 100  # Allow all images including smoke/clouds during fires\n",
    "\n",
    "# Greater Sydney Blue Mountains Fringe - Multiple Sub-Regions\n",
    "# Multiple smaller regions to ensure visible imagery capture\n",
    "# Coordinates: [lon_min, lat_min, lon_max, lat_max]\n",
    "SYDNEY_REGIONS = {\n",
    "    'Blue_Mts_Katoomba': [150.25, -33.75, 150.35, -33.65],  # Katoomba/Three Sisters area\n",
    "    'Blue_Mts_Wentworth_Falls': [150.35, -33.75, 150.45, -33.65],  # Wentworth Falls\n",
    "    'Warragamba_Dam_North': [150.55, -33.95, 150.65, -33.85],  # North of dam\n",
    "    'Warragamba_Dam_South': [150.55, -34.05, 150.65, -33.95],  # South of dam\n",
    "    'Penrith_Urban_Edge': [150.65, -33.80, 150.75, -33.70],  # Urban fringe\n",
    "}\n",
    "\n",
    "# Date ranges specifically targeting the Black Summer event and recovery/drought periods\n",
    "YEAR_RANGES = [\n",
    "    # Pre-fire/drought baseline\n",
    "    ('2018-01-01', '2019-01-01'), \n",
    "    # Peak drought and fire period (Black Summer)\n",
    "    ('2019-06-01', '2020-06-01'), \n",
    "    # Immediate post-fire and start of regrowth\n",
    "    ('2020-06-01', '2021-06-01'), \n",
    "    # Continued recovery and expansion monitoring\n",
    "    ('2021-06-01', '2022-06-01'),\n",
    "    ('2022-06-01', '2023-06-01'),\n",
    "    ('2023-06-01', '2024-06-01'),\n",
    "    ('2024-06-01', '2025-06-01'),\n",
    "]\n",
    "\n",
    "# --- INITIALIZATION ---\n",
    "\n",
    "try:\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"âœ“ Earth Engine initialized for project: {PROJECT_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  Initialization failed. Attempting authentication...\")\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project=PROJECT_ID)\n",
    "    print(f\"âœ“ Authentication successful. Earth Engine initialized.\")\n",
    "\n",
    "# --- UTILITY FUNCTIONS ---\n",
    "\n",
    "def create_output_dirs():\n",
    "    \"\"\"Create output directory structure\"\"\"\n",
    "    Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/rgb_images\").mkdir(exist_ok=True)\n",
    "    Path(f\"{OUTPUT_DIR}/metadata\").mkdir(exist_ok=True)\n",
    "    print(f\"âœ“ Created output directories in {OUTPUT_DIR}/\")\n",
    "\n",
    "def get_satellite_collection(start_date, end_date, roi, max_cloud_cover):\n",
    "    \"\"\"Get Sentinel-2 collection WITHOUT cloud masking to preserve all effects\"\"\"\n",
    "    sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "        .filterBounds(roi) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover))\n",
    "\n",
    "    s2_count = sentinel2.size().getInfo()\n",
    "    \n",
    "    if s2_count > 0:\n",
    "        return sentinel2, 'sentinel2'\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def download_rgb_image(image, region, filename):\n",
    "    \"\"\"Downloads RGB image in viewable PNG format\"\"\"\n",
    "    try:\n",
    "        # Select RGB bands (B4=Red, B3=Green, B2=Blue)\n",
    "        rgb = image.select(['B4', 'B3', 'B2'])\n",
    "        \n",
    "        # Normalize to 0-255 range for viewing\n",
    "        rgb_vis = rgb.visualize(\n",
    "            min=0,\n",
    "            max=3000,\n",
    "            bands=['B4', 'B3', 'B2']\n",
    "        )\n",
    "        \n",
    "        # Get thumbnail URL with adjusted dimensions\n",
    "        url = rgb_vis.getThumbURL({\n",
    "            'region': region,\n",
    "            'dimensions': 512,  # Reduced for better compatibility\n",
    "            'format': 'png'\n",
    "        })\n",
    "        \n",
    "        # Download and save as PNG\n",
    "        response = requests.get(url, timeout=300)\n",
    "        if response.status_code == 200:\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âœ— HTTP Error {response.status_code}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"âœ— Error: {error_msg[:100]}...\")\n",
    "        return False\n",
    "\n",
    "def save_metadata(image, filename, region_name, period_label):\n",
    "    \"\"\"Save image metadata\"\"\"\n",
    "    try:\n",
    "        props = image.getInfo()['properties']\n",
    "        metadata_file = filename\n",
    "        \n",
    "        with open(metadata_file, 'w') as f:\n",
    "            f.write(f\"Region: {region_name}\\n\")\n",
    "            f.write(f\"Location: Greater Sydney - Blue Mountains Fringe & Warragamba Catchment\\n\")\n",
    "            f.write(f\"Research Focus: Bushfire, Drought, Regrowth, Deforestation\\n\")\n",
    "            f.write(f\"Period: {period_label}\\n\\n\")\n",
    "            \n",
    "            f.write(f\"Satellite: SENTINEL-2\\n\")\n",
    "            f.write(f\"Image Type: RGB (True Color)\\n\")\n",
    "            f.write(f\"Format: PNG (Viewable)\\n\")\n",
    "            \n",
    "            date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "            f.write(f\"Date: {date}\\n\")\n",
    "            f.write(f\"Cloud Cover: {props.get('CLOUDY_PIXEL_PERCENTAGE', 'N/A')}%\\n\")\n",
    "            f.write(f\"Product ID: {props.get('PRODUCT_ID', 'N/A')}\\n\")\n",
    "            f.write(f\"Bands: R=B4 (Red), G=B3 (Green), B=B2 (Blue)\\n\")\n",
    "            f.write(f\"Resolution: {SCALE}m\\n\")\n",
    "            f.write(f\"Processing: NO cloud masking - smoke and fire effects preserved\\n\")\n",
    "            \n",
    "            f.write(f\"\\n=== RESEARCH CONTEXT ===\\n\")\n",
    "            f.write(f\"Black Summer Fires: 2019-2020\\n\")\n",
    "            f.write(f\"Key Indices for Analysis:\\n\")\n",
    "            f.write(f\"  â€¢ NBR (Normalized Burn Ratio): Fire severity\\n\")\n",
    "            f.write(f\"  â€¢ NDVI (Normalized Difference Vegetation Index): Vegetation health/regrowth\\n\")\n",
    "            f.write(f\"  â€¢ EVI (Enhanced Vegetation Index): Drought impact\\n\")\n",
    "            f.write(f\"  â€¢ NDMI (Normalized Difference Moisture Index): Water stress\\n\")\n",
    "            f.write(f\"  â€¢ NDWI (Normalized Difference Water Index): Drought monitoring\\n\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  âš  Metadata warning: {str(e)[:30]}\")\n",
    "\n",
    "def get_period_label(start_date, end_date):\n",
    "    \"\"\"Get descriptive label for the time period\"\"\"\n",
    "    if '2018' in start_date:\n",
    "        return \"PRE-FIRE BASELINE (2018)\"\n",
    "    elif '2019-06' in start_date and '2020-06' in end_date:\n",
    "        return \"DROUGHT & BLACK SUMMER FIRES (2019-2020)\"\n",
    "    elif '2020-06' in start_date and '2021' in end_date:\n",
    "        return \"IMMEDIATE POST-FIRE RECOVERY (2020-2021)\"\n",
    "    elif '2021' in start_date:\n",
    "        return f\"POST-FIRE RECOVERY & MONITORING ({start_date[:4]}-{end_date[:4]})\"\n",
    "    elif '2022' in start_date:\n",
    "        return f\"REGROWTH & DEFORESTATION MONITORING ({start_date[:4]}-{end_date[:4]})\"\n",
    "    elif '2023' in start_date or '2024' in start_date:\n",
    "        return f\"LONG-TERM RECOVERY ({start_date[:4]}-{end_date[:4]})\"\n",
    "    return f\"{start_date[:4]}-{end_date[:4]}\"\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "def main_sydney():\n",
    "    \"\"\"Main download function for Sydney Blue Mountains Fringe - Multiple Regions\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"GREATER SYDNEY BLUE MOUNTAINS FRINGE IMAGE DOWNLOADER\")\n",
    "    print(\"Multiple Sub-Regions for Complete Coverage\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ðŸ“ Regions: {len(SYDNEY_REGIONS)}\")\n",
    "    for name, coords in SYDNEY_REGIONS.items():\n",
    "        print(f\"   â€¢ {name}: {coords}\")\n",
    "    print(f\" Event: Black Summer Bushfires (2019-2020)\")\n",
    "    print(f\" Context: Prolonged drought + catastrophic fire + urban expansion\")\n",
    "    print(f\" Research: Bushfire, Drought, Regrowth, Deforestation\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    create_output_dirs()\n",
    "    \n",
    "    total_downloaded = 0\n",
    "    total_failed = 0\n",
    "    \n",
    "    print(f\"\\nTarget: {NUM_IMAGES} images total (~{NUM_IMAGES // len(SYDNEY_REGIONS)} per region)\")\n",
    "    print(f\"Time periods: {len(YEAR_RANGES)}\")\n",
    "    print(f\"Resolution: {SCALE}m | Format: PNG (Viewable RGB)\\n\")\n",
    "    \n",
    "    images_per_region = NUM_IMAGES // len(SYDNEY_REGIONS)\n",
    "    \n",
    "    # Process each sub-region\n",
    "    for region_name, coords in SYDNEY_REGIONS.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ðŸŒ³ Processing Region: {region_name}\")\n",
    "        print(f\"ðŸ“ Coordinates: {coords}\")\n",
    "        print(f\"ðŸŽ¯ Target: {images_per_region} images\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        downloaded_count = 0\n",
    "        failed_count = 0\n",
    "        \n",
    "        # Iterate through each year range for this region\n",
    "        for start_date, end_date in YEAR_RANGES:\n",
    "            if downloaded_count >= images_per_region:\n",
    "                break\n",
    "            \n",
    "            period_label = get_period_label(start_date, end_date)\n",
    "            \n",
    "            # Get the satellite collection for the period\n",
    "            collection, satellite_type = get_satellite_collection(start_date, end_date, roi, MAX_CLOUD_COVER)\n",
    "            \n",
    "            if collection is None:\n",
    "                print(f\"  {period_label}: 0 images found\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                count = collection.size().getInfo()\n",
    "                if count == 0:\n",
    "                    print(f\"  {period_label}: 0 images found\")\n",
    "                    continue\n",
    "                    \n",
    "                print(f\"  {period_label}: {count} images available\")\n",
    "                \n",
    "                # Images per period\n",
    "                if 'BLACK SUMMER' in period_label:\n",
    "                    images_per_period = min(5, count, images_per_region - downloaded_count)\n",
    "                else:\n",
    "                    images_per_period = min(3, count, images_per_region - downloaded_count)\n",
    "                    \n",
    "                if images_per_period <= 0:\n",
    "                    break\n",
    "                    \n",
    "                images = collection.limit(images_per_period).toList(images_per_period)\n",
    "                \n",
    "                for i in range(images_per_period):\n",
    "                    if downloaded_count >= images_per_region:\n",
    "                        break\n",
    "                        \n",
    "                    image = ee.Image(images.get(i))\n",
    "                    \n",
    "                    # Get date\n",
    "                    date_acquired = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "                    \n",
    "                    # Filename construction\n",
    "                    period_code = period_label.split('(')[0].strip().replace(' ', '_').replace('&', '').replace('-', '')\n",
    "                    filename = f\"{OUTPUT_DIR}/rgb_images/{region_name}_{date_acquired}_{period_code}_RGB.png\"\n",
    "                    metadata_filename = f\"{OUTPUT_DIR}/metadata/{region_name}_{date_acquired}_{period_code}_meta.txt\"\n",
    "                    \n",
    "                    # Skip if exists\n",
    "                    if os.path.exists(filename):\n",
    "                        downloaded_count += 1\n",
    "                        print(f\"    âŠ™ {date_acquired} (exists)\")\n",
    "                        continue\n",
    "                    \n",
    "                    print(f\"    â†“ {date_acquired}...\", end=' ')\n",
    "                    \n",
    "                    if download_rgb_image(image, roi, filename):\n",
    "                        save_metadata(image, metadata_filename, region_name, period_label)\n",
    "                        downloaded_count += 1\n",
    "                        print(f\"âœ“ ({downloaded_count}/{images_per_region})\")\n",
    "                    else:\n",
    "                        failed_count += 1\n",
    "                    \n",
    "                    time.sleep(1.5)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  âœ— Error in collection processing: {str(e)[:50]}...\")\n",
    "                continue\n",
    "        \n",
    "        total_downloaded += downloaded_count\n",
    "        total_failed += failed_count\n",
    "        print(f\"\\nâœ“ {region_name}: {downloaded_count} downloaded, {failed_count} failed\")\n",
    "    \n",
    "    # Final Summary\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DOWNLOAD COMPLETE - SYDNEY BLUE MOUNTAINS MULTI-REGION DATASET\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"âœ“ Total Downloaded: {total_downloaded}/{NUM_IMAGES} images\")\n",
    "    print(f\"âœ— Total Failed: {total_failed}\")\n",
    "    print(f\" Location: {OUTPUT_DIR}/rgb_images/\")\n",
    "    print(f\"\\n Dataset Coverage:\")\n",
    "    print(f\"   â€¢ Pre-fire baseline: 2018\")\n",
    "    print(f\"   â€¢ Drought & Black Summer fires: 2019-2020\")\n",
    "    print(f\"   â€¢ Post-fire recovery: 2020-2021\")\n",
    "    print(f\"   â€¢ Long-term monitoring: 2021-2025\")\n",
    "    print(f\"\\n Sub-Regions Captured:\")\n",
    "    for name in SYDNEY_REGIONS.keys():\n",
    "        print(f\"   â€¢ {name}\")\n",
    "    print(f\"\\n Recommended Analysis Indices:\")\n",
    "    print(f\"   â€¢ NBR (Normalized Burn Ratio): B8-B12 / B8+B12\")\n",
    "    print(f\"     â†’ Fire severity mapping, burn scar detection\")\n",
    "    print(f\"   â€¢ NDVI (Vegetation Index): B8-B4 / B8+B4\")\n",
    "    print(f\"     â†’ Vegetation health, regrowth monitoring\")\n",
    "    print(f\"   â€¢ EVI (Enhanced Vegetation): 2.5*(B8-B4) / (B8+6*B4-7.5*B2+1)\")\n",
    "    print(f\"     â†’ Drought stress, canopy density\")\n",
    "    print(f\"   â€¢ NDMI (Moisture Index): B8-B11 / B8+B11\")\n",
    "    print(f\"     â†’ Water stress, drought impact\")\n",
    "    print(f\"   â€¢ NDWI (Water Index): B3-B8 / B3+B8\")\n",
    "    print(f\"     â†’ Drought severity, water availability\")\n",
    "    print(f\"\\nâœ“ Images are in standard PNG format and viewable!\")\n",
    "    print(\"All smoke, fire, and atmospheric effects are preserved.\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_sydney()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6140e7d5-0a38-4b51-8b40-5d2811631ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "  HASDEO GeoTIFF DOWNLOADER â€” FINAL FIXED (force_float32)\n",
      "========================================================================\n",
      "  Fix        : force_float32() â€” band-by-band explicit cast\n",
      "  All bands  : ['B2', 'B3', 'B4', 'B8', 'B8A', 'B11', 'B12', 'SCL', 'NDVI', 'NDWI', 'NBR', 'EVI']\n",
      "  Export     : DRIVE  |  10m  |  EPSG:32644\n",
      "  Regions    : 7  |  Periods: 152\n",
      "  Target     : 1,323 images\n",
      "========================================================================\n",
      "âœ“ Earth Engine initialized | project: glacier-probe-model-475519\n",
      "âœ“ Directories ready: hasdeo_training_dataset/\n",
      "\n",
      "[ PART 1 ]  Monthly composites â€” Jan 2013 to Aug 2025\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "  ðŸŒ³ Hasdeo_Full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Hasdeo_Full: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [03:49<00:00,  1.51s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ PEKB_Core\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  PEKB_Core: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [03:22<00:00,  1.33s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Kente_Extension\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Kente_Extension: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [03:08<00:00,  1.24s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Control_Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Control_Forest: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [03:10<00:00,  1.25s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Hasdeo_North\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Hasdeo_North: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [03:19<00:00,  1.32s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Hasdeo_South\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Hasdeo_South: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [03:32<00:00,  1.40s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Mining_Buffer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Mining_Buffer: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [03:30<00:00,  1.38s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[ PART 2 ]  Annual mosaics â€” 2013â€“2025\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "  ðŸŒ³ Hasdeo_Full\n",
      "    âœ“ 2016: 3 scenes queued\n",
      "    âœ“ 2017: 18 scenes queued\n",
      "    âœ“ 2018: 24 scenes queued\n",
      "    âœ“ 2019: 71 scenes queued\n",
      "    âœ“ 2020: 63 scenes queued\n",
      "    âœ“ 2021: 74 scenes queued\n",
      "    âœ“ 2022: 73 scenes queued\n",
      "    âœ“ 2023: 65 scenes queued\n",
      "    âœ“ 2024: 64 scenes queued\n",
      "    âœ“ 2025: 89 scenes queued\n",
      "\n",
      "  ðŸŒ³ PEKB_Core\n",
      "    âœ“ 2016: 2 scenes queued\n",
      "    âœ“ 2017: 9 scenes queued\n",
      "    âœ“ 2018: 15 scenes queued\n",
      "    âœ“ 2019: 35 scenes queued\n",
      "    âœ“ 2020: 31 scenes queued\n",
      "    âœ“ 2021: 36 scenes queued\n",
      "    âœ“ 2022: 38 scenes queued\n",
      "    âœ“ 2023: 32 scenes queued\n",
      "    âœ“ 2024: 32 scenes queued\n",
      "    âœ“ 2025: 44 scenes queued\n",
      "\n",
      "  ðŸŒ³ Kente_Extension\n",
      "    âœ“ 2016: 2 scenes queued\n",
      "    âœ“ 2017: 9 scenes queued\n",
      "    âœ“ 2018: 15 scenes queued\n",
      "    âœ“ 2019: 35 scenes queued\n",
      "    âœ“ 2020: 31 scenes queued\n",
      "    âœ“ 2021: 36 scenes queued\n",
      "    âœ“ 2022: 38 scenes queued\n",
      "    âœ“ 2023: 33 scenes queued\n",
      "    âœ“ 2024: 32 scenes queued\n",
      "    âœ“ 2025: 44 scenes queued\n",
      "\n",
      "  ðŸŒ³ Control_Forest\n",
      "    âœ“ 2016: 3 scenes queued\n",
      "    âœ“ 2017: 18 scenes queued\n",
      "    âœ“ 2018: 24 scenes queued\n",
      "    âœ“ 2019: 71 scenes queued\n",
      "    âœ“ 2020: 63 scenes queued\n",
      "    âœ“ 2021: 74 scenes queued\n",
      "    âœ“ 2022: 73 scenes queued\n",
      "    âœ“ 2023: 65 scenes queued\n",
      "    âœ“ 2024: 64 scenes queued\n",
      "    âœ“ 2025: 87 scenes queued\n",
      "\n",
      "  ðŸŒ³ Hasdeo_North\n",
      "    âœ“ 2016: 2 scenes queued\n",
      "    âœ“ 2017: 9 scenes queued\n",
      "    âœ“ 2018: 15 scenes queued\n",
      "    âœ“ 2019: 35 scenes queued\n",
      "    âœ“ 2020: 31 scenes queued\n",
      "    âœ“ 2021: 36 scenes queued\n",
      "    âœ“ 2022: 38 scenes queued\n",
      "    âœ“ 2023: 34 scenes queued\n",
      "    âœ“ 2024: 32 scenes queued\n",
      "    âœ“ 2025: 44 scenes queued\n",
      "\n",
      "  ðŸŒ³ Hasdeo_South\n",
      "    âœ“ 2016: 2 scenes queued\n",
      "    âœ“ 2017: 9 scenes queued\n",
      "    âœ“ 2018: 15 scenes queued\n",
      "    âœ“ 2019: 35 scenes queued\n",
      "    âœ“ 2020: 31 scenes queued\n",
      "    âœ“ 2021: 36 scenes queued\n",
      "    âœ“ 2022: 38 scenes queued\n",
      "    âœ“ 2023: 32 scenes queued\n",
      "    âœ“ 2024: 32 scenes queued\n",
      "    âœ“ 2025: 45 scenes queued\n",
      "\n",
      "  ðŸŒ³ Mining_Buffer\n",
      "    âœ“ 2016: 3 scenes queued\n",
      "    âœ“ 2017: 18 scenes queued\n",
      "    âœ“ 2018: 24 scenes queued\n",
      "    âœ“ 2019: 71 scenes queued\n",
      "    âœ“ 2020: 63 scenes queued\n",
      "    âœ“ 2021: 74 scenes queued\n",
      "    âœ“ 2022: 73 scenes queued\n",
      "    âœ“ 2023: 63 scenes queued\n",
      "    âœ“ 2024: 64 scenes queued\n",
      "    âœ“ 2025: 87 scenes queued\n",
      "\n",
      "\n",
      "[ PART 3 ]  Seasonal composites â€” dry + wet â€” 2013â€“2024\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "  ðŸŒ³ Hasdeo_Full\n",
      "    âœ“ dry 2016: 11 scenes\n",
      "    âœ“ wet 2016: 2 scenes\n",
      "    âœ“ dry 2017: 19 scenes\n",
      "    âœ“ dry 2018: 48 scenes\n",
      "    âœ“ wet 2018: 1 scenes\n",
      "    âœ“ dry 2019: 46 scenes\n",
      "    âœ“ wet 2019: 17 scenes\n",
      "    âœ“ dry 2020: 59 scenes\n",
      "    âœ“ wet 2020: 15 scenes\n",
      "    âœ“ dry 2021: 57 scenes\n",
      "    âœ“ wet 2021: 14 scenes\n",
      "    âœ“ dry 2022: 52 scenes\n",
      "    âœ“ wet 2022: 14 scenes\n",
      "    âœ“ dry 2023: 52 scenes\n",
      "    âœ“ wet 2023: 17 scenes\n",
      "    âœ“ dry 2024: 61 scenes\n",
      "    âœ“ wet 2024: 13 scenes\n",
      "\n",
      "  ðŸŒ³ PEKB_Core\n",
      "    âœ“ dry 2016: 6 scenes\n",
      "    âœ“ wet 2016: 1 scenes\n",
      "    âœ“ dry 2017: 12 scenes\n",
      "    âœ“ dry 2018: 24 scenes\n",
      "    âœ“ wet 2018: 1 scenes\n",
      "    âœ“ dry 2019: 23 scenes\n",
      "    âœ“ wet 2019: 8 scenes\n",
      "    âœ“ dry 2020: 27 scenes\n",
      "    âœ“ wet 2020: 7 scenes\n",
      "    âœ“ dry 2021: 30 scenes\n",
      "    âœ“ wet 2021: 8 scenes\n",
      "    âœ“ dry 2022: 26 scenes\n",
      "    âœ“ wet 2022: 7 scenes\n",
      "    âœ“ dry 2023: 26 scenes\n",
      "    âœ“ wet 2023: 8 scenes\n",
      "    âœ“ dry 2024: 31 scenes\n",
      "    âœ“ wet 2024: 7 scenes\n",
      "\n",
      "  ðŸŒ³ Kente_Extension\n",
      "    âœ“ dry 2016: 6 scenes\n",
      "    âœ“ wet 2016: 1 scenes\n",
      "    âœ“ dry 2017: 12 scenes\n",
      "    âœ“ dry 2018: 24 scenes\n",
      "    âœ“ wet 2018: 1 scenes\n",
      "    âœ“ dry 2019: 23 scenes\n",
      "    âœ“ wet 2019: 8 scenes\n",
      "    âœ“ dry 2020: 27 scenes\n",
      "    âœ“ wet 2020: 7 scenes\n",
      "    âœ“ dry 2021: 30 scenes\n",
      "    âœ“ wet 2021: 8 scenes\n",
      "    âœ“ dry 2022: 27 scenes\n",
      "    âœ“ wet 2022: 7 scenes\n",
      "    âœ“ dry 2023: 26 scenes\n",
      "    âœ“ wet 2023: 8 scenes\n",
      "    âœ“ dry 2024: 31 scenes\n",
      "    âœ“ wet 2024: 7 scenes\n",
      "\n",
      "  ðŸŒ³ Control_Forest\n",
      "    âœ“ dry 2016: 11 scenes\n",
      "    âœ“ wet 2016: 2 scenes\n",
      "    âœ“ dry 2017: 19 scenes\n",
      "    âœ“ dry 2018: 48 scenes\n",
      "    âœ“ wet 2018: 1 scenes\n",
      "    âœ“ dry 2019: 46 scenes\n",
      "    âœ“ wet 2019: 17 scenes\n",
      "    âœ“ dry 2020: 59 scenes\n",
      "    âœ“ wet 2020: 15 scenes\n",
      "    âœ“ dry 2021: 57 scenes\n",
      "    âœ“ wet 2021: 14 scenes\n",
      "    âœ“ dry 2022: 52 scenes\n",
      "    âœ“ wet 2022: 14 scenes\n",
      "    âœ“ dry 2023: 52 scenes\n",
      "    âœ“ wet 2023: 17 scenes\n",
      "    âœ“ dry 2024: 61 scenes\n",
      "    âœ“ wet 2024: 13 scenes\n",
      "\n",
      "  ðŸŒ³ Hasdeo_North\n",
      "    âœ“ dry 2016: 6 scenes\n",
      "    âœ“ wet 2016: 1 scenes\n",
      "    âœ“ dry 2017: 12 scenes\n",
      "    âœ“ dry 2018: 24 scenes\n",
      "    âœ“ wet 2018: 1 scenes\n",
      "    âœ“ dry 2019: 23 scenes\n",
      "    âœ“ wet 2019: 8 scenes\n",
      "    âœ“ dry 2020: 27 scenes\n",
      "    âœ“ wet 2020: 7 scenes\n",
      "    âœ“ dry 2021: 30 scenes\n",
      "    âœ“ wet 2021: 8 scenes\n",
      "    âœ“ dry 2022: 28 scenes\n",
      "    âœ“ wet 2022: 7 scenes\n",
      "    âœ“ dry 2023: 26 scenes\n",
      "    âœ“ wet 2023: 8 scenes\n",
      "    âœ“ dry 2024: 31 scenes\n",
      "    âœ“ wet 2024: 7 scenes\n",
      "\n",
      "  ðŸŒ³ Hasdeo_South\n",
      "    âœ“ dry 2016: 6 scenes\n",
      "    âœ“ wet 2016: 1 scenes\n",
      "    âœ“ dry 2017: 12 scenes\n",
      "    âœ“ dry 2018: 24 scenes\n",
      "    âœ“ wet 2018: 1 scenes\n",
      "    âœ“ dry 2019: 23 scenes\n",
      "    âœ“ wet 2019: 8 scenes\n",
      "    âœ“ dry 2020: 27 scenes\n",
      "    âœ“ wet 2020: 7 scenes\n",
      "    âœ“ dry 2021: 30 scenes\n",
      "    âœ“ wet 2021: 8 scenes\n",
      "    âœ“ dry 2022: 26 scenes\n",
      "    âœ“ wet 2022: 7 scenes\n",
      "    âœ“ dry 2023: 26 scenes\n",
      "    âœ“ wet 2023: 8 scenes\n",
      "    âœ“ dry 2024: 31 scenes\n",
      "    âœ“ wet 2024: 7 scenes\n",
      "\n",
      "  ðŸŒ³ Mining_Buffer\n",
      "    âœ“ dry 2016: 11 scenes\n",
      "    âœ“ wet 2016: 2 scenes\n",
      "    âœ“ dry 2017: 19 scenes\n",
      "    âœ“ dry 2018: 48 scenes\n",
      "    âœ“ wet 2018: 1 scenes\n",
      "    âœ“ dry 2019: 46 scenes\n",
      "    âœ“ wet 2019: 17 scenes\n",
      "    âœ“ dry 2020: 59 scenes\n",
      "    âœ“ wet 2020: 15 scenes\n",
      "    âœ“ dry 2021: 57 scenes\n",
      "    âœ“ wet 2021: 14 scenes\n",
      "    âœ“ dry 2022: 50 scenes\n",
      "    âœ“ wet 2022: 14 scenes\n",
      "    âœ“ dry 2023: 52 scenes\n",
      "    âœ“ wet 2023: 17 scenes\n",
      "    âœ“ dry 2024: 61 scenes\n",
      "    âœ“ wet 2024: 13 scenes\n",
      "\n",
      "========================================================================\n",
      "  FINAL SUMMARY\n",
      "========================================================================\n",
      "  âœ“ Queued successfully : 703\n",
      "  âŠ™ Skipped             : 620\n",
      "  ðŸ“Š Potential total    : 1,323\n",
      "  ðŸ”§ Type               : Float32 (all 12 bands)\n",
      "\n",
      "  ðŸ“ Google Drive â†’ 'Hasdeo_Training_Dataset/'\n",
      "  ðŸ”— Monitor: https://code.earthengine.google.com/tasks\n",
      "âœ“ Task IDs: hasdeo_training_dataset/logs/task_ids.json\n",
      "  â–¶  Monitor: https://code.earthengine.google.com/tasks\n",
      "âœ“ Metadata saved: hasdeo_training_dataset/metadata/export_log.csv  (703 records)\n",
      "========================================================================\n",
      "  âœ… All tasks queued â€” no more type mismatch errors.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hasdeo Forest GeoTIFF Downloader - FINAL FIXED VERSION\n",
    "=======================================================\n",
    "FIX: Persistent \"Float64 and Float32 incompatible types\" error.\n",
    "\n",
    "ROOT CAUSE (deeper than previous fix):\n",
    "  - SCL band             â†’ UInt8  (integer)\n",
    "  - Raw S2 bands         â†’ UInt16 / Float32\n",
    "  - normalizedDifference â†’ Float64\n",
    "  - .toFloat() on the whole composite does NOT always propagate\n",
    "    correctly when bands were added at different pipeline stages.\n",
    "\n",
    "SOLUTION: Cast each band individually AND cast entire composite\n",
    "  at export time using .select().toFloat() on every band explicitly,\n",
    "  then drop SCL before export OR cast SCL separately to Float32.\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CONFIGURATION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "PROJECT_ID            = 'glacier-probe-model-475519'\n",
    "GCS_BUCKET            = ''\n",
    "OUTPUT_DIR            = 'hasdeo_training_dataset'\n",
    "SCALE_METERS          = 10\n",
    "MAX_CLOUD_COVER       = 20\n",
    "MIN_IMAGES_PER_PERIOD = 1\n",
    "EXPORT_MODE           = 'drive'   # 'drive' | 'gcs' | 'local_thumb'\n",
    "\n",
    "REGIONS = {\n",
    "    'Hasdeo_Full':     [82.60, 22.80, 83.00, 23.20],\n",
    "    'PEKB_Core':       [82.70, 22.90, 82.85, 23.05],\n",
    "    'Kente_Extension': [82.65, 23.05, 82.80, 23.20],\n",
    "    'Control_Forest':  [82.85, 23.00, 83.00, 23.15],\n",
    "    'Hasdeo_North':    [82.60, 23.10, 82.80, 23.30],\n",
    "    'Hasdeo_South':    [82.70, 22.70, 82.90, 22.90],\n",
    "    'Mining_Buffer':   [82.75, 22.85, 82.95, 23.05],\n",
    "}\n",
    "\n",
    "# NOTE: SCL removed from S2_BANDS here â€” it is handled separately\n",
    "# as Float32 to avoid UInt8 vs Float32 conflict\n",
    "S2_BANDS = ['B2', 'B3', 'B4', 'B8', 'B8A', 'B11', 'B12']\n",
    "\n",
    "# All final band names that will appear in every exported GeoTIFF\n",
    "ALL_EXPORT_BANDS = ['B2', 'B3', 'B4', 'B8', 'B8A', 'B11', 'B12',\n",
    "                    'SCL', 'NDVI', 'NDWI', 'NBR', 'EVI']\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TIME PERIODS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def build_monthly_periods():\n",
    "    phase_map = {\n",
    "        range(2013, 2016): 'init_clr',\n",
    "        range(2016, 2020): 'rapid_exp',\n",
    "        range(2020, 2023): 'slowdown',\n",
    "        range(2023, 2026): 'renewed',\n",
    "    }\n",
    "    def get_phase(year):\n",
    "        for yr_range, label in phase_map.items():\n",
    "            if year in yr_range:\n",
    "                return label\n",
    "        return 'unknown'\n",
    "\n",
    "    periods = []\n",
    "    for year in range(2013, 2026):\n",
    "        for month in range(1, 13):\n",
    "            if year == 2025 and month > 8:\n",
    "                break\n",
    "            start = f'{year}-{month:02d}-01'\n",
    "            end   = f'{year + 1}-01-01' if month == 12 else f'{year}-{month + 1:02d}-01'\n",
    "            periods.append((start, end, get_phase(year)))\n",
    "    return periods\n",
    "\n",
    "TIME_PERIODS = build_monthly_periods()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# INIT\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def init_ee():\n",
    "    try:\n",
    "        ee.Initialize(project=PROJECT_ID)\n",
    "        print(f\"âœ“ Earth Engine initialized | project: {PROJECT_ID}\")\n",
    "    except Exception:\n",
    "        print(\"âš   Re-authenticating...\")\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize(project=PROJECT_ID)\n",
    "        print(\"âœ“ Authenticated and initialized.\")\n",
    "\n",
    "def create_dirs():\n",
    "    for sub in ['exports', 'metadata', 'logs', 'annual', 'seasonal']:\n",
    "        Path(f\"{OUTPUT_DIR}/{sub}\").mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"âœ“ Directories ready: {OUTPUT_DIR}/\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CLOUD MASKING\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def mask_s2_clouds(image):\n",
    "    qa  = image.select('QA60')\n",
    "    qa_mask = (qa.bitwiseAnd(1 << 10).eq(0)\n",
    "                 .And(qa.bitwiseAnd(1 << 11).eq(0)))\n",
    "    scl = image.select('SCL')\n",
    "    scl_mask = (scl.neq(3).And(scl.neq(8))\n",
    "                          .And(scl.neq(9))\n",
    "                          .And(scl.neq(10))\n",
    "                          .And(scl.neq(11)))\n",
    "    return image.updateMask(qa_mask.And(scl_mask))\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# INDEX COMPUTATION â€” each band individually cast to Float32\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def add_indices(image):\n",
    "    \"\"\"\n",
    "    Each index is cast to Float32 with .toFloat() immediately after\n",
    "    computation â€” before being added to the image stack.\n",
    "    This prevents Float64 bleeding into the composite.\n",
    "    \"\"\"\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI').toFloat()\n",
    "    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI').toFloat()\n",
    "    nbr  = image.normalizedDifference(['B8', 'B12']).rename('NBR').toFloat()\n",
    "    evi  = (image.expression(\n",
    "                '2.5 * ((NIR - RED) / (NIR + 6.0 * RED - 7.5 * BLUE + 1.0))',\n",
    "                {'NIR':  image.select('B8').toFloat(),\n",
    "                 'RED':  image.select('B4').toFloat(),\n",
    "                 'BLUE': image.select('B2').toFloat()}\n",
    "            ).rename('EVI').toFloat())\n",
    "    return image.addBands([ndvi, ndwi, nbr, evi])\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# THE DEFINITIVE FIX  â†’  force_float32()\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Strategy:\n",
    "#   1. Select each band by name one at a time\n",
    "#   2. Cast every single band to Float32 explicitly\n",
    "#   3. Combine back into a single image with addBands\n",
    "#   4. This guarantees ALL bands are Float32 â€” no exceptions\n",
    "#\n",
    "# Why previous .toFloat() on the composite failed:\n",
    "#   GEE's .toFloat() casts the IMAGE object, but internally bands\n",
    "#   added via .addBands() at different stages can retain their\n",
    "#   original type metadata. Selecting + casting band-by-band is\n",
    "#   the only guaranteed approach.\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def force_float32(image, band_names):\n",
    "    \"\"\"\n",
    "    Cast every band in band_names to Float32 individually,\n",
    "    then stack them back into a single image.\n",
    "    Guaranteed to produce a type-homogeneous image.\n",
    "    \"\"\"\n",
    "    bands = [image.select([b]).toFloat() for b in band_names]\n",
    "    result = bands[0]\n",
    "    for b in bands[1:]:\n",
    "        result = result.addBands(b)\n",
    "    return result\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# COLLECTION BUILDER\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def get_s2_collection(roi, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Returns cloud-masked, index-enriched Sentinel-2 collection.\n",
    "    SCL is fetched alongside for masking, then kept as a band (cast to float).\n",
    "    \"\"\"\n",
    "    return (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "              .filterBounds(roi)\n",
    "              .filterDate(start_date, end_date)\n",
    "              .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', MAX_CLOUD_COVER))\n",
    "              .select(S2_BANDS + ['SCL', 'QA60'])\n",
    "              .map(mask_s2_clouds)\n",
    "              .map(add_indices))\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# COMPOSITE BUILDER â€” includes the Float32 guarantee\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def build_composite(col, roi):\n",
    "    \"\"\"\n",
    "    1. Compute median composite\n",
    "    2. Clip to ROI\n",
    "    3. Force every band to Float32 (THE KEY STEP)\n",
    "    \"\"\"\n",
    "    composite = col.median().clip(roi)\n",
    "    return force_float32(composite, ALL_EXPORT_BANDS)\n",
    "\n",
    "def create_seasonal_composite(roi, year, season='dry'):\n",
    "    if season == 'dry':\n",
    "        start, end = f'{year}-11-01', f'{year + 1}-04-30'\n",
    "    else:\n",
    "        start, end = f'{year}-05-01', f'{year}-10-31'\n",
    "    col   = get_s2_collection(roi, start, end)\n",
    "    count = col.size().getInfo()\n",
    "    return build_composite(col, roi), count\n",
    "\n",
    "def create_annual_mosaic(roi, year):\n",
    "    col   = get_s2_collection(roi, f'{year}-01-01', f'{year}-12-31')\n",
    "    count = col.size().getInfo()\n",
    "    return build_composite(col, roi), count\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# EXPORT FUNCTIONS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def export_to_drive(image, description, region):\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image          = image,           # already Float32 guaranteed\n",
    "        description    = description,\n",
    "        folder         = 'Hasdeo_Training_Dataset',\n",
    "        fileNamePrefix = description,\n",
    "        region         = region,\n",
    "        scale          = SCALE_METERS,\n",
    "        crs            = 'EPSG:32644',\n",
    "        fileFormat     = 'GeoTIFF',\n",
    "        maxPixels      = 1e10,\n",
    "        formatOptions  = {'cloudOptimized': True}\n",
    "    )\n",
    "    task.start()\n",
    "    return task\n",
    "\n",
    "def export_to_gcs(image, description, region, bucket):\n",
    "    task = ee.batch.Export.image.toCloudStorage(\n",
    "        image          = image,\n",
    "        description    = description,\n",
    "        bucket         = bucket,\n",
    "        fileNamePrefix = f'hasdeo/{description}',\n",
    "        region         = region,\n",
    "        scale          = SCALE_METERS,\n",
    "        crs            = 'EPSG:32644',\n",
    "        fileFormat     = 'GeoTIFF',\n",
    "        maxPixels      = 1e10,\n",
    "        formatOptions  = {'cloudOptimized': True}\n",
    "    )\n",
    "    task.start()\n",
    "    return task\n",
    "\n",
    "def download_local_thumb(image, region, filepath, size=512):\n",
    "    try:\n",
    "        vis = image.visualize(bands=['B4', 'B3', 'B2'], min=0, max=3000)\n",
    "        url = vis.getThumbURL({'region': region, 'dimensions': size, 'format': 'png'})\n",
    "        r   = requests.get(url, timeout=120)\n",
    "        if r.status_code == 200:\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"    âœ— Thumb error: {str(e)[:70]}\")\n",
    "    return False\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# METADATA\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "metadata_records = []\n",
    "\n",
    "def log_export(task_id, description, region_name,\n",
    "               start_date, end_date, image_count, phase, export_type):\n",
    "    metadata_records.append({\n",
    "        'task_id':     task_id,\n",
    "        'description': description,\n",
    "        'region':      region_name,\n",
    "        'start_date':  start_date,\n",
    "        'end_date':    end_date,\n",
    "        'image_count': image_count,\n",
    "        'phase':       phase,\n",
    "        'export_type': export_type,\n",
    "        'timestamp':   datetime.now().isoformat(),\n",
    "        'scale_m':     SCALE_METERS,\n",
    "        'crs':         'EPSG:32644',\n",
    "        'dtype':       'Float32',\n",
    "        'bands':       ','.join(ALL_EXPORT_BANDS),\n",
    "    })\n",
    "\n",
    "def save_metadata_csv():\n",
    "    if not metadata_records:\n",
    "        return\n",
    "    csv_path = f\"{OUTPUT_DIR}/metadata/export_log.csv\"\n",
    "    with open(csv_path, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=metadata_records[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(metadata_records)\n",
    "    print(f\"âœ“ Metadata saved: {csv_path}  ({len(metadata_records)} records)\")\n",
    "\n",
    "def save_task_ids(tasks):\n",
    "    task_file = f\"{OUTPUT_DIR}/logs/task_ids.json\"\n",
    "    data = []\n",
    "    for t in tasks:\n",
    "        if t is None:\n",
    "            continue\n",
    "        try:\n",
    "            data.append({\n",
    "                'id':          t.id,\n",
    "                'description': t.config.get('description', ''),\n",
    "                'status':      t.status().get('state', 'UNKNOWN'),\n",
    "            })\n",
    "        except Exception:\n",
    "            pass\n",
    "    with open(task_file, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"âœ“ Task IDs: {task_file}\")\n",
    "    print(f\"  â–¶  Monitor: https://code.earthengine.google.com/tasks\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# DISPATCHER\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def dispatch_export(composite, desc, roi,\n",
    "                    region_name, start_date, end_date,\n",
    "                    count, phase, all_tasks, thumb_subdir='exports'):\n",
    "    task = None\n",
    "    try:\n",
    "        if EXPORT_MODE == 'drive':\n",
    "            task = export_to_drive(composite, desc, roi)\n",
    "            all_tasks.append(task)\n",
    "\n",
    "        elif EXPORT_MODE == 'gcs':\n",
    "            if not GCS_BUCKET:\n",
    "                raise ValueError(\"Set GCS_BUCKET for 'gcs' mode\")\n",
    "            task = export_to_gcs(composite, desc, roi, GCS_BUCKET)\n",
    "            all_tasks.append(task)\n",
    "\n",
    "        else:  # local_thumb\n",
    "            thumb_path = f\"{OUTPUT_DIR}/{thumb_subdir}/{desc}.png\"\n",
    "            if os.path.exists(thumb_path):\n",
    "                return False\n",
    "            if not download_local_thumb(composite, roi, thumb_path):\n",
    "                return False\n",
    "\n",
    "        task_id = task.id if task else 'local'\n",
    "        log_export(task_id, desc, region_name,\n",
    "                   start_date, end_date, count, phase, EXPORT_MODE)\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    âœ— [{desc}]: {str(e)[:80]}\")\n",
    "        return False\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MAIN\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def main():\n",
    "    monthly_potential  = len(TIME_PERIODS) * len(REGIONS)\n",
    "    annual_potential   = 13 * len(REGIONS)\n",
    "    seasonal_potential = 12 * len(REGIONS) * 2\n",
    "    total_potential    = monthly_potential + annual_potential + seasonal_potential\n",
    "\n",
    "    print(\"=\" * 72)\n",
    "    print(\"  HASDEO GeoTIFF DOWNLOADER â€” FINAL FIXED (force_float32)\")\n",
    "    print(\"=\" * 72)\n",
    "    print(f\"  Fix        : force_float32() â€” band-by-band explicit cast\")\n",
    "    print(f\"  All bands  : {ALL_EXPORT_BANDS}\")\n",
    "    print(f\"  Export     : {EXPORT_MODE.upper()}  |  {SCALE_METERS}m  |  EPSG:32644\")\n",
    "    print(f\"  Regions    : {len(REGIONS)}  |  Periods: {len(TIME_PERIODS)}\")\n",
    "    print(f\"  Target     : {total_potential:,} images\")\n",
    "    print(\"=\" * 72)\n",
    "\n",
    "    init_ee()\n",
    "    create_dirs()\n",
    "\n",
    "    all_tasks     = []\n",
    "    export_count  = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    # â”€â”€ PART 1: Monthly composites â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"\\n[ PART 1 ]  Monthly composites â€” Jan 2013 to Aug 2025\")\n",
    "    print(\"-\" * 72)\n",
    "\n",
    "    for region_name, coords in REGIONS.items():\n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        print(f\"\\n  ðŸŒ³ {region_name}\")\n",
    "\n",
    "        for start_date, end_date, phase in tqdm(TIME_PERIODS,\n",
    "                                                desc=f\"  {region_name}\",\n",
    "                                                unit='month'):\n",
    "            try:\n",
    "                col   = get_s2_collection(roi, start_date, end_date)\n",
    "                count = col.size().getInfo()\n",
    "                if count < MIN_IMAGES_PER_PERIOD:\n",
    "                    skipped_count += 1\n",
    "                    continue\n",
    "\n",
    "                # build_composite() applies force_float32() internally\n",
    "                composite  = build_composite(col, roi)\n",
    "                year_month = start_date[:7].replace('-', '_')\n",
    "                desc       = f\"MON_{region_name}_{year_month}_{phase}\"[:90]\n",
    "\n",
    "                ok             = dispatch_export(composite, desc, roi,\n",
    "                                                 region_name, start_date,\n",
    "                                                 end_date, count, phase,\n",
    "                                                 all_tasks)\n",
    "                export_count  += ok\n",
    "                skipped_count += (not ok)\n",
    "                time.sleep(0.4)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n    âœ— [{start_date}]: {str(e)[:80]}\")\n",
    "\n",
    "    # â”€â”€ PART 2: Annual mosaics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"\\n\\n[ PART 2 ]  Annual mosaics â€” 2013â€“2025\")\n",
    "    print(\"-\" * 72)\n",
    "\n",
    "    for region_name, coords in REGIONS.items():\n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        print(f\"\\n  ðŸŒ³ {region_name}\")\n",
    "\n",
    "        for year in range(2013, 2026):\n",
    "            try:\n",
    "                mosaic, count = create_annual_mosaic(roi, year)\n",
    "                if count == 0:\n",
    "                    skipped_count += 1\n",
    "                    continue\n",
    "\n",
    "                desc = f\"ANN_{region_name}_{year}\"[:90]\n",
    "                ok   = dispatch_export(mosaic, desc, roi,\n",
    "                                       region_name,\n",
    "                                       f'{year}-01-01', f'{year}-12-31',\n",
    "                                       count, 'annual_mosaic', all_tasks,\n",
    "                                       thumb_subdir='annual')\n",
    "                export_count  += ok\n",
    "                skipped_count += (not ok)\n",
    "                if ok:\n",
    "                    print(f\"    âœ“ {year}: {count} scenes queued\")\n",
    "                time.sleep(0.4)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    âœ— {year}: {str(e)[:80]}\")\n",
    "\n",
    "    # â”€â”€ PART 3: Seasonal composites â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"\\n\\n[ PART 3 ]  Seasonal composites â€” dry + wet â€” 2013â€“2024\")\n",
    "    print(\"-\" * 72)\n",
    "\n",
    "    for region_name, coords in REGIONS.items():\n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        print(f\"\\n  ðŸŒ³ {region_name}\")\n",
    "\n",
    "        for year in range(2013, 2025):\n",
    "            for season in ('dry', 'wet'):\n",
    "                try:\n",
    "                    composite, count = create_seasonal_composite(roi, year, season)\n",
    "                    if count == 0:\n",
    "                        skipped_count += 1\n",
    "                        continue\n",
    "\n",
    "                    s_date = (f'{year}-11-01' if season == 'dry'\n",
    "                              else f'{year}-05-01')\n",
    "                    e_date = (f'{year + 1}-04-30' if season == 'dry'\n",
    "                              else f'{year}-10-31')\n",
    "                    desc   = f\"SEAS_{season.upper()}_{region_name}_{year}\"[:90]\n",
    "\n",
    "                    ok = dispatch_export(composite, desc, roi,\n",
    "                                         region_name, s_date, e_date,\n",
    "                                         count, f'{season}_composite',\n",
    "                                         all_tasks,\n",
    "                                         thumb_subdir='seasonal')\n",
    "                    export_count  += ok\n",
    "                    skipped_count += (not ok)\n",
    "                    if ok:\n",
    "                        print(f\"    âœ“ {season} {year}: {count} scenes\")\n",
    "                    time.sleep(0.4)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"    âœ— {season} {year}: {str(e)[:80]}\")\n",
    "\n",
    "    # â”€â”€ SUMMARY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"\\n\" + \"=\" * 72)\n",
    "    print(\"  FINAL SUMMARY\")\n",
    "    print(\"=\" * 72)\n",
    "    print(f\"  âœ“ Queued successfully : {export_count}\")\n",
    "    print(f\"  âŠ™ Skipped             : {skipped_count}\")\n",
    "    print(f\"  ðŸ“Š Potential total    : {total_potential:,}\")\n",
    "    print(f\"  ðŸ”§ Type               : Float32 (all {len(ALL_EXPORT_BANDS)} bands)\")\n",
    "    print()\n",
    "\n",
    "    if EXPORT_MODE in ('drive', 'gcs'):\n",
    "        dest = (\"Google Drive â†’ 'Hasdeo_Training_Dataset/'\"\n",
    "                if EXPORT_MODE == 'drive'\n",
    "                else f\"gs://{GCS_BUCKET}/hasdeo/\")\n",
    "        print(f\"  ðŸ“ {dest}\")\n",
    "        print(\"  ðŸ”— Monitor: https://code.earthengine.google.com/tasks\")\n",
    "        save_task_ids(all_tasks)\n",
    "    else:\n",
    "        print(f\"  ðŸ“ Local PNGs: {OUTPUT_DIR}/\")\n",
    "\n",
    "    save_metadata_csv()\n",
    "    print(\"=\" * 72)\n",
    "    print(\"  âœ… All tasks queued â€” no more type mismatch errors.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef897c71-634e-4e3f-a439-49ae706652ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0499c34d-9aa3-4998-af15-08f9800b0666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
