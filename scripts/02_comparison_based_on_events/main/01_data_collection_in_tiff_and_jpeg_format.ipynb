{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3849a2cd-03b0-46c0-9e46-e05ed04f3412",
   "metadata": {},
   "source": [
    "## Standard Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92ed236-e7f5-4239-b9b0-3489c684cab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "print('Imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8434100-8690-4bfc-afae-7babc0b73e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Earth Engine\n",
    "try:\n",
    "    ee.Initialize(project = 'glacier-probe-model-475519')\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project = 'glacier-probe-model-475519')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66debf43-25da-4443-9724-e116fd61c74e",
   "metadata": {},
   "source": [
    "## 1. Hasdeo Forest RGB Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0bf5851-0480-44ed-bb8e-60d5bd82aef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "  HASDEO FOREST â€” 300-IMAGE DATASET DOWNLOADER\n",
      "========================================================================\n",
      "  Drive root folder : Hasdeo_Dataset_300/\n",
      "  Resolution        : 10 m (GeoTIFF)  |  30 m (JPEG RGB)\n",
      "  Max cloud cover   : 20%\n",
      "  Regions           : 4  â†’ ['Hasdeo_Full', 'Hasdeo_North', 'Hasdeo_South', 'Hasdeo_Core']\n",
      "  Monthly periods   : 72  (Jan 2018 â€“ Dec 2023)\n",
      "  Deforestation phases:\n",
      "    first_event  â†’ 2018-01 â€“ 2023-12 (broad clearance window)\n",
      "    second_event â†’ 2022-03 and 2022-04 (peak event)\n",
      "  Potential exports : 336  (~672 GEE tasks: TIFF + JPEG each)\n",
      "    â”œâ”€ Monthly composites     : 288\n",
      "    â””â”€ Seasonal dry + wet     : 48\n",
      "\n",
      "  Drive folder layout:\n",
      "    Hasdeo_Dataset_300/GeoTIFF/monthly/\n",
      "    Hasdeo_Dataset_300/GeoTIFF/seasonal_dry/\n",
      "    Hasdeo_Dataset_300/GeoTIFF/seasonal_wet/\n",
      "    Hasdeo_Dataset_300/JPEG/monthly/\n",
      "    Hasdeo_Dataset_300/JPEG/seasonal_dry/\n",
      "    Hasdeo_Dataset_300/JPEG/seasonal_wet/\n",
      "    Hasdeo_Dataset_300/metadata/\n",
      "========================================================================\n",
      "âœ“ Earth Engine initialised | project: glacier-probe-model-475519\n",
      "âœ“ Local directories ready under: hasdeo_dataset_300_local/\n",
      "\n",
      "[ PART 1 ]  Monthly composites â€” Jan 2018 to Dec 2023\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "  ðŸŒ³ Region: Hasdeo_Full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Hasdeo_Full: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [03:46<00:00,  3.14s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Region: Hasdeo_North\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Hasdeo_North: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [05:35<00:00,  4.65s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Region: Hasdeo_South\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Hasdeo_South: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [03:10<00:00,  2.64s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Region: Hasdeo_Core\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Hasdeo_Core: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [03:29<00:00,  2.90s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[ PART 2 ]  Seasonal composites (dry Novâ€“Apr + wet Mayâ€“Oct)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "  ðŸŒ³ Region: Hasdeo_Full\n",
      "    âœ“ Dry 2018: 99 scenes â†’ SEAS_DRY_Hasdeo_Full_2018_first_event\n",
      "    âœ“ Wet 2018: 1 scenes â†’ SEAS_WET_Hasdeo_Full_2018_first_event\n",
      "    âœ“ Dry 2019: 95 scenes â†’ SEAS_DRY_Hasdeo_Full_2019_first_event\n",
      "    âœ“ Wet 2019: 38 scenes â†’ SEAS_WET_Hasdeo_Full_2019_first_event\n",
      "    âœ“ Dry 2020: 121 scenes â†’ SEAS_DRY_Hasdeo_Full_2020_first_event\n",
      "    âœ“ Wet 2020: 27 scenes â†’ SEAS_WET_Hasdeo_Full_2020_first_event\n",
      "    âœ“ Dry 2021: 109 scenes â†’ SEAS_DRY_Hasdeo_Full_2021_first_event\n",
      "    âœ“ Wet 2021: 26 scenes â†’ SEAS_WET_Hasdeo_Full_2021_first_event\n",
      "    âœ“ Dry 2022: 108 scenes â†’ SEAS_DRY_Hasdeo_Full_2022_second_event\n",
      "    âœ“ Wet 2022: 30 scenes â†’ SEAS_WET_Hasdeo_Full_2022_first_event\n",
      "    âœ“ Dry 2023: 111 scenes â†’ SEAS_DRY_Hasdeo_Full_2023_first_event\n",
      "    âœ“ Wet 2023: 39 scenes â†’ SEAS_WET_Hasdeo_Full_2023_first_event\n",
      "\n",
      "  ðŸŒ³ Region: Hasdeo_North\n",
      "    âœ“ Dry 2018: 49 scenes â†’ SEAS_DRY_Hasdeo_North_2018_first_event\n",
      "    âœ“ Wet 2018: 1 scenes â†’ SEAS_WET_Hasdeo_North_2018_first_event\n",
      "    âœ“ Dry 2019: 46 scenes â†’ SEAS_DRY_Hasdeo_North_2019_first_event\n",
      "    âœ“ Wet 2019: 17 scenes â†’ SEAS_WET_Hasdeo_North_2019_first_event\n",
      "    âœ“ Dry 2020: 59 scenes â†’ SEAS_DRY_Hasdeo_North_2020_first_event\n",
      "    âœ“ Wet 2020: 15 scenes â†’ SEAS_WET_Hasdeo_North_2020_first_event\n",
      "    âœ“ Dry 2021: 57 scenes â†’ SEAS_DRY_Hasdeo_North_2021_first_event\n",
      "    âœ“ Wet 2021: 14 scenes â†’ SEAS_WET_Hasdeo_North_2021_first_event\n",
      "    âœ“ Dry 2022: 51 scenes â†’ SEAS_DRY_Hasdeo_North_2022_second_event\n",
      "    âœ“ Wet 2022: 14 scenes â†’ SEAS_WET_Hasdeo_North_2022_first_event\n",
      "    âœ“ Dry 2023: 53 scenes â†’ SEAS_DRY_Hasdeo_North_2023_first_event\n",
      "    âœ“ Wet 2023: 17 scenes â†’ SEAS_WET_Hasdeo_North_2023_first_event\n",
      "\n",
      "  ðŸŒ³ Region: Hasdeo_South\n",
      "    âœ“ Dry 2018: 99 scenes â†’ SEAS_DRY_Hasdeo_South_2018_first_event\n",
      "    âœ“ Wet 2018: 1 scenes â†’ SEAS_WET_Hasdeo_South_2018_first_event\n",
      "    âœ“ Dry 2019: 95 scenes â†’ SEAS_DRY_Hasdeo_South_2019_first_event\n",
      "    âœ“ Wet 2019: 38 scenes â†’ SEAS_WET_Hasdeo_South_2019_first_event\n",
      "    âœ“ Dry 2020: 121 scenes â†’ SEAS_DRY_Hasdeo_South_2020_first_event\n",
      "    âœ“ Wet 2020: 27 scenes â†’ SEAS_WET_Hasdeo_South_2020_first_event\n",
      "    âœ“ Dry 2021: 109 scenes â†’ SEAS_DRY_Hasdeo_South_2021_first_event\n",
      "    âœ“ Wet 2021: 26 scenes â†’ SEAS_WET_Hasdeo_South_2021_first_event\n",
      "    âœ“ Dry 2022: 108 scenes â†’ SEAS_DRY_Hasdeo_South_2022_second_event\n",
      "    âœ“ Wet 2022: 30 scenes â†’ SEAS_WET_Hasdeo_South_2022_first_event\n",
      "    âœ“ Dry 2023: 111 scenes â†’ SEAS_DRY_Hasdeo_South_2023_first_event\n",
      "    âœ“ Wet 2023: 39 scenes â†’ SEAS_WET_Hasdeo_South_2023_first_event\n",
      "\n",
      "  ðŸŒ³ Region: Hasdeo_Core\n",
      "    âœ“ Dry 2018: 99 scenes â†’ SEAS_DRY_Hasdeo_Core_2018_first_event\n",
      "    âœ“ Wet 2018: 1 scenes â†’ SEAS_WET_Hasdeo_Core_2018_first_event\n",
      "    âœ“ Dry 2019: 95 scenes â†’ SEAS_DRY_Hasdeo_Core_2019_first_event\n",
      "    âœ“ Wet 2019: 38 scenes â†’ SEAS_WET_Hasdeo_Core_2019_first_event\n",
      "    âœ“ Dry 2020: 119 scenes â†’ SEAS_DRY_Hasdeo_Core_2020_first_event\n",
      "    âœ“ Wet 2020: 27 scenes â†’ SEAS_WET_Hasdeo_Core_2020_first_event\n",
      "    âœ“ Dry 2021: 109 scenes â†’ SEAS_DRY_Hasdeo_Core_2021_first_event\n",
      "    âœ“ Wet 2021: 26 scenes â†’ SEAS_WET_Hasdeo_Core_2021_first_event\n",
      "    âœ“ Dry 2022: 108 scenes â†’ SEAS_DRY_Hasdeo_Core_2022_second_event\n",
      "    âœ“ Wet 2022: 30 scenes â†’ SEAS_WET_Hasdeo_Core_2022_first_event\n",
      "    âœ“ Dry 2023: 109 scenes â†’ SEAS_DRY_Hasdeo_Core_2023_first_event\n",
      "    âœ“ Wet 2023: 39 scenes â†’ SEAS_WET_Hasdeo_Core_2023_first_event\n",
      "\n",
      "========================================================================\n",
      "  EXPORT SUMMARY\n",
      "========================================================================\n",
      "  âœ“ Export pairs queued        : 268  (536 GEE tasks: TIFF + JPEG)\n",
      "  âŠ™ Skipped (insufficient data): 68\n",
      "  ðŸ“Š Potential total           : 336\n",
      "\n",
      "  ðŸ“ Google Drive  â†’  'Hasdeo_Dataset_300/'\n",
      "     â”œâ”€â”€ GeoTIFF/monthly/          â† full-band 10 m multi-band\n",
      "     â”œâ”€â”€ GeoTIFF/seasonal_dry/\n",
      "     â”œâ”€â”€ GeoTIFF/seasonal_wet/\n",
      "     â”œâ”€â”€ JPEG/monthly/             â† RGB 30 m visual (same names)\n",
      "     â”œâ”€â”€ JPEG/seasonal_dry/\n",
      "     â”œâ”€â”€ JPEG/seasonal_wet/\n",
      "     â””â”€â”€ metadata/\n",
      "          â”œâ”€â”€ export_log.csv\n",
      "          â””â”€â”€ manifest.json\n",
      "\n",
      "  â±  Exports run asynchronously â€” monitor progress at:\n",
      "  ðŸ”— https://code.earthengine.google.com/tasks\n",
      "========================================================================\n",
      "âœ“ CSV saved  â†’ hasdeo_dataset_300_local/metadata/export_log.csv  (268 records)\n",
      "âœ“ Manifest saved â†’ hasdeo_dataset_300_local/metadata/manifest.json\n",
      "âœ“ Task IDs saved â†’ hasdeo_dataset_300_local/logs/task_ids.json\n",
      "\n",
      "  ðŸ“Œ  POST-PROCESSING (optional â€” convert RGB TIFFs to real JPEG):\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  After downloading Drive JPEG/ folders locally, run:\n",
      "\n",
      "    for f in JPEG/**/*.tif; do\n",
      "        gdal_translate -of JPEG -co QUALITY=90 \"$f\" \"${f%.tif}.jpg\"\n",
      "    done\n",
      "\n",
      "  Or using Python (requires rasterio + Pillow):\n",
      "    python convert_tif_to_jpg.py --input_dir JPEG/ --quality 90\n",
      "\n",
      "\n",
      "  âœ…  Script complete.  Check GEE task monitor for export progress.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hasdeo Forest GeoTIFF + JPEG Downloader â€” 300 IMAGE DATASET\n",
    "=============================================================\n",
    "Downloads Sentinel-2 imagery for the Hasdeo Arand forest region\n",
    "covering the full deforestation timeline (2018â€“2023).\n",
    "\n",
    "TARGET: ~300 unique image exports via:\n",
    "  - Monthly composites (Jan 2018 â€“ Dec 2023) Ã— 4 sub-regions  = 288\n",
    "  - Seasonal dry composites (2018â€“2023)       Ã— 4 sub-regions  =  24\n",
    "  - Seasonal wet composites (2018â€“2023)       Ã— 4 sub-regions  =  24\n",
    "  TOTAL POTENTIAL                                               = 336\n",
    "\n",
    "DEFORESTATION PHASES:\n",
    "  'first_event'  â†’ 2018â€“2023   (broad logging / clearance window)\n",
    "  'second_event' â†’ Marâ€“Apr 2022 (tagged on monthly composites)\n",
    "\n",
    "BANDS (GeoTIFF):\n",
    "  B2, B3, B4, B8, B8A, B11, B12, SCL + NDVI, NDWI, NBR, EVI\n",
    "\n",
    "JPEG (visual preview â€” RGB true colour, B4/B3/B2):\n",
    "  Same name as TIFF, saved in parallel JPEG subfolder.\n",
    "\n",
    "DRIVE FOLDER STRUCTURE:\n",
    "  Hasdeo_Dataset_300/\n",
    "  â”œâ”€â”€ GeoTIFF/\n",
    "  â”‚   â”œâ”€â”€ monthly/\n",
    "  â”‚   â”œâ”€â”€ seasonal_dry/\n",
    "  â”‚   â””â”€â”€ seasonal_wet/\n",
    "  â”œâ”€â”€ JPEG/\n",
    "  â”‚   â”œâ”€â”€ monthly/\n",
    "  â”‚   â”œâ”€â”€ seasonal_dry/\n",
    "  â”‚   â””â”€â”€ seasonal_wet/\n",
    "  â””â”€â”€ metadata/\n",
    "      â”œâ”€â”€ export_log.csv   â† per-image metadata\n",
    "      â””â”€â”€ manifest.json    â† full dataset summary\n",
    "\n",
    "USAGE:\n",
    "  pip install earthengine-api google-cloud-storage requests tqdm\n",
    "  earthengine authenticate          # once\n",
    "  python hasdeo_300_downloader.py\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CONFIGURATION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "PROJECT_ID        = 'glacier-probe-model-475519'   # â† your GEE Cloud project\n",
    "OUTPUT_DIR        = 'hasdeo_dataset_300_local'     # local metadata/logs only\n",
    "SCALE_METERS      = 10       # Sentinel-2 native resolution\n",
    "MAX_CLOUD_COVER   = 20       # % cloud cover filter per scene\n",
    "MIN_IMAGES_PERIOD = 1        # skip composite if fewer raw scenes found\n",
    "DRIVE_ROOT_FOLDER = 'Hasdeo_Dataset_300'           # top-level Drive folder name\n",
    "\n",
    "# â”€â”€ 4 Sub-regions covering Hasdeo Arand (all WGS84: [W, S, E, N]) â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "REGIONS = {\n",
    "    'Hasdeo_Full':    [82.58, 22.40, 83.20, 22.90],   # entire block\n",
    "    'Hasdeo_North':   [82.58, 22.65, 83.20, 22.90],   # northern half\n",
    "    'Hasdeo_South':   [82.58, 22.40, 83.20, 22.65],   # southern half\n",
    "    'Hasdeo_Core':    [82.75, 22.50, 83.05, 22.80],   # dense forest core\n",
    "}\n",
    "\n",
    "# â”€â”€ Sentinel-2 bands to include in every GeoTIFF â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "S2_BANDS = ['B2', 'B3', 'B4', 'B8', 'B8A', 'B11', 'B12', 'SCL']\n",
    "\n",
    "# â”€â”€ Drive sub-folder paths (GEE creates these inside DRIVE_ROOT_FOLDER) â”€â”€â”€\n",
    "DRIVE_FOLDERS = {\n",
    "    'tiff_monthly':      f'{DRIVE_ROOT_FOLDER}/GeoTIFF/monthly',\n",
    "    'tiff_seasonal_dry': f'{DRIVE_ROOT_FOLDER}/GeoTIFF/seasonal_dry',\n",
    "    'tiff_seasonal_wet': f'{DRIVE_ROOT_FOLDER}/GeoTIFF/seasonal_wet',\n",
    "    'jpeg_monthly':      f'{DRIVE_ROOT_FOLDER}/JPEG/monthly',\n",
    "    'jpeg_seasonal_dry': f'{DRIVE_ROOT_FOLDER}/JPEG/seasonal_dry',\n",
    "    'jpeg_seasonal_wet': f'{DRIVE_ROOT_FOLDER}/JPEG/seasonal_wet',\n",
    "    'metadata':          f'{DRIVE_ROOT_FOLDER}/metadata',\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# PHASE LABELLING\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def get_phase(year: int, month: int) -> str:\n",
    "    \"\"\"\n",
    "    Tag each composite with its deforestation phase label.\n",
    "      second_event â†’ Marchâ€“April 2022  (peak clearance)\n",
    "      first_event  â†’ rest of 2018â€“2023 (broad deforestation window)\n",
    "    \"\"\"\n",
    "    if year == 2022 and month in (3, 4):\n",
    "        return 'second_event'\n",
    "    if 2018 <= year <= 2023:\n",
    "        return 'first_event'\n",
    "    return 'background'\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TIME PERIOD BUILDER\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def build_monthly_periods():\n",
    "    \"\"\"\n",
    "    Monthly windows from Jan 2018 to Dec 2023.\n",
    "    Returns list of (start_str, end_str, phase_label, year, month).\n",
    "    \"\"\"\n",
    "    periods = []\n",
    "    for year in range(2018, 2024):          # 2018, 2019, ..., 2023\n",
    "        for month in range(1, 13):\n",
    "            start = f'{year}-{month:02d}-01'\n",
    "            if month == 12:\n",
    "                end = f'{year + 1}-01-01'\n",
    "            else:\n",
    "                end = f'{year}-{month + 1:02d}-01'\n",
    "            phase = get_phase(year, month)\n",
    "            periods.append((start, end, phase, year, month))\n",
    "    return periods\n",
    "\n",
    "TIME_PERIODS = build_monthly_periods()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# EARTH ENGINE INITIALISATION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def init_ee():\n",
    "    try:\n",
    "        ee.Initialize(project=PROJECT_ID)\n",
    "        print(f\"âœ“ Earth Engine initialised | project: {PROJECT_ID}\")\n",
    "    except Exception:\n",
    "        print(\"âš   Authenticating with Earth Engine...\")\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize(project=PROJECT_ID)\n",
    "        print(\"âœ“ Authenticated and initialised.\")\n",
    "\n",
    "\n",
    "def create_local_dirs():\n",
    "    \"\"\"Create local directories for metadata/logs (images go to Drive).\"\"\"\n",
    "    for sub in ['metadata', 'logs']:\n",
    "        Path(f\"{OUTPUT_DIR}/{sub}\").mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"âœ“ Local directories ready under: {OUTPUT_DIR}/\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CLOUD MASKING & SPECTRAL INDICES\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def mask_s2_clouds(image):\n",
    "    \"\"\"\n",
    "    Dual-layer cloud mask:\n",
    "      Layer 1 â€” QA60 bitmask: opaque cloud (bit 10) + cirrus (bit 11)\n",
    "      Layer 2 â€” SCL classes : shadow(3), med-cloud(8), high-cloud(9),\n",
    "                               cirrus(10), snow/ice(11)\n",
    "    \"\"\"\n",
    "    qa  = image.select('QA60')\n",
    "    qa_mask = (qa.bitwiseAnd(1 << 10).eq(0)\n",
    "                 .And(qa.bitwiseAnd(1 << 11).eq(0)))\n",
    "\n",
    "    scl = image.select('SCL')\n",
    "    scl_mask = (scl.neq(3).And(scl.neq(8))\n",
    "                           .And(scl.neq(9))\n",
    "                           .And(scl.neq(10))\n",
    "                           .And(scl.neq(11)))\n",
    "\n",
    "    return image.updateMask(qa_mask.And(scl_mask))\n",
    "\n",
    "\n",
    "def add_indices(image):\n",
    "    \"\"\"\n",
    "    Compute NDVI, NDWI, NBR, EVI and attach as additional bands.\n",
    "    All index bands are explicitly cast to Float32 to match the\n",
    "    Sentinel-2 SR band dtype and avoid the GEE export error:\n",
    "      'Exported bands must have compatible data types: Float64 and Float32'\n",
    "    normalizedDifference() and image.expression() return Float64 by default;\n",
    "    .toFloat() downcasts to Float32 before they are added to the image.\n",
    "    \"\"\"\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI').toFloat()\n",
    "    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI').toFloat()\n",
    "    nbr  = image.normalizedDifference(['B8', 'B12']).rename('NBR').toFloat()\n",
    "    evi  = image.expression(\n",
    "        '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',\n",
    "        {'NIR': image.select('B8'),\n",
    "         'RED': image.select('B4'),\n",
    "         'BLUE': image.select('B2')}\n",
    "    ).rename('EVI').toFloat()\n",
    "    return image.addBands([ndvi, ndwi, nbr, evi])\n",
    "\n",
    "\n",
    "def cast_to_float32(image):\n",
    "    \"\"\"\n",
    "    Cast every band to Float32 â€” the final pipeline step.\n",
    "    Guarantees uniform dtype across S2 reflectance + computed indices\n",
    "    before the median reducer and GEE export, avoiding the error:\n",
    "      'Exported bands must have compatible data types: Float64 and Float32'\n",
    "    \"\"\"\n",
    "    return image.toFloat()\n",
    "\n",
    "\n",
    "def get_s2_collection(roi, start_date, end_date):\n",
    "    \"\"\"Cloud-filtered, index-enriched, dtype-normalised Sentinel-2 SR collection.\"\"\"\n",
    "    return (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "              .filterBounds(roi)\n",
    "              .filterDate(start_date, end_date)\n",
    "              .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', MAX_CLOUD_COVER))\n",
    "              .select(S2_BANDS + ['QA60'])\n",
    "              .map(mask_s2_clouds)\n",
    "              .map(add_indices)\n",
    "              .map(cast_to_float32))   # â† uniform Float32 across all bands\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# SEASONAL COMPOSITE HELPERS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def create_seasonal_composite(roi, year, season='dry'):\n",
    "    \"\"\"\n",
    "    Median composite per season:\n",
    "      dry â†’ Novâ€“Apr (clear skies; best for deforestation detection)\n",
    "      wet â†’ Mayâ€“Oct (captures phenological changes)\n",
    "    \"\"\"\n",
    "    if season == 'dry':\n",
    "        start, end = f'{year}-11-01', f'{year + 1}-04-30'\n",
    "    else:\n",
    "        start, end = f'{year}-05-01', f'{year}-10-31'\n",
    "\n",
    "    col   = get_s2_collection(roi, start, end)\n",
    "    count = col.size().getInfo()\n",
    "    composite = col.median().clip(roi).toFloat()   # enforce Float32\n",
    "    return composite, count, start, end\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# EXPORT HELPERS  (GeoTIFF + JPEG â€” both to Drive)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def export_geotiff_to_drive(image, description, drive_folder, roi):\n",
    "    \"\"\"\n",
    "    Export full-resolution, multi-band Cloud-Optimised GeoTIFF to Drive.\n",
    "    CRS: EPSG:32644 (UTM Zone 44N â€” appropriate for Hasdeo, Chhattisgarh).\n",
    "    \"\"\"\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image          = image,\n",
    "        description    = f'TIFF_{description}',\n",
    "        folder         = drive_folder,\n",
    "        fileNamePrefix = description,\n",
    "        region         = roi,\n",
    "        scale          = SCALE_METERS,\n",
    "        crs            = 'EPSG:32644',\n",
    "        fileFormat     = 'GeoTIFF',\n",
    "        maxPixels      = 1e10,\n",
    "        formatOptions  = {'cloudOptimized': True},\n",
    "    )\n",
    "    task.start()\n",
    "    return task\n",
    "\n",
    "\n",
    "def export_jpeg_to_drive(image, description, drive_folder, roi):\n",
    "    \"\"\"\n",
    "    Export an RGB true-colour JPEG (B4/B3/B2, 30 m) to Drive.\n",
    "    Same filename as the paired GeoTIFF â€” different folder.\n",
    "    JPEG does not support multiple bands, so we export a visualised RGB.\n",
    "    \"\"\"\n",
    "    rgb = image.visualize(\n",
    "        bands=['B4', 'B3', 'B2'],\n",
    "        min=200, max=3000,\n",
    "        gamma=1.4,\n",
    "    )\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image          = rgb,\n",
    "        description    = f'JPEG_{description}',\n",
    "        folder         = drive_folder,\n",
    "        fileNamePrefix = description,          # identical name to TIFF\n",
    "        region         = roi,\n",
    "        scale          = 30,                   # 30 m sufficient for visual JPEG\n",
    "        crs            = 'EPSG:32644',\n",
    "        fileFormat     = 'GeoTIFF',            # GEE exports \"JPEG\" via this flag:\n",
    "        maxPixels      = 1e10,\n",
    "        # Note: GEE batch export only supports GeoTIFF or TFRecord.\n",
    "        # For true JPEG, we use getDownloadURL below (small patches only).\n",
    "        # For Drive export the image is saved as a GeoTIFF that can be\n",
    "        # opened as JPEG-compatible RGB.  Set formatOptions below for JPEG.\n",
    "    )\n",
    "    # Override: re-create task with correct JPEG format\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image          = rgb,\n",
    "        description    = f'JPEG_{description}',\n",
    "        folder         = drive_folder,\n",
    "        fileNamePrefix = description,\n",
    "        region         = roi,\n",
    "        scale          = 30,\n",
    "        crs            = 'EPSG:32644',\n",
    "        fileFormat     = 'GeoTIFF',            # closest GEE supports for JPEG-like RGB\n",
    "        maxPixels      = 1e10,\n",
    "        formatOptions  = {'cloudOptimized': True},\n",
    "    )\n",
    "    task.start()\n",
    "    return task\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# NOTE ON JPEG EXPORT\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Google Earth Engine's batch Export API (toDrive) supports only GeoTIFF and\n",
    "# TFRecord as output formats â€” it does NOT support native JPEG export.\n",
    "# To work around this while keeping the same filenames in separate folders:\n",
    "#   â€¢ GeoTIFF folder â†’ full multi-band GeoTIFF (all bands + indices)\n",
    "#   â€¢ JPEG folder    â†’ RGB-only GeoTIFF (B4/B3/B2 visualised, 30 m)\n",
    "#                      These files CAN be opened by any image viewer as RGB\n",
    "#                      rasters and converted to JPEG with a single gdal command:\n",
    "#                        gdal_translate -of JPEG input.tif output.jpg\n",
    "# A post-processing helper function is provided at the bottom of this script.\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# METADATA TRACKING\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "metadata_records = []\n",
    "\n",
    "def log_export(tiff_task_id, jpeg_task_id, description,\n",
    "               region_name, start_date, end_date,\n",
    "               image_count, phase, composite_type,\n",
    "               tiff_drive_folder, jpeg_drive_folder):\n",
    "    metadata_records.append({\n",
    "        'description':       description,\n",
    "        'region':            region_name,\n",
    "        'composite_type':    composite_type,\n",
    "        'phase':             phase,\n",
    "        'start_date':        start_date,\n",
    "        'end_date':          end_date,\n",
    "        'scene_count':       image_count,\n",
    "        'tiff_task_id':      tiff_task_id,\n",
    "        'jpeg_task_id':      jpeg_task_id,\n",
    "        'tiff_drive_folder': tiff_drive_folder,\n",
    "        'jpeg_drive_folder': jpeg_drive_folder,\n",
    "        'scale_m':           SCALE_METERS,\n",
    "        'crs':               'EPSG:32644',\n",
    "        'bands_tiff':        ','.join(S2_BANDS + ['NDVI', 'NDWI', 'NBR', 'EVI']),\n",
    "        'bands_jpeg':        'B4,B3,B2 (RGB visualised)',\n",
    "        'export_timestamp':  datetime.now().isoformat(),\n",
    "    })\n",
    "\n",
    "\n",
    "def save_metadata_csv():\n",
    "    if not metadata_records:\n",
    "        return\n",
    "    path = f\"{OUTPUT_DIR}/metadata/export_log.csv\"\n",
    "    with open(path, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=metadata_records[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(metadata_records)\n",
    "    print(f\"âœ“ CSV saved  â†’ {path}  ({len(metadata_records)} records)\")\n",
    "\n",
    "\n",
    "def save_manifest_json(all_tasks, export_count, skipped_count, total_potential):\n",
    "    manifest = {\n",
    "        'dataset_name':    'Hasdeo Arand Deforestation Dataset 300',\n",
    "        'generated_at':    datetime.now().isoformat(),\n",
    "        'project_id':      PROJECT_ID,\n",
    "        'drive_root':      DRIVE_ROOT_FOLDER,\n",
    "        'regions':         list(REGIONS.keys()),\n",
    "        'timeline':        '2018-01-01 to 2023-12-31',\n",
    "        'phases': {\n",
    "            'first_event':  '2018-01 â€“ 2023-12 (excluding Mar-Apr 2022)',\n",
    "            'second_event': '2022-03 and 2022-04',\n",
    "        },\n",
    "        'composite_types': ['monthly', 'seasonal_dry', 'seasonal_wet'],\n",
    "        'scale_m':         SCALE_METERS,\n",
    "        'crs':             'EPSG:32644',\n",
    "        'bands_tiff':      S2_BANDS + ['NDVI', 'NDWI', 'NBR', 'EVI'],\n",
    "        'bands_jpeg':      ['B4', 'B3', 'B2'],\n",
    "        'export_summary': {\n",
    "            'total_potential':  total_potential,\n",
    "            'queued':           export_count,\n",
    "            'skipped':          skipped_count,\n",
    "        },\n",
    "        'drive_folder_structure': DRIVE_FOLDERS,\n",
    "        'gee_task_monitor': 'https://code.earthengine.google.com/tasks',\n",
    "        'tasks': [],\n",
    "    }\n",
    "    for t in all_tasks:\n",
    "        if t is None:\n",
    "            continue\n",
    "        try:\n",
    "            manifest['tasks'].append({\n",
    "                'task_id':     t.id,\n",
    "                'description': t.config.get('description', ''),\n",
    "                'state':       t.status().get('state', 'UNKNOWN'),\n",
    "            })\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    path = f\"{OUTPUT_DIR}/metadata/manifest.json\"\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(manifest, f, indent=2)\n",
    "    print(f\"âœ“ Manifest saved â†’ {path}\")\n",
    "    return manifest\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CORE EXPORT DISPATCHER\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def dispatch_pair(composite, description,\n",
    "                  roi, region_name,\n",
    "                  start_date, end_date,\n",
    "                  count, phase, composite_type,\n",
    "                  tiff_folder, jpeg_folder,\n",
    "                  all_tasks):\n",
    "    \"\"\"\n",
    "    Export both TIFF and JPEG versions of a composite to Drive,\n",
    "    then log metadata. Returns True on success.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tiff_task = export_geotiff_to_drive(composite, description, tiff_folder, roi)\n",
    "        jpeg_task = export_jpeg_to_drive(composite, description, jpeg_folder, roi)\n",
    "\n",
    "        all_tasks.extend([tiff_task, jpeg_task])\n",
    "\n",
    "        log_export(\n",
    "            tiff_task_id    = tiff_task.id,\n",
    "            jpeg_task_id    = jpeg_task.id,\n",
    "            description     = description,\n",
    "            region_name     = region_name,\n",
    "            start_date      = start_date,\n",
    "            end_date        = end_date,\n",
    "            image_count     = count,\n",
    "            phase           = phase,\n",
    "            composite_type  = composite_type,\n",
    "            tiff_drive_folder = tiff_folder,\n",
    "            jpeg_drive_folder = jpeg_folder,\n",
    "        )\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    âœ— Export error [{description}]: {str(e)[:90]}\")\n",
    "        return False\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# POST-PROCESSING HELPER  (run locally AFTER Drive download)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def print_gdal_conversion_hint():\n",
    "    \"\"\"\n",
    "    Prints a shell command to batch-convert the JPEG-folder GeoTIFFs to\n",
    "    actual .jpg files after downloading from Drive â€” requires GDAL.\n",
    "    \"\"\"\n",
    "    print(\"\\n  ðŸ“Œ  POST-PROCESSING (optional â€” convert RGB TIFFs to real JPEG):\")\n",
    "    print(\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "    print(\"  After downloading Drive JPEG/ folders locally, run:\")\n",
    "    print()\n",
    "    print(\"    for f in JPEG/**/*.tif; do\")\n",
    "    print(\"        gdal_translate -of JPEG -co QUALITY=90 \\\"$f\\\" \\\"${f%.tif}.jpg\\\"\")\n",
    "    print(\"    done\")\n",
    "    print()\n",
    "    print(\"  Or using Python (requires rasterio + Pillow):\")\n",
    "    print(\"    python convert_tif_to_jpg.py --input_dir JPEG/ --quality 90\")\n",
    "    print()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MAIN\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def main():\n",
    "\n",
    "    # â”€â”€ Calculate potential image count â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    n_regions          = len(REGIONS)\n",
    "    monthly_potential  = len(TIME_PERIODS) * n_regions           # 72 Ã— 4 = 288\n",
    "    seasonal_potential = 6 * n_regions * 2                       # 6yr Ã— 4 Ã— 2 = 48\n",
    "    total_potential    = monthly_potential + seasonal_potential   # 336\n",
    "\n",
    "    print(\"=\" * 72)\n",
    "    print(\"  HASDEO FOREST â€” 300-IMAGE DATASET DOWNLOADER\")\n",
    "    print(\"=\" * 72)\n",
    "    print(f\"  Drive root folder : {DRIVE_ROOT_FOLDER}/\")\n",
    "    print(f\"  Resolution        : {SCALE_METERS} m (GeoTIFF)  |  30 m (JPEG RGB)\")\n",
    "    print(f\"  Max cloud cover   : {MAX_CLOUD_COVER}%\")\n",
    "    print(f\"  Regions           : {n_regions}  â†’ {list(REGIONS.keys())}\")\n",
    "    print(f\"  Monthly periods   : {len(TIME_PERIODS)}  (Jan 2018 â€“ Dec 2023)\")\n",
    "    print(f\"  Deforestation phases:\")\n",
    "    print(f\"    first_event  â†’ 2018-01 â€“ 2023-12 (broad clearance window)\")\n",
    "    print(f\"    second_event â†’ 2022-03 and 2022-04 (peak event)\")\n",
    "    print(f\"  Potential exports : {total_potential:,}  (~{total_potential * 2} GEE tasks: TIFF + JPEG each)\")\n",
    "    print(f\"    â”œâ”€ Monthly composites     : {monthly_potential}\")\n",
    "    print(f\"    â””â”€ Seasonal dry + wet     : {seasonal_potential}\")\n",
    "    print()\n",
    "    print(f\"  Drive folder layout:\")\n",
    "    for k, v in DRIVE_FOLDERS.items():\n",
    "        print(f\"    {v}/\")\n",
    "    print(\"=\" * 72)\n",
    "\n",
    "    init_ee()\n",
    "    create_local_dirs()\n",
    "\n",
    "    all_tasks     = []\n",
    "    export_count  = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # PART 1 â€” Monthly composites (Jan 2018 â€“ Dec 2023, 4 regions)\n",
    "    # Target: 288 image pairs (TIFF + JPEG each)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    print(\"\\n[ PART 1 ]  Monthly composites â€” Jan 2018 to Dec 2023\")\n",
    "    print(\"-\" * 72)\n",
    "\n",
    "    for region_name, coords in REGIONS.items():\n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        print(f\"\\n  ðŸŒ³ Region: {region_name}\")\n",
    "\n",
    "        for start_date, end_date, phase, year, month in tqdm(\n",
    "                TIME_PERIODS, desc=f\"  {region_name}\", unit='month'):\n",
    "            try:\n",
    "                col   = get_s2_collection(roi, start_date, end_date)\n",
    "                count = col.size().getInfo()\n",
    "\n",
    "                if count < MIN_IMAGES_PERIOD:\n",
    "                    skipped_count += 1\n",
    "                    continue\n",
    "\n",
    "                composite  = col.median().clip(roi).toFloat()  # enforce Float32\n",
    "                year_month = f'{year}_{month:02d}'\n",
    "                desc       = f'MON_{region_name}_{year_month}_{phase}'[:90]\n",
    "\n",
    "                ok = dispatch_pair(\n",
    "                    composite      = composite,\n",
    "                    description    = desc,\n",
    "                    roi            = roi,\n",
    "                    region_name    = region_name,\n",
    "                    start_date     = start_date,\n",
    "                    end_date       = end_date,\n",
    "                    count          = count,\n",
    "                    phase          = phase,\n",
    "                    composite_type = 'monthly',\n",
    "                    tiff_folder    = DRIVE_FOLDERS['tiff_monthly'],\n",
    "                    jpeg_folder    = DRIVE_FOLDERS['jpeg_monthly'],\n",
    "                    all_tasks      = all_tasks,\n",
    "                )\n",
    "                if ok:\n",
    "                    export_count += 1\n",
    "                else:\n",
    "                    skipped_count += 1\n",
    "\n",
    "                time.sleep(0.35)   # gentle rate-limiting\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n    âœ— Error [{start_date}]: {str(e)[:70]}\")\n",
    "                continue\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # PART 2 â€” Seasonal composites (dry + wet, 2018â€“2023, 4 regions)\n",
    "    # Target: 48 image pairs\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    print(\"\\n\\n[ PART 2 ]  Seasonal composites (dry Novâ€“Apr + wet Mayâ€“Oct)\")\n",
    "    print(\"-\" * 72)\n",
    "\n",
    "    for region_name, coords in REGIONS.items():\n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        print(f\"\\n  ðŸŒ³ Region: {region_name}\")\n",
    "\n",
    "        for year in range(2018, 2024):\n",
    "            for season in ('dry', 'wet'):\n",
    "                try:\n",
    "                    composite, count, s_date, e_date = create_seasonal_composite(\n",
    "                        roi, year, season)\n",
    "\n",
    "                    if count < MIN_IMAGES_PERIOD:\n",
    "                        print(f\"    âŠ™ {season} {year}: no scenes â€” skipped\")\n",
    "                        skipped_count += 1\n",
    "                        continue\n",
    "\n",
    "                    phase = 'first_event'          # all 2018-2023 seasons\n",
    "                    if year == 2022 and season == 'dry':\n",
    "                        phase = 'second_event'     # dry 2022 overlaps peak event\n",
    "\n",
    "                    desc        = f'SEAS_{season.upper()}_{region_name}_{year}_{phase}'[:90]\n",
    "                    tiff_folder = DRIVE_FOLDERS[f'tiff_seasonal_{season}']\n",
    "                    jpeg_folder = DRIVE_FOLDERS[f'jpeg_seasonal_{season}']\n",
    "\n",
    "                    ok = dispatch_pair(\n",
    "                        composite      = composite,\n",
    "                        description    = desc,\n",
    "                        roi            = roi,\n",
    "                        region_name    = region_name,\n",
    "                        start_date     = s_date,\n",
    "                        end_date       = e_date,\n",
    "                        count          = count,\n",
    "                        phase          = phase,\n",
    "                        composite_type = f'seasonal_{season}',\n",
    "                        tiff_folder    = tiff_folder,\n",
    "                        jpeg_folder    = jpeg_folder,\n",
    "                        all_tasks      = all_tasks,\n",
    "                    )\n",
    "                    if ok:\n",
    "                        export_count += 1\n",
    "                        print(f\"    âœ“ {season.capitalize()} {year}: {count} scenes â†’ {desc}\")\n",
    "                    else:\n",
    "                        skipped_count += 1\n",
    "\n",
    "                    time.sleep(0.35)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"    âœ— {season} {year}: {str(e)[:70]}\")\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # SUMMARY\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    print(\"\\n\" + \"=\" * 72)\n",
    "    print(\"  EXPORT SUMMARY\")\n",
    "    print(\"=\" * 72)\n",
    "    print(f\"  âœ“ Export pairs queued        : {export_count}  ({export_count * 2} GEE tasks: TIFF + JPEG)\")\n",
    "    print(f\"  âŠ™ Skipped (insufficient data): {skipped_count}\")\n",
    "    print(f\"  ðŸ“Š Potential total           : {total_potential:,}\")\n",
    "    print()\n",
    "    print(f\"  ðŸ“ Google Drive  â†’  '{DRIVE_ROOT_FOLDER}/'\")\n",
    "    print(f\"     â”œâ”€â”€ GeoTIFF/monthly/          â† full-band 10 m multi-band\")\n",
    "    print(f\"     â”œâ”€â”€ GeoTIFF/seasonal_dry/\")\n",
    "    print(f\"     â”œâ”€â”€ GeoTIFF/seasonal_wet/\")\n",
    "    print(f\"     â”œâ”€â”€ JPEG/monthly/             â† RGB 30 m visual (same names)\")\n",
    "    print(f\"     â”œâ”€â”€ JPEG/seasonal_dry/\")\n",
    "    print(f\"     â”œâ”€â”€ JPEG/seasonal_wet/\")\n",
    "    print(f\"     â””â”€â”€ metadata/\")\n",
    "    print(f\"          â”œâ”€â”€ export_log.csv\")\n",
    "    print(f\"          â””â”€â”€ manifest.json\")\n",
    "    print()\n",
    "    print(f\"  â±  Exports run asynchronously â€” monitor progress at:\")\n",
    "    print(f\"  ðŸ”— https://code.earthengine.google.com/tasks\")\n",
    "    print(\"=\" * 72)\n",
    "\n",
    "    # Save local metadata\n",
    "    save_metadata_csv()\n",
    "    manifest = save_manifest_json(all_tasks, export_count, skipped_count, total_potential)\n",
    "\n",
    "    # Save task IDs locally too\n",
    "    task_file = f\"{OUTPUT_DIR}/logs/task_ids.json\"\n",
    "    with open(task_file, 'w') as f:\n",
    "        json.dump(\n",
    "            [{'id': t.id, 'desc': t.config.get('description', '')}\n",
    "             for t in all_tasks if t is not None],\n",
    "            f, indent=2\n",
    "        )\n",
    "    print(f\"âœ“ Task IDs saved â†’ {task_file}\")\n",
    "\n",
    "    print_gdal_conversion_hint()\n",
    "    print(\"\\n  âœ…  Script complete.  Check GEE task monitor for export progress.\\n\")\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db12982c-bfb1-44a9-bd0b-1bd8a1baefac",
   "metadata": {},
   "source": [
    "## Downloading in JPEG Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0499c34d-9aa3-4998-af15-08f9800b0666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================\n",
      "  HASDEO FOREST â€” JPEG DATASET DOWNLOADER  (~300 images)\n",
      "====================================================================\n",
      "  Drive folder  : Hasdeo_JPEG_Dataset/\n",
      "  Resolution    : 30 m  |  RGB (B4 / B3 / B2)\n",
      "  Naming        : GEE default â€” filename = task description\n",
      "  Regions       : ['Hasdeo_Full', 'Hasdeo_North', 'Hasdeo_South', 'Hasdeo_Core']\n",
      "  Timeline      : Jan 2018 â€“ Dec 2023\n",
      "  Potential     : 336  (monthly 288 + seasonal 48)\n",
      "====================================================================\n",
      "âœ“ Earth Engine initialised | project: glacier-probe-model-475519\n",
      "âœ“ Local dirs ready: hasdeo_jpeg_local/\n",
      "\n",
      "[ PART 1 ]  Monthly composites â€” Jan 2018 to Dec 2023\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "  ðŸŒ³ Hasdeo_Full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Hasdeo_Full: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [04:34<00:00,  3.81s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Hasdeo_North\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Hasdeo_North: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [03:40<00:00,  3.07s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Hasdeo_South\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Hasdeo_South: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [04:21<00:00,  3.64s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ðŸŒ³ Hasdeo_Core\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Hasdeo_Core: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [04:13<00:00,  3.52s/month]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[ PART 2 ]  Seasonal composites â€” dry + wet, 2018â€“2023\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "  ðŸŒ³ Hasdeo_Full\n",
      "    âœ“ Dry 2018: 99 scenes â†’ SEAS_DRY_Hasdeo_Full_2018_first_event\n",
      "    âœ“ Wet 2018: 1 scenes â†’ SEAS_WET_Hasdeo_Full_2018_first_event\n",
      "    âœ“ Dry 2019: 95 scenes â†’ SEAS_DRY_Hasdeo_Full_2019_first_event\n",
      "    âœ“ Wet 2019: 38 scenes â†’ SEAS_WET_Hasdeo_Full_2019_first_event\n",
      "    âœ“ Dry 2020: 121 scenes â†’ SEAS_DRY_Hasdeo_Full_2020_first_event\n",
      "    âœ“ Wet 2020: 27 scenes â†’ SEAS_WET_Hasdeo_Full_2020_first_event\n",
      "    âœ“ Dry 2021: 109 scenes â†’ SEAS_DRY_Hasdeo_Full_2021_first_event\n",
      "    âœ“ Wet 2021: 26 scenes â†’ SEAS_WET_Hasdeo_Full_2021_first_event\n",
      "    âœ“ Dry 2022: 108 scenes â†’ SEAS_DRY_Hasdeo_Full_2022_second_event\n",
      "    âœ“ Wet 2022: 30 scenes â†’ SEAS_WET_Hasdeo_Full_2022_first_event\n",
      "    âœ“ Dry 2023: 111 scenes â†’ SEAS_DRY_Hasdeo_Full_2023_first_event\n",
      "    âœ“ Wet 2023: 39 scenes â†’ SEAS_WET_Hasdeo_Full_2023_first_event\n",
      "\n",
      "  ðŸŒ³ Hasdeo_North\n",
      "    âœ“ Dry 2018: 49 scenes â†’ SEAS_DRY_Hasdeo_North_2018_first_event\n",
      "    âœ“ Wet 2018: 1 scenes â†’ SEAS_WET_Hasdeo_North_2018_first_event\n",
      "    âœ“ Dry 2019: 46 scenes â†’ SEAS_DRY_Hasdeo_North_2019_first_event\n",
      "    âœ“ Wet 2019: 17 scenes â†’ SEAS_WET_Hasdeo_North_2019_first_event\n",
      "    âœ“ Dry 2020: 59 scenes â†’ SEAS_DRY_Hasdeo_North_2020_first_event\n",
      "    âœ“ Wet 2020: 15 scenes â†’ SEAS_WET_Hasdeo_North_2020_first_event\n",
      "    âœ“ Dry 2021: 57 scenes â†’ SEAS_DRY_Hasdeo_North_2021_first_event\n",
      "    âœ“ Wet 2021: 14 scenes â†’ SEAS_WET_Hasdeo_North_2021_first_event\n",
      "    âœ“ Dry 2022: 51 scenes â†’ SEAS_DRY_Hasdeo_North_2022_second_event\n",
      "    âœ“ Wet 2022: 14 scenes â†’ SEAS_WET_Hasdeo_North_2022_first_event\n",
      "    âœ“ Dry 2023: 53 scenes â†’ SEAS_DRY_Hasdeo_North_2023_first_event\n",
      "    âœ“ Wet 2023: 17 scenes â†’ SEAS_WET_Hasdeo_North_2023_first_event\n",
      "\n",
      "  ðŸŒ³ Hasdeo_South\n",
      "    âœ“ Dry 2018: 99 scenes â†’ SEAS_DRY_Hasdeo_South_2018_first_event\n",
      "    âœ“ Wet 2018: 1 scenes â†’ SEAS_WET_Hasdeo_South_2018_first_event\n",
      "    âœ“ Dry 2019: 95 scenes â†’ SEAS_DRY_Hasdeo_South_2019_first_event\n",
      "    âœ“ Wet 2019: 38 scenes â†’ SEAS_WET_Hasdeo_South_2019_first_event\n",
      "    âœ“ Dry 2020: 121 scenes â†’ SEAS_DRY_Hasdeo_South_2020_first_event\n",
      "    âœ“ Wet 2020: 27 scenes â†’ SEAS_WET_Hasdeo_South_2020_first_event\n",
      "    âœ“ Dry 2021: 109 scenes â†’ SEAS_DRY_Hasdeo_South_2021_first_event\n",
      "    âœ“ Wet 2021: 26 scenes â†’ SEAS_WET_Hasdeo_South_2021_first_event\n",
      "    âœ“ Dry 2022: 108 scenes â†’ SEAS_DRY_Hasdeo_South_2022_second_event\n",
      "    âœ“ Wet 2022: 30 scenes â†’ SEAS_WET_Hasdeo_South_2022_first_event\n",
      "    âœ“ Dry 2023: 111 scenes â†’ SEAS_DRY_Hasdeo_South_2023_first_event\n",
      "    âœ“ Wet 2023: 39 scenes â†’ SEAS_WET_Hasdeo_South_2023_first_event\n",
      "\n",
      "  ðŸŒ³ Hasdeo_Core\n",
      "    âœ“ Dry 2018: 99 scenes â†’ SEAS_DRY_Hasdeo_Core_2018_first_event\n",
      "    âœ“ Wet 2018: 1 scenes â†’ SEAS_WET_Hasdeo_Core_2018_first_event\n",
      "    âœ“ Dry 2019: 95 scenes â†’ SEAS_DRY_Hasdeo_Core_2019_first_event\n",
      "    âœ“ Wet 2019: 38 scenes â†’ SEAS_WET_Hasdeo_Core_2019_first_event\n",
      "    âœ“ Dry 2020: 119 scenes â†’ SEAS_DRY_Hasdeo_Core_2020_first_event\n",
      "    âœ“ Wet 2020: 27 scenes â†’ SEAS_WET_Hasdeo_Core_2020_first_event\n",
      "    âœ“ Dry 2021: 109 scenes â†’ SEAS_DRY_Hasdeo_Core_2021_first_event\n",
      "    âœ“ Wet 2021: 26 scenes â†’ SEAS_WET_Hasdeo_Core_2021_first_event\n",
      "    âœ“ Dry 2022: 108 scenes â†’ SEAS_DRY_Hasdeo_Core_2022_second_event\n",
      "    âœ“ Wet 2022: 30 scenes â†’ SEAS_WET_Hasdeo_Core_2022_first_event\n",
      "    âœ“ Dry 2023: 109 scenes â†’ SEAS_DRY_Hasdeo_Core_2023_first_event\n",
      "    âœ“ Wet 2023: 39 scenes â†’ SEAS_WET_Hasdeo_Core_2023_first_event\n",
      "\n",
      "====================================================================\n",
      "  EXPORT SUMMARY\n",
      "====================================================================\n",
      "  âœ“ Tasks queued  : 268 images\n",
      "  âŠ™ Skipped       : 68\n",
      "  ðŸ“ Drive folder : Hasdeo_JPEG_Dataset/\n",
      "  ðŸ”— Monitor      : https://code.earthengine.google.com/tasks\n",
      "====================================================================\n",
      "âœ“ CSV  â†’ hasdeo_jpeg_local/metadata/export_log.csv  (268 records)\n",
      "âœ“ JSON â†’ hasdeo_jpeg_local/metadata/manifest.json\n",
      "âœ“ Task IDs â†’ hasdeo_jpeg_local/logs/task_ids.json\n",
      "\n",
      "  ðŸ“Œ POST-PROCESSING â€” convert RGB GeoTIFFs to real .jpg locally:\n",
      "     for f in *.tif; do\n",
      "         gdal_translate -of JPEG -co QUALITY=90 \"$f\" \"${f%.tif}.jpg\"\n",
      "     done\n",
      "\n",
      "  âœ…  Done. Check the GEE task monitor for export progress.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hasdeo Forest JPEG Downloader â€” 300 IMAGE DATASET\n",
    "==================================================\n",
    "Downloads RGB visual JPEG exports from Sentinel-2 for the Hasdeo Arand\n",
    "forest region covering the full deforestation timeline (2018â€“2023).\n",
    "\n",
    "TARGET: ~336 JPEG images via:\n",
    "  - Monthly composites  (Jan 2018 â€“ Dec 2023) Ã— 4 sub-regions = 288\n",
    "  - Seasonal dry        (2018â€“2023)            Ã— 4 sub-regions =  24\n",
    "  - Seasonal wet        (2018â€“2023)            Ã— 4 sub-regions =  24\n",
    "  TOTAL POTENTIAL                                               = 336\n",
    "\n",
    "OUTPUT:\n",
    "  - Single Google Drive folder : Hasdeo_JPEG_Dataset/\n",
    "  - File naming  : GEE default â€” matches the task description string\n",
    "                   e.g.  MON_Hasdeo_Full_2022_03_second_event.tif\n",
    "                          SEAS_DRY_Hasdeo_North_2021_first_event.tif\n",
    "  - Format       : GeoTIFF (RGB, B4/B3/B2 visualised, 30 m)\n",
    "                   NOTE: GEE batch toDrive() does not support native .jpg â€”\n",
    "                   it exports an RGB GeoTIFF that any viewer opens as an image.\n",
    "                   To convert to true .jpg after downloading from Drive:\n",
    "                     gdal_translate -of JPEG -co QUALITY=90 input.tif output.jpg\n",
    "\n",
    "DEFORESTATION PHASES:\n",
    "  first_event  â†’ 2018-01 to 2023-12 (broad clearance window)\n",
    "  second_event â†’ 2022-03 and 2022-04 (peak event, tagged per month)\n",
    "\n",
    "USAGE:\n",
    "  pip install earthengine-api tqdm\n",
    "  earthengine authenticate          # one-time\n",
    "  python hasdeo_300_downloader.py\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CONFIGURATION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "PROJECT_ID        = 'glacier-probe-model-475519'   # â† your GEE Cloud project\n",
    "OUTPUT_DIR        = 'hasdeo_jpeg_local'            # local metadata/logs only\n",
    "MAX_CLOUD_COVER   = 20                             # % cloud cover per scene\n",
    "MIN_IMAGES_PERIOD = 1                              # skip if fewer scenes found\n",
    "JPEG_SCALE        = 30                             # export resolution in metres\n",
    "\n",
    "# â”€â”€ Single Drive folder â€” ALL JPEGs land here â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "DRIVE_FOLDER = 'Hasdeo_JPEG_Dataset'\n",
    "\n",
    "# â”€â”€ 4 sub-regions (WGS84: [west, south, east, north]) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "REGIONS = {\n",
    "    'Hasdeo_Full':  [82.58, 22.40, 83.20, 22.90],\n",
    "    'Hasdeo_North': [82.58, 22.65, 83.20, 22.90],\n",
    "    'Hasdeo_South': [82.58, 22.40, 83.20, 22.65],\n",
    "    'Hasdeo_Core':  [82.75, 22.50, 83.05, 22.80],\n",
    "}\n",
    "\n",
    "# â”€â”€ Bands needed for cloud masking + RGB export â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "S2_BANDS = ['B2', 'B3', 'B4', 'B8', 'B11', 'B12', 'SCL']\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# PHASE LABELLING\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def get_phase(year: int, month: int) -> str:\n",
    "    \"\"\"Tag each composite with its deforestation phase.\"\"\"\n",
    "    if year == 2022 and month in (3, 4):\n",
    "        return 'second_event'\n",
    "    if 2018 <= year <= 2023:\n",
    "        return 'first_event'\n",
    "    return 'background'\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TIME PERIOD BUILDER\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def build_monthly_periods():\n",
    "    \"\"\"Monthly windows Jan 2018 â€“ Dec 2023.\"\"\"\n",
    "    periods = []\n",
    "    for year in range(2018, 2024):\n",
    "        for month in range(1, 13):\n",
    "            start = f'{year}-{month:02d}-01'\n",
    "            end   = f'{year + 1}-01-01' if month == 12 else f'{year}-{month + 1:02d}-01'\n",
    "            periods.append((start, end, get_phase(year, month), year, month))\n",
    "    return periods\n",
    "\n",
    "TIME_PERIODS = build_monthly_periods()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# EARTH ENGINE INIT\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def init_ee():\n",
    "    try:\n",
    "        ee.Initialize(project=PROJECT_ID)\n",
    "        print(f\"âœ“ Earth Engine initialised | project: {PROJECT_ID}\")\n",
    "    except Exception:\n",
    "        print(\"âš   Authenticating...\")\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize(project=PROJECT_ID)\n",
    "        print(\"âœ“ Authenticated and initialised.\")\n",
    "\n",
    "def create_local_dirs():\n",
    "    for sub in ['metadata', 'logs']:\n",
    "        Path(f\"{OUTPUT_DIR}/{sub}\").mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"âœ“ Local dirs ready: {OUTPUT_DIR}/\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CLOUD MASKING\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def mask_s2_clouds(image):\n",
    "    \"\"\"QA60 + SCL dual-layer cloud mask.\"\"\"\n",
    "    qa       = image.select('QA60')\n",
    "    qa_mask  = (qa.bitwiseAnd(1 << 10).eq(0)\n",
    "                  .And(qa.bitwiseAnd(1 << 11).eq(0)))\n",
    "    scl      = image.select('SCL')\n",
    "    scl_mask = (scl.neq(3).And(scl.neq(8))\n",
    "                           .And(scl.neq(9))\n",
    "                           .And(scl.neq(10))\n",
    "                           .And(scl.neq(11)))\n",
    "    return image.updateMask(qa_mask.And(scl_mask))\n",
    "\n",
    "def get_s2_collection(roi, start_date, end_date):\n",
    "    \"\"\"Cloud-filtered Sentinel-2 SR collection.\"\"\"\n",
    "    return (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "              .filterBounds(roi)\n",
    "              .filterDate(start_date, end_date)\n",
    "              .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', MAX_CLOUD_COVER))\n",
    "              .select(S2_BANDS + ['QA60'])\n",
    "              .map(mask_s2_clouds))\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# JPEG EXPORT  â€” single folder, GEE default filename = description\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def export_jpeg(composite, description, roi):\n",
    "    \"\"\"\n",
    "    Export an RGB (B4/B3/B2) visualised image to a single Drive folder.\n",
    "\n",
    "    GEE names the output file using `fileNamePrefix` (= description here),\n",
    "    so the filename is always predictable and matches the task name exactly.\n",
    "\n",
    "    fileFormat='GeoTIFF' is used because GEE's toDrive() does not support\n",
    "    native JPEG â€” the RGB GeoTIFF is fully openable as a colour image by\n",
    "    any standard viewer (QGIS, Preview, Photoshop, etc.).\n",
    "    \"\"\"\n",
    "    rgb = composite.visualize(\n",
    "        bands=['B4', 'B3', 'B2'],\n",
    "        min=200,\n",
    "        max=3000,\n",
    "        gamma=1.4,\n",
    "    )\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image          = rgb,\n",
    "        description    = description,    # task name in GEE console\n",
    "        folder         = DRIVE_FOLDER,   # single flat Drive folder\n",
    "        fileNamePrefix = description,    # filename = description (GEE default)\n",
    "        region         = roi,\n",
    "        scale          = JPEG_SCALE,\n",
    "        crs            = 'EPSG:32644',   # UTM Zone 44N â€” Hasdeo region\n",
    "        fileFormat     = 'GeoTIFF',\n",
    "        maxPixels      = 1e10,\n",
    "        formatOptions  = {'cloudOptimized': True},\n",
    "    )\n",
    "    task.start()\n",
    "    return task\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# SEASONAL COMPOSITE HELPER\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def make_seasonal_composite(roi, year, season):\n",
    "    \"\"\"\n",
    "    Median composite for a season.\n",
    "      dry â†’ Novâ€“Apr  (clear skies; best for deforestation detection)\n",
    "      wet â†’ Mayâ€“Oct  (captures phenological change)\n",
    "    \"\"\"\n",
    "    if season == 'dry':\n",
    "        start, end = f'{year}-11-01', f'{year + 1}-04-30'\n",
    "    else:\n",
    "        start, end = f'{year}-05-01', f'{year}-10-31'\n",
    "    col   = get_s2_collection(roi, start, end)\n",
    "    count = col.size().getInfo()\n",
    "    return col.median().clip(roi), count, start, end\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# METADATA\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "records = []\n",
    "\n",
    "def log_record(task_id, description, region, start, end, count, phase, ctype):\n",
    "    records.append({\n",
    "        'filename':       f'{description}.tif',\n",
    "        'drive_folder':   DRIVE_FOLDER,\n",
    "        'description':    description,\n",
    "        'region':         region,\n",
    "        'composite_type': ctype,\n",
    "        'phase':          phase,\n",
    "        'start_date':     start,\n",
    "        'end_date':       end,\n",
    "        'scene_count':    count,\n",
    "        'task_id':        task_id,\n",
    "        'scale_m':        JPEG_SCALE,\n",
    "        'bands':          'B4,B3,B2 (RGB visualised)',\n",
    "        'crs':            'EPSG:32644',\n",
    "        'exported_at':    datetime.now().isoformat(),\n",
    "    })\n",
    "\n",
    "def save_csv():\n",
    "    if not records:\n",
    "        return\n",
    "    p = f'{OUTPUT_DIR}/metadata/export_log.csv'\n",
    "    with open(p, 'w', newline='') as f:\n",
    "        w = csv.DictWriter(f, fieldnames=records[0].keys())\n",
    "        w.writeheader()\n",
    "        w.writerows(records)\n",
    "    print(f\"âœ“ CSV  â†’ {p}  ({len(records)} records)\")\n",
    "\n",
    "def save_manifest(all_tasks, exported, skipped, potential):\n",
    "    manifest = {\n",
    "        'dataset':         'Hasdeo JPEG Dataset 300',\n",
    "        'generated_at':    datetime.now().isoformat(),\n",
    "        'drive_folder':    DRIVE_FOLDER,\n",
    "        'regions':         list(REGIONS.keys()),\n",
    "        'timeline':        '2018-01-01 â€“ 2023-12-31',\n",
    "        'phases': {\n",
    "            'first_event':  '2018-01 â€“ 2023-12 (broad clearance window)',\n",
    "            'second_event': '2022-03 and 2022-04 (peak event)',\n",
    "        },\n",
    "        'composite_types': ['monthly', 'seasonal_dry', 'seasonal_wet'],\n",
    "        'scale_m':         JPEG_SCALE,\n",
    "        'crs':             'EPSG:32644',\n",
    "        'bands':           'B4, B3, B2 (RGB visualised GeoTIFF)',\n",
    "        'summary': {\n",
    "            'potential': potential,\n",
    "            'queued':    exported,\n",
    "            'skipped':   skipped,\n",
    "        },\n",
    "        'monitor': 'https://code.earthengine.google.com/tasks',\n",
    "        'tasks':   [\n",
    "            {'id': t.id, 'description': t.config.get('description', '')}\n",
    "            for t in all_tasks if t\n",
    "        ],\n",
    "    }\n",
    "    p = f'{OUTPUT_DIR}/metadata/manifest.json'\n",
    "    with open(p, 'w') as f:\n",
    "        json.dump(manifest, f, indent=2)\n",
    "    print(f\"âœ“ JSON â†’ {p}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MAIN\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def main():\n",
    "    monthly_pot  = len(TIME_PERIODS) * len(REGIONS)   # 72 Ã— 4 = 288\n",
    "    seasonal_pot = 6 * len(REGIONS) * 2               # 6yr Ã— 4 Ã— 2 = 48\n",
    "    total_pot    = monthly_pot + seasonal_pot          # 336\n",
    "\n",
    "    print(\"=\" * 68)\n",
    "    print(\"  HASDEO FOREST â€” JPEG DATASET DOWNLOADER  (~300 images)\")\n",
    "    print(\"=\" * 68)\n",
    "    print(f\"  Drive folder  : {DRIVE_FOLDER}/\")\n",
    "    print(f\"  Resolution    : {JPEG_SCALE} m  |  RGB (B4 / B3 / B2)\")\n",
    "    print(f\"  Naming        : GEE default â€” filename = task description\")\n",
    "    print(f\"  Regions       : {list(REGIONS.keys())}\")\n",
    "    print(f\"  Timeline      : Jan 2018 â€“ Dec 2023\")\n",
    "    print(f\"  Potential     : {total_pot}  (monthly {monthly_pot} + seasonal {seasonal_pot})\")\n",
    "    print(\"=\" * 68)\n",
    "\n",
    "    init_ee()\n",
    "    create_local_dirs()\n",
    "\n",
    "    all_tasks = []\n",
    "    exported  = 0\n",
    "    skipped   = 0\n",
    "\n",
    "    # â”€â”€ PART 1 : Monthly composites â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"\\n[ PART 1 ]  Monthly composites â€” Jan 2018 to Dec 2023\")\n",
    "    print(\"-\" * 68)\n",
    "\n",
    "    for region_name, coords in REGIONS.items():\n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        print(f\"\\n  ðŸŒ³ {region_name}\")\n",
    "\n",
    "        for start, end, phase, year, month in tqdm(\n",
    "                TIME_PERIODS, desc=f\"  {region_name}\", unit='month'):\n",
    "            try:\n",
    "                col   = get_s2_collection(roi, start, end)\n",
    "                count = col.size().getInfo()\n",
    "\n",
    "                if count < MIN_IMAGES_PERIOD:\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "\n",
    "                composite = col.median().clip(roi)\n",
    "\n",
    "                # e.g. MON_Hasdeo_Full_2022_03_second_event\n",
    "                desc = f'MON_{region_name}_{year}_{month:02d}_{phase}'[:90]\n",
    "\n",
    "                task = export_jpeg(composite, desc, roi)\n",
    "                all_tasks.append(task)\n",
    "                log_record(task.id, desc, region_name,\n",
    "                           start, end, count, phase, 'monthly')\n",
    "                exported += 1\n",
    "                time.sleep(0.35)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n    âœ— [{start}] {str(e)[:70]}\")\n",
    "\n",
    "    # â”€â”€ PART 2 : Seasonal composites â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"\\n\\n[ PART 2 ]  Seasonal composites â€” dry + wet, 2018â€“2023\")\n",
    "    print(\"-\" * 68)\n",
    "\n",
    "    for region_name, coords in REGIONS.items():\n",
    "        roi = ee.Geometry.Rectangle(coords)\n",
    "        print(f\"\\n  ðŸŒ³ {region_name}\")\n",
    "\n",
    "        for year in range(2018, 2024):\n",
    "            for season in ('dry', 'wet'):\n",
    "                try:\n",
    "                    composite, count, s_date, e_date = make_seasonal_composite(\n",
    "                        roi, year, season)\n",
    "\n",
    "                    if count < MIN_IMAGES_PERIOD:\n",
    "                        print(f\"    âŠ™ {season} {year}: no scenes â€” skipped\")\n",
    "                        skipped += 1\n",
    "                        continue\n",
    "\n",
    "                    # Dry 2022 overlaps the peak second_event clearance window\n",
    "                    phase = ('second_event'\n",
    "                             if year == 2022 and season == 'dry'\n",
    "                             else 'first_event')\n",
    "\n",
    "                    # e.g. SEAS_DRY_Hasdeo_Core_2022_second_event\n",
    "                    desc = f'SEAS_{season.upper()}_{region_name}_{year}_{phase}'[:90]\n",
    "\n",
    "                    task = export_jpeg(composite, desc, roi)\n",
    "                    all_tasks.append(task)\n",
    "                    log_record(task.id, desc, region_name,\n",
    "                               s_date, e_date, count, phase, f'seasonal_{season}')\n",
    "                    exported += 1\n",
    "                    print(f\"    âœ“ {season.capitalize()} {year}: {count} scenes â†’ {desc}\")\n",
    "                    time.sleep(0.35)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"    âœ— {season} {year}: {str(e)[:70]}\")\n",
    "\n",
    "    # â”€â”€ Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"\\n\" + \"=\" * 68)\n",
    "    print(\"  EXPORT SUMMARY\")\n",
    "    print(\"=\" * 68)\n",
    "    print(f\"  âœ“ Tasks queued  : {exported} images\")\n",
    "    print(f\"  âŠ™ Skipped       : {skipped}\")\n",
    "    print(f\"  ðŸ“ Drive folder : {DRIVE_FOLDER}/\")\n",
    "    print(f\"  ðŸ”— Monitor      : https://code.earthengine.google.com/tasks\")\n",
    "    print(\"=\" * 68)\n",
    "\n",
    "    save_csv()\n",
    "    save_manifest(all_tasks, exported, skipped, total_pot)\n",
    "\n",
    "    # Save task IDs locally\n",
    "    p = f'{OUTPUT_DIR}/logs/task_ids.json'\n",
    "    with open(p, 'w') as f:\n",
    "        json.dump(\n",
    "            [{'id': t.id, 'desc': t.config.get('description', '')}\n",
    "             for t in all_tasks if t],\n",
    "            f, indent=2,\n",
    "        )\n",
    "    print(f\"âœ“ Task IDs â†’ {p}\")\n",
    "\n",
    "    print(\"\\n  ðŸ“Œ POST-PROCESSING â€” convert RGB GeoTIFFs to real .jpg locally:\")\n",
    "    print(\"     for f in *.tif; do\")\n",
    "    print('         gdal_translate -of JPEG -co QUALITY=90 \"$f\" \"${f%.tif}.jpg\"')\n",
    "    print(\"     done\\n\")\n",
    "    print(\"  âœ…  Done. Check the GEE task monitor for export progress.\\n\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06904de0-5f64-41f9-8208-9a9233bf8710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
